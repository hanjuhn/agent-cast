[
    {
        "title": "[GN⁺] GPT-OSS vs. Qwen3 및 GPT-2 이후 LLM 아키텍처 발전 상세 비교",
        "url": "https://discuss.pytorch.kr/t/gn-gpt-oss-vs-qwen3-gpt-2-llm/7497",
        "content": "GPT-OSS vs. Qwen3 및 GPT-2 이후 LLM 아키텍처 발전 상세 비교 글 소개\nOpenAI가 gpt-oss-20b/120b 모델을 오픈 가중치로 공개함에 따라 2019년 GPT-2 이후 처음으로 OpenAI의 대형 공개 가중치 LLM이 등장함\ngpt-oss 모델은 GPT-2와 비교해 Dropout, Absolute Position Embedding, GELU 등을 효율적인 현대 기법인 RoPE, SwiGLU, RMSNorm 등으로 대체하며 발전함\nMixture-of-Experts(모듈형 전문가 구조), Sliding Window Attention, MXFP4 양자화 등의 적용으로 성능 효율뿐 아니라 단일 GPU 실행 환경을 크게 개선함\nQwen3와의 비교에서 아키텍처 깊이/넓이, 전문가 수, 주의 편향, 오픈소스 라이선스 등 다양한 차별점이 존재함을 확인함\ngpt-oss-20b는 최신 하드웨어에 맞춘 경량화와 reasoning effort 조정 기능으로 실제 활용성과 연구 확장성 모두 확보함\n개요 및 주요 혁신\nOpenAI는 gpt-oss-20b/120b를 2019년 GPT-2 이후 처음으로 오픈 가중치로 공개함\n일반 사용자 GPU(최대 16GB RAM)에서 20B, H100 80GB에서 120B를 실행 가능하게 함\nMXFP4 최적화로 단일 GPU 실행, 소비자 접근성 확대\nGPT-2 → gpt-oss 주요 아키텍처 변화\nDropout 제거\nGPT-2에는 Dropout이 포함됐으나 대량 데이터 단일 epoch 학습 환경에선 오히려 성능 저하가 확인됨\n최근 연구 결과에서도 Dropout 미적용이 LLM의 다운스트림 작업에서 더 뛰어난 성능을 보임\nRoPE(회전 위치 임베딩) 채택\n기존 절대 위치 임베딩 대신 RoPE(Rotary Position Embedding) 가 주류로 자리 잡음\nRoPE는 쿼리/키 벡터의 각도를 위치에 따라 회전시켜 더 유연하고 일반화된 위치 정보를 제공함\nSwiGLU 활성화 함수와 GLU 도입\nGEGLU/SwiGLU 등 GLU 방식 도입으로 기존 2-layer FFN보다 적은 파라미터로 더 우수한 표현 능력을 발휘함\nSwish는 연산적으로도 GELU 대비 효율적\nMixture-of-Experts(MoE) 적용\n단일 FFN 대신 다중 전문가(Expert) 네트워크를 활용해 매 토큰 생성 시 일부 전문가만 활성화\n모델 파라미터 수를 급격히 늘리면서도 추론 효율성(희소성) 유지, 학습 용량 증대\nGrouped Query Attention(GQA) 도입\n기존 Multi-Head Attention 대비 키/값 공유로 메모리 및 연산량 절감 효과\n성능 손실 없이 효율성 개선, 대규모 LLM에서 표준적 적용 추세\nSliding Window Attention 활용\n일부 레이어마다 전체 문맥 대신 최근 128토큰 한정 Sliding Window로 국소 주의 계산, 메모리 사용량 최소화\n성능 저하 없이 빠른 추론, 대규모 컨텍스트 지원용\nRMSNorm 채택\nLayerNorm 대신 RMSNorm 적용으로 연산 효율 증대\nLayerNorm의 평균/분산 계산 대신 RMS(평균제곱근)를 적용, GPU 연산 부담 감소\ngpt-oss와 Qwen3 비교\n규모/구조 차이\nQwen3은 더 깊은(48개 Transformer 블록) 구조이나, gpt-oss는 더 넓은(emb dimension, head 수 증가) 구조\n깊은 모델이 더 유연하지만 학습 어려움, 넓은 모델이 추론 병렬화에 유리(Gemma 2 논문, 9B 모델 기준 넓은 쪽이 소폭 우세)\nMoE 구조 차이\ngpt-oss-20b: 32명 대형 전문가, 4명만 활성화\nQwen3: 다수 소형 전문가, 8명 활성화\n최신 흐름은 더 많은 소형 전문가 구성이 효과적이라는 방향이나 gpt-oss는 대형-소수 구조 고수 (20B, 120B에서는 전문가 및 블록 수만 조정)\nAttention Bias와 Sinks\ngpt-oss는 attention에 bias 유닛 활용 (GPT-2 시절 이후 보기 드문 방식)\n하지만 key-proj에는 효과 미미함이 최근 연구에서 밝혀짐\n주의 sink는 시퀀스 시작위치에 항상 attend되는 특수 토큰 개념이나, gpt-oss에서는 입력 토큰에 변형 없이 Learned bias logit 형태로 각 head에 추가 적용\n라이선스 및 공개 범위\nApache 2.0 오픈소스 라이선스로 상업적 활용/파생 모델 구축 자유\n단, 진정한 의미의 오픈소스(학습 코드, 데이터 세트 공개)는 아님(‘open weight’ 모델임)\n기타 세부 사항 및 실제 운용\n훈련/최적화\ngpt-oss는 2.1M H100-hours 컴퓨팅 리소스로 훈련\n영어 중심, STEM과 코딩, 일반 지식 텍스트에 집중\n사전학습+지도 미세학습(Instruction), RL 기반 reasoning 단계 등 최신 기법 적용\nReasoning Effort 조절\nSystem prompt를 통해 reasoning effort(저/중/고)를 설정해 답변 길이·정확도를 자동 조정\n단순 작업은 저효율로 빠르게, 복잡한 reasoning이 필요하면 높게 설정 가능\nMXFP4 양자화로 단일 GPU 지원\nMXFP4 포맷 활용으로 20B도 16GB VRAM(최신 GPU 필수)에서 구동 가능\n120B는 H100 기준 80GB 메모리면 단일 GPU에서 실현 가능, 분산 처리 없고 구동 간편\n벤치마크 및 실 사용성\ngpt-oss는 학습 초점이 reasoning에 치중, 일부 범용 지식 질문에는 환각(hallucination) 경향\n사용성 면에서는 현존 오픈 모델 중 상위, tool integration과 조합 시 실용성 강화 예정\n실제 사용에서 정확도와 reasoning의 균형, 추후 타 오픈모델과의 비교 필요\nGPT-5와의 비교\ngpt-oss-120b는 OpenAI 상용 모델(GPT-5)과 벤치마크 기준 근접 성능을 보임\n현실 환경에서의 우위는 더 지켜봐야 하나, 오픈 가중치로 제공되는 최신 LLM 중 강력한 대안임\n벤치마크만으로 실전 경쟁력 완전히 설명하기엔 한계, 향후 외부 비교 및 연구에 큰 기회 제공\n요약\ngpt-oss 시리즈의 등장은 대형 오픈 가중치 LLM 분야의 새로운 기준 제시, 최신 LLM들이 도입한 혁신적 아키텍처들이 실제로 어떻게 구현·적용됐는지 상세히 비교, 분석됨\nQuen3, GPT-5 등 다른 최신 모델과의 차별점과 추세를 파악할 수 있어, 실제 적용/연구에 유용한 최신 동향 파악 가능\nHacker News 의견\nQwen3가 로컬 테스트에서 훨씬 뛰어남을 확인함. 32B 파라미터 버전에서는 프롬프트를 거의 완벽하게 지키며 결과가 자연스럽게 나옴. 반면 simplebench gpt-oss(120B)는 논리 퍼즐에서 좋지 않은 성능을 보임. 이런 차이는 트레이닝 방식, 모델 차원, 그리고 적은 수의 대형 전문가 vs 많은 수의 소형 전문가 등에서 비롯된다고 생각함\nQwen3 32B는 모든 파라미터를 항상 사용하는 덴스 모델임. GPT OSS 20B는 일부만 사용하는 스파스 MoE(Expert of Experts) 모델로, 한 번에 약 3.6B만 활용함. 이로 인해 덴스 20B 모델보다 빠르고, 3.6B 모델보다는 똑똑함. 공정한 비교라면 덴스 8B 모델과 비교해야 하고, Qwen Coder 30B A3B 같은 모델도 좋은 비교 지점임\n내 생각에 이런 차이는 모델 아키텍처보다는 데이터와 트레이닝 파이프라인 영향이 훨씬 크다고 봄. gpt-oss가 Phi 스타일의 합성 데이터셋만을 활용하고, 주로 벤치마크 게임에 집중했다는 이야기가 있는데, 그 증거가 충분히 설득력 있어 보임\nMoE의 기대 성능 공식은 sqrt(활성 헤드 수 * 전체 파라미터 수)임. 예를 들어 sqrt(120*5) ~= 24로, GPT-OSS 120B는 사실 24B 수준의 성능과 훨씬 작은 모델 수준의 속도를 제공함\nqwen3는 느린 편임. 직접 써보니 동작은 하는데 속도가 느리고, 기능이 부족한 느낌임\nSebastian Raschk의 블로그 글들이 보물 같은 정보임. get-oss와 qwen3 모델을 Ollama, LM Studio로 로컬에서 사용하고, 대형 모델은 상용 API를 씀. get-oss는 프롬프트에 많은 컨텍스트 정보를 넘기면 좋은 결과를 주고, qwen3는 그냥 훌륭함. 3년 전까지는 신경망, GAN, RNN, LSTM 등 머신러닝을 실제로 구현할 정도로 잘 이해했었는데, 요즘 LLM은 직접 개발할 정도로 쉽지 않아서 아쉬움. Sebastian Raschk의 책도 보고 있는데, 아마 끝까지 다 못 볼 듯함\n믿을 수 없을 정도로 빠르게 변화하는 분야에서 Sebastian Raschk가 항상 최신 정보를 간결하게 정리해줘서 정말 도움을 받고 있음\n로컬 3090 GPU에서 qwen3 coder instruct 30b-a3b exl3 q6 모델을 돌려서 샘플 페이지도 만들고, 서버 실행, 남아있는 서버 감지, 이를 직접 종료한 후(권한 요청까지 받음), 재실행 후 ip를 자동으로 찾아 브라우저에 띄우는 과정을 해봄. 이제는 더 이상 단순 데모가 아니라 주니어나 인턴에게도 실질적으로 유용한 수준의 도움임\n내 경험상 qwen3-coder가 월등히 뛰어남. gpt-oss:20b도 설치해봤지만, 코드 요약을 시키면 qwen3는 몇 초 만에 결과가 나오고 gpt-oss는 5분 넘게 아무 일도 하지 않아서 중단함. 그래서 그냥 qwen3만 씀. 만약 원하는 답을 못 받으면, 검색 엔진이나 Perplexity를 씀. 10GB 3080, Ryzen 3600x, 32GB RAM을 쓰고 있음. Qwen3-coder는 지금까지 써본 것 중 최고임\nQwen3 coder 480B는 Sonnet 4와 맞먹을 정도로 좋음. 이 덕분에 중국 모델이 미국 기반 모델을 조만간 앞지를 수도 있다는 실감을 처음 가짐(특히 코딩 분야에서)\ngpt-oss 20B는 10GB에 올라가지 않아서 생긴 문제일 가능성이 있음\n나도 gpt-oss-20b를 간단하게 쓰는데, 짧은 프롬프트(단문)에는 무한 반복에 빠질 때가 있음. llama.cpp로 돌릴 때 반복 패널티 값을 작게 잡으니 그런 문제가 없었음(주로 diff 분석에 하루 몇 번 정도 사용함). 단, 내가 운이 좋은 걸 수도 있음\n혹시 agentic 방식(여러 번의 질문과 답변을 주고받는 자동화)으로 쓰고 있는지, 아니면 복사해서 “이 코드 짜줘” 식의 단일 입력/출력으로만 쓰는지 궁금함. 최신 공개 모델이 agentic한 코딩에서 얼마나 상용 모델을 따라잡았는지 알고 싶음\n요즘 오픈 웨이트 LLM들은 아키텍처가 너무 비슷하고, 혁신이 데이터나 RL 쪽에서만 일어나고 있는 점이 흥미로움. 예전 대형 ML 조직에서는 아키텍처 튜닝이 가장 중요했는데 현실은 달라 보임\nLLM 규모에서는 하이퍼파라미터 튜닝 자체가 불가능하다고 봄. 비용이 너무 커서 여러 아키텍처를 기본 테스트만 하고, 하나를 골라 데이터와 RL로 최적화하는 식임\n좋은 지적임. LLM 덕분에 리소스만 충분하면 누구나 도전할 수 있게 되었음. 아키텍처가 꽤 조정에 강하고, 충분한 컴퓨트와 데이터를 넣으면 확장 법칙(scaling law)를 어겨도 괜찮은 모델을 만들 수 있음(Llama 3가 과거에 보여줬던 것처럼)\nQwen3 4B 모델을 로컬에서 정말 잘 사용 중임. 온라인 모델은 거의 안 쓰고, 웹 검색도 훨씬 타깃팅이 잘 됨. 완전히 신뢰하지는 않지만 전반적으로 괜찮음. 이런 오픈소스 모델이 로컬 지식 자동화의 판도를 바꿀 거라고 확신함\nQwen이 직접 더 나은 검색 파라미터를 안내해주는 것인지, 아니면 Qwen이 실제 웹 검색까지 해주는 것인지 궁금함\nLM Arena에서 순수 Transformer 기반이 아닌 모델 중 가장 성능이 좋은 모델은 Jamba임(Transformers와 state space 모델의 하이브리드 구조, 96위). Tencent의 hunyuan-turbos도 역시 하이브리드로, 22위임. arxiv 논문 참고\nLLM은 보통 아주 거대한 데이터셋을 딱 한 번(단일 에폭)만 학습함. 이는 여러 번 반복 학습(수백 에폭) 전제를 깔고 있던 Dropout 방식과는 다른 환경임\n이건 잘 알려진 사실임. GPT-3 논문의 Table 2.2를 참고하면 됨\n대형 연구실에서 공개하는 모델들이 추가적인 학습을 더 하면 얼마나 발전할 수 있을지 궁금함. 예를 들어 GPT-OSS가 210만 시간 학습했다면, 그걸 두 배로 늘리면 얼마나 개선될 수 있을지 알고 싶음\nGPT-4.5는 사실 더 큰 GPT-5로 기획되어 더 많은 데이터를 학습했을 수도 있음. 하지만 너무 비싸서 대규모 상용화는 못 했고, RL 적용 버전도 못 보게 된 아쉬움 있음\nGPT-5에서 활용된 RL 기반 트레이닝 첨단 기법도 무한정 확장되진 않는다는 점이 이미 드러남\n사이트에 접속하면 \"연결이 안전하지 않습니다\"라는 오류 메시지를 받음. \"magazine.sebastianraschka.com 웹사이트가 HSTS를 사용 중이라 지금 방문할 수 없습니다\"라고 나옴. 크롬 최신 버전, Ubuntu 환경임\n원문\nmagazine.sebastianraschka.com\nFrom GPT-2 to gpt-oss: Analyzing the Architectural Advances\nAnd How They Stack Up Against Qwen3\n출처 / GeekNews\nGeekNews – 11 Aug 25\nGPT-OSS vs. Qwen3 및 GPT-2 이후 LLM 아키텍처 발전 상세 비교 | GeekNews\nOpenAI가 gpt-oss-20b/120b 모델을 오픈 가중치로 공개함에 따라 2019년 GPT-2 이후 처음으로 OpenAI의 대형 공개 가중치 LLM이 등장함gpt-oss 모델은 GPT-2와 비교해 Dropout, Absolute Position Embedding, GELU 등을 효율적인 현대 기법인 RoPE, SwiGLU, RMSNorm 등으로 대체\n알려드립니다\n이 글은 국내외 IT 소식들을 공유하는 GeekNews의 운영자이신 xguru님께 허락을 받아 GeekNews에 게제된 AI 관련된 소식을 공유한 것입니다.\n출처의 GeekNews 링크를 방문하시면 이 글과 관련한 추가적인 의견들을 보시거나 공유하실 수 있습니다!\n아래쪽에 좋아요를 눌러주시면 새로운 소식을 정리하고 공유하는데 힘이 됩니다~",
        "date": "2025-08-17",
        "source": "파이토치 한국 사용자 모임",
        "category": "기술"
    },
    {
        "title": "all-smi: 현존하는 대부분의 GPU 및 NPU의 하드웨어 모니터링 CLI 도구",
        "url": "https://discuss.pytorch.kr/t/all-smi-gpu-npu-cli/7496",
        "content": "all-smi 소개\n최근 AI·머신러닝 워크로드와 고성능 컴퓨팅(HPC) 환경이 확산되면서 GPU와 NPU의 실시간 상태 추적은 필수적인 운영 요소가 되고 있습니다. all-smi는 이러한 요구에 대응하기 위해 플랫폼 간 호환성과 확장성을 극대화하였고, 설치와 사용이 간단하며 다양한 배포 방법(Homebrew, PPA, .deb, Cargo, 바이너리 다운로드 등)을 지원하는 명령줄 기반(CLI)의 도구입니다.\nall-smi는 다양한 하드웨어 플랫폼에서 GPU와 NPU 자원을 실시간으로 모니터링할 수 있는 명령줄 기반 유틸리티입니다. 또한, 터미널 기반 UI를 통해 가속기 사용량, 메모리, 온도, 전력 소비량 등을 직관적으로 시각화하며, 색상 코드와 인터랙티브 정렬 기능을 제공해 대규모 모니터링 환경에서도 효율적으로 활용할 수 있습니다.\n전통적으로 NVIDIA GPU 모니터링에 사용되는 nvidia-smi를 대체할 수 있도록 설계되었으며, NVIDIA GPU뿐 아니라 NVIDIA Jetson, Apple Silicon GPU, Tenstorrent NPU, Rebellions NPU, Furiosa NPU 등 여러 가속기 하드웨어를 지원합니다. 특히 단일 PC뿐 아니라 클러스터 환경에서도 여러 노드를 동시에 모니터링할 수 있으며, 로컬·원격 모드와 Prometheus API 통합 기능을 제공합니다. Prometheus와 연동을 하게되면 Grafana 같은 시각화 대시보드로 확장 가능하며, 내장 모의(Mock) 서버로 개발·테스트 환경 구축도 손쉽게 할 수 있어 개발자와 운영자 모두에게 유용합니다.\nnvidia-smi와의 비교\n기능 nvidia-smi all-smi\n지원 하드웨어 NVIDIA GPU 전용 NVIDIA, Apple Silicon, Jetson, Tenstorrent, Rebellions, Furiosa\n운영체제 지원 Linux, Windows (일부 macOS 제한) Linux, macOS\nGPU 외 자원 모니터링 제한적 (GPU 중심) GPU, NPU, CPU, 메모리, 디스크\n클러스터 원격 모니터링 불가능 가능 (256+ 노드 지원)\nPrometheus API 연동 불가능 가능\nUI 인터랙션 기본 텍스트 출력 (정렬/컬러 없음) 컬러 코드, 컬럼별 정렬, 마우스 클릭 지원\n설치 방식 다양성 드라이버 설치 시 포함 Homebrew, PPA, Debian 패키지, Cargo, 바이너리 다운로드, 소스 빌드\n기존의 nvidia-smi는 NVIDIA GPU에 특화되어 있으며, 다른 하드웨어 플랫폼에서는 사용할 수 없는 한계가 있습니다. 반면, all-smi는 다양한 하드웨어 가속기(GPU·NPU)를 단일 인터페이스에서 관리할 수 있고, NVIDIA 외의 플랫폼에서도 동일한 명령과 UI를 제공합니다.\n또한, all-smi는 CPU·메모리·디스크 모니터링까지 통합 제공하며, 클러스터 단위의 원격 모니터링과 Prometheus API 연동 기능을 내장해 확장성이 뛰어납니다. UI 측면에서도 색상 코드, 탭 전환, 컬럼별 정렬, 마우스 클릭 정렬 등 상호작용성이 강화되어 있습니다.\n즉, nvidia-smi가 NVIDIA 전용 도구라면, all-smi는 \"플랫폼 불문 통합 하드웨어 모니터링 도구\"라고 요약할 수 있습니다.\nall-smi의 주요 기능\nGPU 및 NPU 모니터링: all-smi는 GPU 이름·드라이버 버전·사용량·메모리 상태·온도·클럭 속도·전력 소비 등 세부 지표를 실시간으로 표시합니다. NVIDIA, Apple Silicon, Jetson, Tenstorrent, Rebellions, Furiosa 등 각 플랫폼별 특화 지표도 지원하며, 다중 GPU 환경에서도 개별 장치별 모니터링이 가능합니다.\nCPU 및 메모리 모니터링: CPU는 소켓별 사용량, 클럭 속도, 온도, 전력 소비량을 표시하며, Apple Silicon의 경우 P코어·E코어별 사용량과 주파수까지 세분화 지원합니다. 메모리는 총량·사용량·가용량·스왑 영역까지 시각화하며, Linux에서는 버퍼·캐시 메모리 정보까지 제공합니다.\n프로세스·클러스터 관리: GPU 메모리를 사용하는 프로세스 목록, PID, CPU 사용률, 실행 사용자 등을 보여주며 컬럼별 색상 표시와 정렬 기능을 지원합니다. 클러스터 관리 모드에서는 전체 노드와 GPU 상태를 집계해 평균 사용량, 온도, 전력 통계를 실시간으로 제공합니다.\n원격 모니터링 및 API 연동: 256개 이상의 원격 노드를 동시에 모니터링할 수 있으며, Prometheus API 형식으로 메트릭을 노출해 Grafana 등 외부 모니터링 시스템과 연동할 수 있습니다.\nall-smi 설치 방법\nHomebrew (macOS/Linux)\nbrew tap lablup/tap\nbrew install all-smi\nUbuntu PPA\nsudo add-apt-repository ppa:lablup/backend-ai\nsudo apt update\nsudo apt install all-smi\nDebian 패키지: Releases 페이지에서 .deb 다운로드 후 설치\nCargo 설치: cargo install all-smi\n바이너리 다운로드: GitHub Releases에서 직접 내려받아 $PATH에 추가\n소스 빌드: 개발자 문서 참고\n사용 예시\n# 로컬 모니터링 (기본)\nall-smi\nsudo all-smi local --interval 5\n\n# 원격 노드 모니터링\nall-smi view --hosts http://node1:9090 http://node2:9090\nall-smi view --hostfile hosts.csv\n\n# Prometheus API 서버 실행\nall-smi api --port 9090 --processes\n라이선스\nall-smi 프로젝트는 Apache License 2.0으로 공개 및 배포되고 있습니다. 상업적 이용에 제한이 없습니다.\nall-smi GitHub 저장소\ngithub.com\nGitHub - inureyes/all-smi: Command-line utility for monitoring GPU hardware.\nCommand-line utility for monitoring GPU hardware.\n\n\n이 글은 GPT 모델로 정리한 글을 바탕으로 한 것으로, 원문의 내용 또는 의도와 다르게 정리된 내용이 있을 수 있습니다. 관심있는 내용이시라면 원문도 함께 참고해주세요! 읽으시면서 어색하거나 잘못된 내용을 발견하시면 덧글로 알려주시기를 부탁드립니다.\n파이토치 한국 사용자 모임이 정리한 이 글이 유용하셨나요? 회원으로 가입하시면 주요 글들을 이메일로 보내드립니다! (기본은 Weekly지만 Daily로 변경도 가능합니다.)\n아래쪽에 좋아요를 눌러주시면 새로운 소식들을 정리하고 공유하는데 힘이 됩니다~",
        "date": "2025-08-16",
        "source": "파이토치 한국 사용자 모임",
        "category": "기술"
    },
    {
        "title": "DINOv3: 자기 지도 학습(SSL)을 활용한 초대규모의 범용 비전 백본(Vision Backbone) 모델(feat. Meta AI)",
        "url": "https://discuss.pytorch.kr/t/dinov3-ssl-vision-backbone-feat-meta-ai/7495",
        "content": "DINOv3 소개\nDINOv3는 Meta AI가 개발한 차세대 자기지도학습(Self-Supervised Learning, SSL) 기반 비전 모델로, 대규모 이미지 데이터에서 범용적으로 활용 가능한 고성능 시각 백본(vision backbone)을 제공합니다. 기존의 강력한 이미지 인코딩 모델들이 웹 캡션 같은 사람 손으로 작성된 메타데이터에 의존했던 것과 달리, DINOv3는 전혀 라벨이 없는 상태에서 이미지 데이터로부터 의미있는 시각 표현을 스스로 학습하는 자기 지도 학습(Self-Supervised Learning, SSL) 기반의 비전 모델입니다.이를 통해 라벨 수집이 어렵거나 불가능한 분야에서도 대규모 학습이 가능해졌습니다.\n특히, DINOv3는 다양한 이미지 도메인에 걸쳐 범용적으로 사용 가능한 백본을 제공함으로써, 웹 이미지뿐만 아니라 위성, 의료, 산업용 이미지를 포함한 다양한 도메인에서 활용할 수 있으며, 이미지 분류, 객체 탐지, 시맨틱 분할, 비디오 객체 추적 등 폭넓은 비전 작업에서 최첨단 성능을 기록합니다. 17억 장의 이미지와 최대 70억 개의 파라미터로 학습하여 단일 백본으로도 밀집 예측(dense prediction) 작업에서 전문 모델을 초월하는 결과를 보여줍니다.\nDINO 계열 모델과 자기 지도 학습(SSL)의 흐름\nDINO는 2021년 공개된 첫 버전부터 Vision Transformer(ViT)를 기반으로, 학습자(학생)-참조자(교사)의 지식 증류(distillation) 메커니즘을 활용해 자기 지도 학습을 구현해왔습니다. DINOv2에서는 이미지 표현 학습을 보다 정제된 이미지 셋에서 수행하면서 범용성과 정확도를 개선했고, DINOv3는 이를 계승하여 더욱 큰 스케일과 강력한 백본으로 성능을 극대화한 버전입니다.\nDINOv2도 자기지도학습 기반으로 높은 성능을 보여줬지만, DINOv3는 이를 한층 발전시켜 더 큰 모델 규모(7B 파라미터)와 12배 더 큰 학습 데이터셋을 사용했습니다. 성능 면에서도, 특히 시맨틱 분할, 객체 탐지, 깊이 추정 같은 밀집 예측 작업에서 DINOv2 대비 월등히 향상되었습니다.\n또한 DINOv3는 CLIP 기반 모델(SigLIP 2, Perception Encoder 등)과 비교 시 다양한 이미지 분류 벤치마크에서 동등하거나 그 이상을 기록하며, 밀집 예측에서는 압도적인 우위를 보입니다. DINOv3는 라벨 없는 상태에서 학습했음에도, 라벨이 있는 약지도(weakly supervised) 모델보다 성능이 더 높다는 점이 특징입니다.\nDINO 계열 모델들의 핵심은, 텍스트나 외부 라벨 없이 이미지 자체만으로도 강력한 표현을 학습할 수 있다는 점입니다. CLIP과 같은 텍스트-이미지 쌍 기반 모델과는 달리, DINO는 오직 이미지 간 유사도와 구조만으로 시각적 의미를 파악하고 학습합니다. 이를 위해서는 모델 아키텍처와 학습 기법 모두에서 섬세한 설계가 요구됩니다.\nDINOv3 아키텍처 구성\nDINOv3는 Vision Transformer(ViT)와 ConvNeXt 두 가지 백본 구조를 지원하며, 그 중에서도 ViT 기반이 주류입니다. 특히 ViT-g/14 모델은 약 70억 개의 파라미터를 가지며, 이는 ViT-H/14보다도 크고 CLIP ViT 모델을 능가하는 스케일입니다.\n교사-학생 구조\n학생(Student) 네트워크는 인코딩하고자 하는 입력 이미지를 다양한 증강 방식으로 변형된 뷰(views)로 처리합니다.\n교사(Teacher) 네트워크는 EMA(Exponential Moving Average)를 통해 학생 네트워크의 가중치로부터 업데이트되며, 직접 학습되지 않습니다.\nLoss는 서로 다른 뷰들 간의 예측 일관성을 최대화하도록 설계됩니다. 이는 서로 다른 증강 이미지를 같은 것으로 인식하도록 모델이 스스로 학습하게 합니다.\n입력 증강 및 멀티크롭 전략\n입력 이미지는 다양한 해상도와 위치로 잘라진 여러 crop(예: 224×224, 96×96)으로 생성됩니다.\n교사는 대형 crop만 사용하고, 학생은 대형 및 소형 crop을 함께 사용하여 더욱 강건한 표현을 유도합니다.\n이러한 멀티크롭(multicropping)은 모델이 다양한 공간 및 시각 스케일에서 일관된 표현을 학습하도록 도와줍니다.\nMLP Head\n각 백본 출력 후에는 MLP 헤드가 붙어, 최종적으로 표현(feature embedding)을 생성합니다.\n이 표현은 downstream task (분류, 분할 등)에 그대로 활용될 수 있습니다.\nMLP 헤드는 교사-학생 간 출력을 정렬시키는 핵심 위치입니다.\n학습 방식과 최적화 전략\n대규모 비지도 학습\nDINOv3는 17억 개의 웹 이미지로 학습되었습니다. 이 이미지들은 라벨이 없으며, CLIP의 사전학습 이미지보다 4배 많고 품질도 뛰어납니다. 또한 단일 GPU로는 학습이 불가능하며, 대규모 클러스터에서 수 주간 학습됩니다.\n성능을 끌어올린 최적화 기법\nSharpness-Aware Minimization(SAM) 기법이 적용되어, 일반적인 SGD나 Adam보다 일반화 성능이 뛰어납니다.\nEMA decay 파라미터 조정으로 학생-교사 간 동기화를 세밀히 조절합니다.\nCosine similarity loss 및 centering 기법을 통해 출력의 다양성과 안정성을 동시에 확보합니다.\nDINOv3의 주요 특징\n자기지도학습(SSL)과 대규모 학습: DINOv3의 핵심은 대규모 라벨 없는 데이터로부터 범용 시각 표현을 학습하는 능력입니다. 이를 통해 위성 이미지, 의료 영상, 산업용 데이터 등 라벨링이 어려운 데이터셋에서도 고성능 모델을 만들 수 있습니다. 예를 들어, 위성 이미지 기반 숲 캐노피 높이 추정에서 DINOv2 대비 오차를 4.1m → 1.2m로 줄였습니다.\n파인튜닝 없이도 최첨단 성능: DINOv3는 백본 가중치를 고정(frozen)한 상태에서도 객체 탐지, 시맨틱 분할, 깊이 추정 같은 핵심 비전 작업에서 최첨단 성능을 기록합니다. 이는 다양한 애플리케이션에서 동일한 백본을 공유할 수 있어, 엣지 디바이스나 멀티태스크 환경에서 연산 효율성을 극대화합니다.\n다양한 모델 크기 제공: Meta는 7B 모델뿐만 아니라, 경량화된 ViT-B, ViT-L, ConvNeXt(T/S/B/L) 구조로도 DINOv3를 distillation하여 공개했습니다. 이를 통해 모바일·임베디드 환경 등 자원 제약이 있는 환경에서도 활용할 수 있습니다.\n실제 활용 사례\n세계자원연구소(WRI): 위성 이미지로 산림 훼손과 토지 이용 변화를 감지, 탄소 복원 프로젝트의 검증 및 자금 지원을 효율화합니다. (더 자세히 보기)\nNASA JPL: DINO 백본을 활용한 화성 탐사 로봇의 멀티태스크 비전 인식에 활용합니다. (더 자세히 보기)\nOrakl Oncology: DINO를 장기유사체 이미지로 사전 훈련시켜, 암 치료에 대한 환자 반응 예측을 지원하는 기반 모델을 생성합니다. (더 자세히 보기)\n라이선스\nDINOv3 모델은 Commercial License로 공개 및 배포되고 있습니다. 상업적 사용이 가능하지만, 세부 조건은 라이선스 문서를 반드시 확인해야 합니다.\nDINOv3 공식 홈페이지\nAI at Meta\nDINOv3\nDINOv3 scales self-supervised learning (SSL) for images to produce our strongest universal vision backbones, enabling breakthrough performance across diverse domains.\nMeta AI의 DINOv3 공개 블로그\nMeta AI\nDINOv3: Self-supervised learning for vision at unprecedented scale\nDINOv3 scales self-supervised learning for images to create universal vision backbones that achieve absolute state-of-the-art performance across diverse domains, including web and satellite imagery.\nDINOv3 논문\narXiv.org\nDINOv3\nSelf-supervised learning holds the promise of eliminating the need for manual data annotation, enabling models to scale effortlessly to massive datasets and larger architectures. By not being tailored to specific tasks or domains, this training...\nDINOv3 GitHub 저장소\ngithub.com\nGitHub - facebookresearch/dinov3: Reference PyTorch implementation and models for...\nReference PyTorch implementation and models for DINOv3\nDINOv3 모델 다운로드\nhuggingface.co\nDINOv3 - a facebook Collection\nDINOv3: foundation models producing excellent dense features, outperforming SotA w/o fine-tuning - https://arxiv.org/abs/2508.10104\n\n\n이 글은 GPT 모델로 정리한 글을 바탕으로 한 것으로, 원문의 내용 또는 의도와 다르게 정리된 내용이 있을 수 있습니다. 관심있는 내용이시라면 원문도 함께 참고해주세요! 읽으시면서 어색하거나 잘못된 내용을 발견하시면 덧글로 알려주시기를 부탁드립니다.\n파이토치 한국 사용자 모임이 정리한 이 글이 유용하셨나요? 회원으로 가입하시면 주요 글들을 이메일로 보내드립니다! (기본은 Weekly지만 Daily로 변경도 가능합니다.)\n아래쪽에 좋아요를 눌러주시면 새로운 소식들을 정리하고 공유하는데 힘이 됩니다~",
        "date": "2025-08-16",
        "source": "파이토치 한국 사용자 모임",
        "category": "기술"
    },
    {
        "title": "ECA(Editor Code Assistant): 다양한 코드 편집기를 지원하는 오픈소스 AI Pair Programming 도구",
        "url": "https://discuss.pytorch.kr/t/eca-editor-code-assistant-ai-pair-programming/7491",
        "content": "ECA 소개\nECA(Editor Code Assistant)는 다양한 코드 편집기와 대형 언어 모델(LLM)을 연결해주는 오픈소스 툴로, AI 기반 페어 프로그래밍을 보다 간편하게 경험할 수 있도록 설계되었습니다. 이 프로젝트의 가장 큰 특징은 에디터에 종속되지 않는 통합 프로토콜을 제공한다는 점입니다. 이를 통해 Emacs, VSCode, Vim 등 다양한 편집기에서 동일한 환경과 기능을 구현할 수 있습니다. ECA는 LSP(Language Server Protocol)에서 영감을 받아 설계되었으며, 서버-클라이언트 구조를 기반으로 합니다.\nLLM 기술 발전이 가속화되면서 모델 간 성능 격차는 점차 줄어드는 반면, 개발자가 편리하게 코드를 작성하고 변경 사항을 계획할 수 있는 **사용자 경험(UX)**의 중요성은 더욱 커지고 있습니다. ECA는 바로 이 UX 향상을 위해, 편집기 개발자가 모델 연동과 같은 복잡한 구현 대신 UI/UX에 집중할 수 있는 환경을 제공합니다.\n또한, 단일 설정 파일을 통해 전역 혹은 로컬에서 동일한 환경을 구성할 수 있으며, OpenAI, Anthropic, Ollama와 같은 다양한 모델을 동시에 사용할 수 있습니다. 이를 통해 사용자는 프로젝트 요구사항과 개인 선호에 맞춰 유연하게 모델을 선택하고 조합할 수 있습니다.\nECA는 GitHub Copilot이나 Cursor 등 특정 에디터에 종속된 AI 코드 도우미와 달리, **편집기 비종속성(editor-agnostic)**을 핵심 가치로 삼습니다. 예를 들어, GitHub Copilot은 VSCode, JetBrains IDE 중심으로 동작하지만, ECA는 Emacs, VSCode, Vim뿐 아니라 앞으로 Intellij 등 다른 에디터로도 확장될 계획입니다. 또한, LSP처럼 표준화된 통신 프로토콜을 적용하여 신규 에디터 통합 시 최소한의 개발로 빠르게 연동할 수 있습니다.\n또한 ECA는 단순히 코드 자동완성에 그치지 않고, 채팅 기반 상호작용, 도구 호출 관리, 다중 모델 지원, 맥락 정보 제공 등 LLM 활용의 확장성을 극대화할 수 있는 기능을 제공합니다. 이 점에서 단일 모델 기반 도구보다 훨씬 유연하고 확장성 있는 아키텍처를 갖추고 있습니다.\nECA의 주요 기능\n편집기에 종속되지 않는 프로토콜(Editor-agnostic Protocol): ECA는 모든 편집기에서 동일한 UX를 제공하기 위해 자체 정의한 통신 프로토콜을 사용합니다. 이는 LSP와 유사하게 표준화된 방식으로 서버와 편집기가 stdin/stdout을 통해 데이터를 교환하도록 설계되었습니다. 덕분에 새로운 에디터가 추가되더라도 복잡한 수정 없이 쉽게 통합할 수 있습니다.\n단일 설정 관리(Single configuration): 사용자는 .eca/config.json 파일에 API 키와 모델 정보를 입력하여 환경을 설정할 수 있습니다. 이 파일은 프로젝트 루트나 전역 설정 경로에 위치할 수 있으며, OpenAI, Anthropic, Ollama, 그리고 사용자 정의 모델까지 모두 지원합니다. 설정은 다음과 같은 방식으로 구성됩니다:\n{\n  \"openaiApiKey\": \"your-openai-api-key-here\",\n  \"anthropicApiKey\": \"your-anthropic-api-key-here\"\n}\n채팅 기반 상호작용: ECA는 코드 작성 중 질문, 코드 리뷰, 리팩토링 제안 등을 채팅 형태로 지원합니다. 사용자는 마치 동료 개발자와 협업하듯 LLM과 대화하며 개발을 진행할 수 있습니다.\n다중 모델 및 컨텍스트 지원: ECA는 하나의 세션에서 여러 LLM 모델을 사용할 수 있으며, 프로젝트 코드나 MCP(Model Context Protocol) 리소스, 사용자 정의 프롬프트 등을 포함해 풍부한 컨텍스트를 LLM에 전달할 수 있습니다. 이를 통해 답변 품질과 코드 추천의 정확도를 높일 수 있습니다.\nECA 설치 및 시작\n편집기용 플러그인을 설치하면 ECA 서버가 자동으로 다운로드 및 실행됩니다.\nEmacs 플러그인\nVSCode 확장\nVim 플러그인\nIntellij 지원 예정\n.eca/config.json에 모델 설정을 추가합니다.\n편집기 내 채팅 인터페이스를 통해 바로 AI 코딩 지원을 시작할 수 있습니다.\n라이선스\nECA 프로젝트는 Apache License 2.0으로 공개 및 배포되고 있습니다. 상업적 사용에 제한이 없습니다.\nECA 프로젝트 공식 홈페이지\neca.dev\nOverview - ECA - Editor Code Assistant\nECA - AI pair programming capabilities in any editor\nECA 프로젝트 GitHub 저장소\ngithub.com\nGitHub - editor-code-assistant/eca: Editor Code Assistant (ECA) - AI pair programming...\nEditor Code Assistant (ECA) - AI pair programming capabilities agnostic of editor\n\n\n이 글은 GPT 모델로 정리한 글을 바탕으로 한 것으로, 원문의 내용 또는 의도와 다르게 정리된 내용이 있을 수 있습니다. 관심있는 내용이시라면 원문도 함께 참고해주세요! 읽으시면서 어색하거나 잘못된 내용을 발견하시면 덧글로 알려주시기를 부탁드립니다.\n파이토치 한국 사용자 모임이 정리한 이 글이 유용하셨나요? 회원으로 가입하시면 주요 글들을 이메일로 보내드립니다! (기본은 Weekly지만 Daily로 변경도 가능합니다.)\n아래쪽에 좋아요를 눌러주시면 새로운 소식들을 정리하고 공유하는데 힘이 됩니다~",
        "date": "2025-08-15",
        "source": "파이토치 한국 사용자 모임",
        "category": "기술"
    },
    {
        "title": "Anthropic의 Claude 4 Sonnet 모델이 1백만 토큰(1M tokens)의 컨텍스트 지원",
        "url": "https://discuss.pytorch.kr/t/anthropic-claude-4-sonnet-1-1m-tokens/7489",
        "content": "Claude Sonnet 4의 1M Context Window 소개\nAnthropic이 자사의 언어 모델 Claude Sonnet 4에 1백만 토큰 규모의 콘텍스트 윈도우를 도입했습니다. 이는 이전 대비 5배 이상 향상된 수치로, 이제 개발자나 연구자들은 수십 개의 논문, 대규모 코드베이스 전체, 방대한 문서 집합을 한 번의 요청으로 처리할 수 있습니다. 이러한 기능 확장은 자연어 처리(NLP) 및 AI 모델 활용에 있어 매우 실질적인 전환점을 의미합니다.\n기존의 대부분 언어 모델은 수만 개 수준의 토큰 콘텍스트만 지원했기 때문에, 대규모 데이터를 다루는 데 있어 제한적이었습니다. 특히 긴 코드를 다루거나 문서 간의 상호 연관성을 파악해야 할 때, 콘텍스트 제한으로 인한 정보 손실이나 문맥 부재 문제가 자주 발생했습니다. 하지만 1백만 토큰 지원은 이러한 한계를 근본적으로 해소하며, AI 모델이 전반적인 시스템 구조를 보다 깊이 이해하도록 돕습니다.\n이번 발표는 Anthropic API 및 Amazon Bedrock을 통해 퍼블릭 베타로 제공되고 있으며, 곧 Google Cloud의 Vertex AI에서도 사용할 수 있도록 확장될 예정입니다. 모델의 콘텍스트 한계가 늘어나면서, 보다 현실적인 엔지니어링 워크플로우가 가능해졌고, 이를 활용한 다양한 사례도 함께 소개되었습니다.\n확장된 Context Window로는 무엇을 할 수 있나요?\n대규모 코드 분석: 1백만 토큰 지원은 전체 소스코드, 테스트 파일, 문서 등을 한 번에 로딩하고 분석하는 데 유리합니다. Claude는 코드 간의 의존 관계를 파악하고 프로젝트 전체의 아키텍처를 이해한 상태에서 개선 방향을 제안할 수 있습니다. 예전에는 파일별로 분할하여 처리하고, 모델에게 반복적으로 맥락을 제공해야 했다면 이제는 이 과정을 대폭 줄일 수 있습니다.\n문서 통합 및 요약: 수백 개에 달하는 법률 문서, 연구 논문, 기술 명세서도 한 번의 요청으로 통합 분석이 가능합니다. Claude는 이들 문서 간의 연관성과 흐름을 유지한 채, 보다 일관된 해석과 분석을 제공할 수 있습니다. 복잡한 문서 간의 연관성 분석이 필요한 분야에서 매우 유용하게 사용될 수 있습니다.\n콘텍스트를 유지하는 에이전트 구축: 에이전트 기반 시스템에서는 수많은 도구(tool) 호출과 멀티스텝 워크플로우가 필요한데, 이때 이전 대화 내역과 API 문서, 도구 정의 등을 모두 기억하는 것이 중요합니다. 1백만 토큰 콘텍스트는 이 모든 정보를 한 번에 포함하여, 더욱 일관되고 지능적인 대화를 유지할 수 있게 해줍니다.\n가격 정책 및 최적화 팁\n1백만 토큰 처리에는 많은 계산 자원이 필요하기 때문에, 200K 토큰을 초과한 요청부터는 가격이 상승합니다. 예를 들어, 200K 이하 요청은 입력 기준 1백만 토큰(1MTok)당 $3, 출력을 기준으로는 $15이며, 200K 초과 시에는 각각 $6, $22.5로 책정됩니다.\n하지만 프롬프트 캐싱이나 배치 처리를 활용하면 비용과 지연시간을 절감할 수 있습니다. 특히 배치 처리 시 최대 50%까지 절감 효과를 얻을 수 있어, 대규모 작업에서 효율적인 전략이 될 수 있습니다.\n고객 사례 소개\nBolt.new: 웹 기반 개발 플랫폼 Bolt.new는 Claude Sonnet 4를 코드 생성 워크플로우에 적극 활용하고 있습니다. CEO인 Eric Simons는 “1M 콘텍스트 윈도우 덕분에 훨씬 더 큰 프로젝트를 정확하게 처리할 수 있게 되었다”며 실사용 성과를 강조합니다. Claude는 생산 환경에서 여타 모델보다 높은 정확도를 보이고 있다고 합니다.\niGent AI: 런던의 iGent AI는 ‘Maestro’라는 AI 코딩 파트너를 통해 실제 대규모 코드베이스를 며칠간 지속적으로 다루는 기능을 구현했습니다. 이들은 Claude Sonnet 4가 “자율적인 소프트웨어 엔지니어링의 새로운 패러다임”을 가능하게 한다고 평가하고 있습니다.\nClaude Sonnet 4 1M 콘텍스트 발표 블로그\nanthropic.com\nClaude Sonnet 4 now supports 1M tokens of context\nClaude Sonnet 4 now supports up to 1 million tokens of context on the Anthropic API—a 5x increase.\n\n\n이 글은 GPT 모델로 정리한 글을 바탕으로 한 것으로, 원문의 내용 또는 의도와 다르게 정리된 내용이 있을 수 있습니다. 관심있는 내용이시라면 원문도 함께 참고해주세요! 읽으시면서 어색하거나 잘못된 내용을 발견하시면 덧글로 알려주시기를 부탁드립니다.\n파이토치 한국 사용자 모임이 정리한 이 글이 유용하셨나요? 회원으로 가입하시면 주요 글들을 이메일로 보내드립니다! (기본은 Weekly지만 Daily로 변경도 가능합니다.)\n아래쪽에 좋아요를 눌러주시면 새로운 소식들을 정리하고 공유하는데 힘이 됩니다~",
        "date": "2025-08-15",
        "source": "파이토치 한국 사용자 모임",
        "category": "기술"
    },
    {
        "title": "YAMS: LLM 및 다양한 애플리케이션을 위한 영구 메모리 시스템 (Yet Another Memory System)",
        "url": "https://discuss.pytorch.kr/t/yams-llm-yet-another-memory-system/7486",
        "content": "YAMS 소개\nYAMS(Yet Another Memory System)는 대규모 언어 모델(LLM)과 다양한 애플리케이션을 위한 영구 메모리 시스템입니다. 단순한 데이터 저장소가 아니라, 콘텐츠 주소 기반 저장(content-addressed storage), 중복 제거(deduplication), 의미 기반 검색(semantic search), 그리고 전체 텍스트 인덱싱(full-text indexing) 기능을 통합적으로 제공합니다. 이를 통해 LLM이 세션 간에 맥락을 유지하거나, 개발자가 프로젝트별 지식 베이스를 구성하는 데 최적화되어 있습니다.\nYAMS의 핵심은 SHA-256 기반 콘텐츠 주소화를 통해 데이터 무결성을 보장하고, Rabin fingerprinting으로 블록 단위 중복 제거를 수행하며, Zstandard와 LZMA 압축 방식을 지능적으로 적용하여 저장 효율을 극대화하는 데 있습니다. 검색 기능은 SQLite FTS5를 통한 전체 텍스트 검색과 벡터 임베딩을 활용한 의미 기반 검색을 모두 지원하여 단순 키워드 매칭 이상의 결과를 제공합니다. 또한 쓰기 전 로그(write-ahead logging)를 통해 장애 상황에서도 안정적으로 복구 가능하며, 멀티스레드 환경에서도 100MB/s 이상의 고성능 처리를 구현합니다.\n특히 YAMS는 LLM 환경에서의 문맥 기억 및 데이터 재활용을 염두에 두고 설계되었습니다. 예를 들어, 개발자가 이전 코드 변경 내역, 대화 맥락, 외부 문서 등을 저장해두고 필요할 때 즉시 검색·활용할 수 있습니다. 이러한 특성은 대규모 AI 모델을 활용한 개발 워크플로우에서 매우 유용합니다.\nYAMS는 Git이나 일반 문서 검색 시스템과 비교했을 때 다음과 같은 차별성이 있습니다:\nGit과 비교: Git은 소스 코드 버전 관리에 특화되어 있으며, 주로 텍스트 파일의 변경 이력을 추적합니다. 반면 YAMS는 다양한 형식의 데이터를 저장할 수 있으며, 의미 기반 검색과 중복 제거, 압축, PDF 텍스트 추출 등 데이터 관리에 필요한 다양한 기능을 제공합니다.\n일반 검색 엔진과 비교: Elasticsearch, Lucene 같은 검색 시스템은 강력한 검색 기능을 제공하지만, 콘텐츠 주소 기반 저장과 블록 단위 중복 제거, LLM 친화적 CLI 및 파이프라인 통합 기능은 기본적으로 제공하지 않습니다.\n기존 파일 저장소와 비교: 단순한 파일 서버나 클라우드 스토리지와 달리 YAMS는 검색·저장·관리·통합까지 하나의 CLI/TUI 및 API에서 모두 수행할 수 있습니다.\nYAMS의 주요 특징\n기본 사용법\n저장: 표준 입력(stdin)이나 파일을 받아 SHA-256 해시 기반으로 저장\n검색: 키워드 검색, 의미 검색, 퍼지(fuzzy) 매칭 지원\n목록 출력: JSON, 테이블, 최소 출력 포맷 지원\n문서 조회: 해시 기반 즉시 조회, 파일로 저장 또는 파이프 처리 가능\nTUI 브라우저: yams browse 명령어로 인터랙티브 탐색 지원\nLLM 통합\nLLM 환경에서는 대화 맥락, 코드 변경, 연구 자료, 외부 문서 등을 YAMS에 저장하고 필요 시 검색·재사용할 수 있습니다. 특히 Claude Desktop과 같은 MCP(Model Context Protocol) 호환 클라이언트와의 통합 기능을 제공합니다.\n성능 최적화\n환경 변수를 통해 청크 크기(YAMS_CHUNK_SIZE), 캐시 크기(YAMS_CACHE_SIZE), 압축 방식(YAMS_COMPRESSION) 등을 조정할 수 있어 대용량 파일 처리와 메모리 사용량을 상황에 맞게 최적화할 수 있습니다.\n라이선스\nYAMS 프로젝트는 Apache-2.0 라이선스로 공개 및 배포되고 있습니다. 상업적 사용에 제한이 없습니다.\nYAMS 프로젝트 GitHub 저장소\ngithub.com\nGitHub - trvon/yams: Content addressable storage with excellent search\nContent addressable storage with excellent search\n\n\n이 글은 GPT 모델로 정리한 글을 바탕으로 한 것으로, 원문의 내용 또는 의도와 다르게 정리된 내용이 있을 수 있습니다. 관심있는 내용이시라면 원문도 함께 참고해주세요! 읽으시면서 어색하거나 잘못된 내용을 발견하시면 덧글로 알려주시기를 부탁드립니다.\n파이토치 한국 사용자 모임이 정리한 이 글이 유용하셨나요? 회원으로 가입하시면 주요 글들을 이메일로 보내드립니다! (기본은 Weekly지만 Daily로 변경도 가능합니다.)\n아래쪽에 좋아요를 눌러주시면 새로운 소식들을 정리하고 공유하는데 힘이 됩니다~",
        "date": "2025-08-14",
        "source": "파이토치 한국 사용자 모임",
        "category": "기술"
    },
    {
        "title": "BMad-Method: AI 중심의 애자일 개발 방식을 진환시킨 범용 AI 에이전트 프레임워크",
        "url": "https://discuss.pytorch.kr/t/bmad-method-ai-ai/7481",
        "content": "BMad-Method 소개\nBMad-Method는 “Breakthrough Method of Agile AI-Driven Development”라는 이름에서도 알 수 있듯이, AI 중심의 애자일 개발 방식을 한 단계 진화시킨 범용 AI 에이전트 프레임워크입니다. 단순한 작업 지시 도구나 태스크 러너가 아니라, 기획(Planning)과 개발(Development) 두 단계를 AI 에이전트로 체계화하여, 소프트웨어 개발뿐 아니라 창작, 비즈니스 전략, 개인 건강 관리 등 다양한 분야에 적용할 수 있습니다.\nBMad-Method 프레임워크의 핵심 가치는 두 가지 혁신에서 나옵니다:\n첫째, Agentic Planning은 분석가(Analyst), 프로젝트 매니저(PM), 아키텍트(Architect) 등 역할을 가진 AI 에이전트들이 협업하여, 일관성 있고 완전한 PRD(제품 요구 사항 문서)와 아키텍처 문서를 생성합니다.\n둘째, Context-Engineered Development에서는 스크럼 마스터(SM) 에이전트가 이 기획 문서를 기반으로 개발자(Dev) 에이전트가 필요한 모든 컨텍스트와 구현 세부 사항을 포함한 개발 스토리를 생성합니다.\n이 접근 방식은 AI 보조 개발에서 가장 흔한 두 가지 문제인 기획 불일치와 컨텍스트 손실을 근본적으로 해결합니다. 개발자는 스토리 파일 하나만 열어도 ‘무엇을, 어떻게, 왜’ 만들어야 하는지를 완벽히 이해할 수 있게 됩니다.\nBMad-Method는 Node.js 환경에서 동작하며, 최소 버전 20 이상이 필요합니다. 커맨드라인 도구뿐 아니라 웹 UI를 통한 팀 구성, IDE 연계 개발, 확장팩을 통한 기능 확장 등 다양한 활용 방식을 지원합니다.\n일반적인 AI 작업 지시 도구(Taskmaster형 도구)는 사용자가 요청한 작업을 분할하여 처리하지만, 전 과정의 일관성과 세부 문맥을 유지하는 데 취약합니다. 반면, BMad-Method는 계획 단계에서의 완성도와 개발 단계에서의 정보 전달 방식에 집중하여, 처음부터 끝까지 동일한 컨텍스트를 유지합니다.\n또한, Git 기반 코드베이스 플래터너(Codebase Flattener) 기능을 내장해 AI가 프로젝트 전체를 이해할 수 있도록 XML 형식으로 변환하는 기능을 제공합니다. 이는 기존 단순 파일 업로드 방식보다 구조적이고 AI 친화적입니다.\nBMad-Method\nAgentic Planning\n다양한 전문 역할을 가진 AI 에이전트가 PRD와 아키텍처 문서 생성\n고급 프롬프트 엔지니어링과 사람의 개입(Human-in-the-loop)으로 품질 보장\n기획 단계에서 컨텍스트와 일관성을 확보\nContext-Engineered Development\n스크럼 마스터 에이전트가 개발자에게 필요한 모든 정보를 스토리 파일에 포함\n개발자가 파일 하나로 완전한 개발 환경 컨텍스트를 획득\nQA 에이전트와의 협업도 동일 컨텍스트 기반으로 진행\n설치 및 업데이트\nnpx bmad-method install\n# 또는 기존 설치 업데이트\ngit pull\nnpm run install:bmad\n기존 설정과 사용자 커스터마이징을 유지하면서 업데이트 가능\n변경된 파일만 교체하며 .bak 백업 생성\n확장팩(Expansion Packs)\n소프트웨어 개발 외 창작, 비즈니스, 교육, 건강 등 다양한 분야 지원\n맞춤형 AI 에이전트를 직접 제작 가능\n게임 개발, 인프라, DevOps 등 도메인별 예제 제공\n코드베이스 플래터너(Codebase Flattener)\n프로젝트 전체를 AI 최적화 XML로 변환\n.gitignore 기반 불필요 파일 제외\n바이너리 파일 자동 감지 및 제외\n실시간 진행 상황과 결과 통계 제공\nnpx bmad-method flatten\nnpx bmad-method flatten -i /path/to/source -o output.xml\n라이선스\nBMad-Method 프로젝트는 MIT License로 공개되어 있으며, 상업적 사용에 제한이 없습니다.\nBMad-Method 프로젝트 GitHub 저장소\ngithub.com\nGitHub - bmad-code-org/BMAD-METHOD: Breakthrough Method for Agile Ai Driven...\nBreakthrough Method for Agile Ai Driven Development\n\n\n이 글은 GPT 모델로 정리한 글을 바탕으로 한 것으로, 원문의 내용 또는 의도와 다르게 정리된 내용이 있을 수 있습니다. 관심있는 내용이시라면 원문도 함께 참고해주세요! 읽으시면서 어색하거나 잘못된 내용을 발견하시면 덧글로 알려주시기를 부탁드립니다.\n파이토치 한국 사용자 모임이 정리한 이 글이 유용하셨나요? 회원으로 가입하시면 주요 글들을 이메일로 보내드립니다! (기본은 Weekly지만 Daily로 변경도 가능합니다.)\n아래쪽에 좋아요를 눌러주시면 새로운 소식들을 정리하고 공유하는데 힘이 됩니다~",
        "date": "2025-08-13",
        "source": "파이토치 한국 사용자 모임",
        "category": "기술"
    },
    {
        "title": "Chrome MCP Server: 사용자의 Chrome 환경을 사용해 로그인 등의 설정을 유지하는 MCP Server",
        "url": "https://discuss.pytorch.kr/t/chrome-mcp-server-chrome-mcp-server/7472",
        "content": "Chrome MCP Server 소개\nChrome MCP Server는 Chrome 확장 프로그램 기반의 Model Context Protocol (MCP) 서버로, 사용자의 Chrome 브라우저 기능을 Claude 같은 AI 어시스턴트에 노출하여 고급 브라우저 자동화, 콘텐츠 분석, 시맨틱 검색 등을 가능하게 하는 도구입니다. 기존의 Playwright 같은 브라우저 자동화 도구와 달리, 사용자가 평소 쓰던 Chrome 환경(설정, 로그인 상태 등)을 그대로 활용합니다. 이를 통해 별도의 브라우저를 실행하거나 초기 세팅을 반복할 필요 없이, AI가 사용자의 실제 브라우저를 제어하며 개인 맞춤형 어시스턴트로 동작하게 할 수 있습니다.\n또한 이 MCP 서버는 완전 로컬 환경에서 동작하므로 개인 정보 보호 측면에서 안전합니다. 브라우저 탭 간 컨텍스트 공유, AI 기반의 텍스트 추출 및 유사도 분석, 스크린샷·네트워크 모니터링·북마크 관리 등 20개 이상의 고급 툴을 제공합니다. 특히 SIMD 기반 WebAssembly 최적화를 통해 벡터 연산 속도를 기존보다 4~8배 향상시킨 것이 특징입니다.\nChrome MCP Server는 현재 초기 단계이지만, 빠르게 기능이 확장되고 있으며 향후 인증 기능, 기록/재생, 워크플로우 자동화, Firefox 지원 등의 로드맵이 공개되어 있습니다.\nPlaywright 기반 MCP 서버와의 비교\n일반적인 Playwright 기반 MCP 서버는 별도의 브라우저 프로세스를 실행하고, 전용 브라우저 바이너리를 다운로드하며, 독립된 세션을 사용하기 때문에 사용자의 기존 로그인 상태나 환경이 반영되지 않습니다. 반면 Chrome MCP Server는 이미 열려 있는 Chrome 브라우저를 직접 활용해 환경 설정과 로그인 상태를 그대로 유지합니다.\n리소스 사용량: Playwright는 별도 프로세스 필요 / MCP Chrome은 기존 브라우저 사용\n세션 재사용: Playwright는 재로그인 필요 / MCP Chrome은 기존 로그인 상태 사용\n브라우저 환경: Playwright는 초기화된 환경 / MCP Chrome은 사용자의 설정 유지\nAPI 접근성: Playwright는 제한적 / MCP Chrome은 Chrome 네이티브 API 완전 활용 가능\n속도: Playwright는 50~200ms IPC / MCP Chrome은 더 빠름\n설치 및 사용 방법\n사전 요구 사항\nNode.js 18.19.0 이상\nChrome 또는 Chromium 브라우저\n설치 절차\nGitHub의 프로젝트 저장소에서 최신 확장 프로그램 다운로드:\nReleases · hangwin/mcp-chrome · GitHub\nmcp-chrome-bridge 전역 설치:\n# npm 사용 시 다음과 같이 설치가 가능합니다:\nnpm install -g mcp-chrome-bridge\n\n# pnpm 사용 시 다음과 같이 설치가 가능합니다:\npnpm config set enable-pre-post-scripts true\npnpm install -g mcp-chrome-bridge\nChrome 확장 프로그램 로드:\nchrome://extensions/ 접속 후 개발자 모드 활성화\n“압축해제된 확장 프로그램 로드” 클릭 후 다운로드 폴더 선택\nMCP 클라이언트와 연결: Streamable HTTP 방식 권장\n{\n  \"mcpServers\": {\n    \"chrome-mcp-server\": {\n      \"type\": \"streamableHttp\",\n      \"url\": \"http://127.0.0.1:12306/mcp\"\n    }\n  }\n}\nChrome MCP Server의 주요 기능 (tools)\n다음은 Chrome MCP Server가 제공하는 도구(tool)들입니다. 전체 도구 목록은 다음 링크를 참고해주세요.\n브라우저 관리: 탭/창 목록 조회, URL 이동, 탭 닫기, 뒤로/앞으로 이동, 스크립트 주입, 주입된 스크립트 제어\n시각화: 요소별·전체 페이지 스크린샷\n네트워크 모니터링: webRequest API, Debugger API, 사용자 지정 HTTP 요청\n콘텐츠 분석: 시맨틱 검색, HTML/텍스트 추출, 클릭 가능한 요소 탐색, 콘솔 로그 수집\n상호작용: 클릭, 폼 입력, 키보드 이벤트 시뮬레이션\n데이터 관리: 히스토리 검색, 북마크 검색·추가·삭제\n활용 예시\nAI가 웹페이지 내용을 요약하고 Excalidraw로 시각 자료 작성\n사용 프롬프트: excalidraw-prompt\n사용한 지시문: Help me summarize the current page content, then draw a diagram to aid my understanding.\nuse chrome-mcp to summarize web content and then draw with Excalidraw\n이미지 분석 후 동일 이미지 그리기\n사용 프롬프트: content-analize\n사용한 지시문: First, analyze the content of the image, and then replicate the image by combining the analysis with the content of the image.\nchrome-mcp分析完图片内容后画图\n광고 제거를 포함한 스타일 변경\n사용 프롬프트: modify-web-prompt\n사용한 지시문: Help me modify the current page's style and remove advertisements.\nuse chrome-mcp to modify web style\n네트워크 요청 캡처\n사용한 지시문: I want to know what the search API for Xiaohongshu is and what the response structure looks like\n使用chrome-mcp-server捕获网络请求\n브라우저 히스토리 분석\n사용한 지시문: Analyze my browsing history from the past month\n使用chrome-mcp-server分析你的浏览记录\n라이선스\nChrome MCP Server 프로젝트는 MIT 라이선스로 배포되며, 상업적 사용에 제한이 없습니다.\nChrome MCP Server 프로젝트 GitHub 저장소\ngithub.com\nGitHub - hangwin/mcp-chrome: Chrome MCP Server is a Chrome extension-based...\nChrome MCP Server is a Chrome extension-based Model Context Protocol (MCP) server that exposes your Chrome browser functionality to AI assistants like Claude, enabling complex browser automation, content analysis, and semantic search.\n더 읽어보기\nChrome for Developers\nChrome 확장 프로그램  |  Chrome Extensions  |  Chrome for...\nChrome 확장 프로그램 개발 방법을 알아보세요.\nModel Context Protocol\nIntroduction - Model Context Protocol\nGet started with the Model Context Protocol (MCP)\n\n\n이 글은 GPT 모델로 정리한 글을 바탕으로 한 것으로, 원문의 내용 또는 의도와 다르게 정리된 내용이 있을 수 있습니다. 관심있는 내용이시라면 원문도 함께 참고해주세요! 읽으시면서 어색하거나 잘못된 내용을 발견하시면 덧글로 알려주시기를 부탁드립니다.\n파이토치 한국 사용자 모임이 정리한 이 글이 유용하셨나요? 회원으로 가입하시면 주요 글들을 이메일로 보내드립니다! (기본은 Weekly지만 Daily로 변경도 가능합니다.)\n아래쪽에 좋아요를 눌러주시면 새로운 소식들을 정리하고 공유하는데 힘이 됩니다~",
        "date": "2025-08-12",
        "source": "파이토치 한국 사용자 모임",
        "category": "기술"
    },
    {
        "title": "AURA: 기계가 읽을 수 있는 웹(Machine-Readable Web)을 위한 프로토콜",
        "url": "https://discuss.pytorch.kr/t/aura-machine-readable-web/7467",
        "content": "AURA 프로토콜 소개\n**AURA (Agent-Usable Resource Assertion)**는 AI 에이전트가 웹사이트를 이해하고 조작할 수 있도록 설계된 오픈 프로토콜입니다. 현재 대부분의 AI 기반 웹 상호작용은 화면 스크래핑(screen scraping)이나 DOM 분석에 의존하지만, 이는 매우 취약하고 유지보수가 어렵습니다. 화면 배치가 조금만 변경되어도 동작이 깨지고, 다양한 사이트 간 HTML 구조 차이로 인해 코드 재사용이 어렵다는 문제가 있습니다. AURA는 이러한 문제를 해결하기 위해 웹사이트가 자신이 제공하는 기능을 **표준화된 manifest 파일(aura.json)**을 통해 명시적으로 선언하도록 합니다.\n즉, AI 에이전트가 웹사이트에서 “어떻게 글을 작성할지” 추측하는 대신, 해당 사이트가 “create_post라는 기능이 있으며, /api/posts로 HTTP POST 요청을 보내고 title과 content 파라미터를 받아야 한다”라고 직접 알려주는 구조입니다. 이는 ‘명령 기반 추측(imperative guessing)’에서 ‘선언적 상호작용(declarative interaction)’으로의 패러다임 전환입니다.\n이 프로젝트는 단순한 API 문서 이상의 역할을 합니다. AURA는 사이트의 상태(AURA-State 헤더)까지 정의해, 예를 들어 사용자가 로그인되어 있는지 여부나 현재 가능한 기능 목록을 실시간으로 에이전트에 전달할 수 있습니다. 이를 통해 AI와 웹 간의 상호작용이 더욱 안전하고 예측 가능해집니다.\n기존 방식과 AURA를 비교해 보면 다음과 같은 차이가 있습니다.\n화면 스크래핑(Screen Scraping)\n장점: 별도의 API 없이도 동작 가능\n단점: 속도 느림, 유지보수 비용 높음, UI 변경 시 즉시 중단\nDOM 분석(DOM Manipulation)\n장점: HTML 구조를 기반으로 직접 데이터 추출 가능\n단점: 사이트별 HTML 구조 차이로 범용성 낮음, 변경 취약\nAURA 프로토콜\n장점: 표준화된 manifest(aura.json)로 구조적 정보 제공, 사이트 상태 동기화 가능, 보안 및 제어 강화\n단점: 사이트 측에서 AURA 지원 구현 필요\n주요 내용\n핵심 개념\nManifest (aura.json) 각 사이트의 “AI 사용 설명서” 역할을 하며, /.well-known/aura.json 경로에서 제공됩니다.여기에는 가능한 모든 리소스와 기능이 정의됩니다.\nCapability AI 에이전트가 수행할 수 있는 개별 액션(예: list_posts, login, update_profile)을 의미합니다. 각 capability는 특정 HTTP 요청과 연결됩니다.\nState (AURA-State 헤더) 서버가 응답 시 동적으로 현재 사용자의 상태나 가능한 기능 목록을 제공하는 HTTP 헤더입니다.\n저장소 구성\npackages/aura-protocol: 핵심 TypeScript 인터페이스와 공식 JSON Schema를 포함한 NPM 패키지 (@aura/protocol).\npackages/reference-server: Next.js 기반 AURA 지원 서버 예제. 사이트를 AURA 호환으로 만드는 참고 자료.\npackages/reference-client: 브라우저나 확장 프로그램 없이 프로토콜을 소비할 수 있는 최소 백엔드 클라이언트 예제.\n설치 및 빠른 시작 예제\n의존성 설치\npnpm install\n레퍼런스 서버 실행\npnpm --filter aura-reference-server dev\n실행 후, 브라우저에서 http://localhost:3000/.well-known/aura.json 접속 시 manifest 확인 가능합니다.\n레퍼런스 에이전트 실행\n# OpenAI API 키를 .env 파일에 설정\npnpm --filter aura-reference-client agent -- http://localhost:3000 \"list all the blog posts\"\n크롤러 실행\npnpm --filter aura-reference-client crawler -- http://localhost:3000\n사이트의 가능한 기능을 구조화된 JSON으로 출력합니다.\n생태계 확장 가능성\nAURA의 미래 비전은 단순한 프로토콜 표준화에 그치지 않고, 다양한 웹 프레임워크(Express, Laravel, Django, Rails) 어댑터, 여러 언어(Python, Go, Rust, Java) 클라이언트, 그리고 지능형 애플리케이션으로 확장되는 것입니다.\n라이선스\nAURA 프로젝트는 MIT 라이선스로 공개되어 있으며, 상업적 사용에 제한이 없습니다.\nAURA 프로젝트 GitHub 저장소\ngithub.com\nGitHub - osmandkitay/aura: AURA (Agent-Usable Resource Assertion) is an open...\nAURA (Agent-Usable Resource Assertion) is an open protocol designed to make the web machine-readable. It replaces fragile screen scraping with a declarative aura.json manifest, allowing websites to expose their capabilities as a secure, efficient, and standardized API for AI agents.\n\n\n이 글은 GPT 모델로 정리한 글을 바탕으로 한 것으로, 원문의 내용 또는 의도와 다르게 정리된 내용이 있을 수 있습니다. 관심있는 내용이시라면 원문도 함께 참고해주세요! 읽으시면서 어색하거나 잘못된 내용을 발견하시면 덧글로 알려주시기를 부탁드립니다.\n파이토치 한국 사용자 모임이 정리한 이 글이 유용하셨나요? 회원으로 가입하시면 주요 글들을 이메일로 보내드립니다! (기본은 Weekly지만 Daily로 변경도 가능합니다.)\n아래쪽에 좋아요를 눌러주시면 새로운 소식들을 정리하고 공유하는데 힘이 됩니다~",
        "date": "2025-08-11",
        "source": "파이토치 한국 사용자 모임",
        "category": "기술"
    },
    {
        "title": "[2025/08/04 ~ 10] 이번 주에 살펴볼 만한 AI/ML 논문 모음",
        "url": "https://discuss.pytorch.kr/t/2025-08-04-10-ai-ml/7462",
        "content": "[2025/08/04 ~ 10] 이번 주에 살펴볼 만한 AI/ML 논문 모음\nPyTorchKR\n이번 주 선정된 논문들을 살펴보면, 첫째로 대규모 언어 모델(LLM)을 활용한 에이전트 시스템에서 비용 대비 성능 최적화에 대한 연구가 두드러집니다. 복잡한 다중 단계 작업을 수행하는 에이전트의 효율성을 높이면서도 운영 비용을 절감하려는 시도가 많으며, 이를 통해 AI 솔루션의 확장성과 접근성을 개선하려는 방향성이 명확합니다. 이는 산업 현장에서 AI 도입 시 현실적인 비용 문제를 해결하고, 보다 지속 가능한 AI 서비스 구축에 기여할 수 있는 중요한 연구 동향임을 보여줍니다.\n둘째로, 그래프 기반 지식 표현과 강화학습을 결합하여 에이전트의 추론 능력과 정보 검색 효율을 높이는 연구들이 눈에 띕니다. 단순한 텍스트 기반 검색을 넘어 엔티티와 관계를 구조화한 그래프 형태로 지식을 모델링하고, 이를 에이전트가 능동적으로 활용하도록 설계함으로써 복잡한 질의에 대한 정확도와 응답 품질을 향상시키고 있습니다. 이러한 접근은 에이전트가 더 깊이 있는 의미적 이해와 장기적 계획 수립을 가능하게 하여, AI의 지능적 상호작용 역량을 한층 강화하는 데 기여합니다.\n마지막으로, 다중 턴 대화에서의 도구 호출과 장기 기억 관리 문제를 해결하려는 연구가 활발합니다. 고정된 컨텍스트 윈도우의 한계를 극복하기 위해 단기 및 장기 기억을 효율적으로 관리하고, 동적으로 다양한 도구와 외부 API를 활용하는 에이전트 아키텍처가 제안되고 있습니다. 이는 실제 서비스 환경에서 사용자와의 지속적이고 복잡한 상호작용을 지원하며, 대규모 산업 시스템에서 낮은 지연 시간과 높은 신뢰성을 유지하는 데 필수적인 요소로 평가됩니다. 전반적으로 이번 주 논문들은 에이전트 AI가 실용적이고 확장 가능한 방향으로 진화하고 있음을 보여주고 있습니다.\n효율적인 에이전트: 비용 절감과 성능을 모두 갖춘 에이전트 설계 / Efficient Agents: Building Effective Agents While Reducing Cost\n논문 소개\n대규모 언어 모델(LLM) 기반 에이전트의 뛰어난 성능에도 불구하고 비용 증가가 확장성과 접근성을 저해하는 문제를 다루고 있습니다. 본 연구는 에이전트 시스템에서 효율성과 성능 간의 균형을 체계적으로 분석하며, 작업 복잡도, 추가 모듈의 효과 한계, 효율적인 프레임워크 설계가 비용 절감에 미치는 영향을 평가합니다. GAIA 벤치마크를 활용한 실험을 통해 LLM 백본 선택, 에이전트 프레임워크 구조, 테스트 시 확장 전략이 비용 대비 성능에 미치는 영향을 정량화하였습니다. 제안된 Efficient Agents 프레임워크는 기존 최고 수준의 오픈소스 에이전트 대비 약 3%의 성능 저하만으로 운영 비용을 28.4% 절감하여 비용 효율성을 크게 향상시켰습니다.\n논문 초록(Abstract)\n대규모 언어 모델(LLM) 기반 에이전트의 뛰어난 능력은 복잡하고 다단계 작업을 수행하는 정교한 시스템을 가능하게 했으나, 증가하는 비용은 확장성과 접근성을 위협하고 있습니다. 본 연구는 성능을 희생하지 않으면서 비용 효율적인 설계의 필요성을 해결하기 위해 현대 에이전트 시스템에서 효율성과 효과성 간의 상충관계에 대한 최초의 체계적인 연구를 제시합니다. 우리는 세 가지 핵심 질문을 탐구합니다: (1) 에이전트 작업이 본질적으로 요구하는 복잡성은 어느 정도인가? (2) 추가 모듈이 언제부터 수익 체감 현상을 보이는가? (3) 효율적인 에이전트 프레임워크 설계를 통해 얼마나 많은 효율성을 얻을 수 있는가? GAIA 벤치마크에 대한 실증 분석을 통해 LLM 백본 선택, 에이전트 프레임워크 설계, 테스트 시 확장 전략의 영향을 평가하였습니다. cost-of-pass 지표를 활용하여 이들 요소 간의 효율성-성능 상충관계를 정량화하였습니다. 연구 결과는 작업 요구사항에 최적화된 복잡도를 갖는 새로운 에이전트 프레임워크인 Efficient Agents 개발에 기여합니다. Efficient Agents는 대표적인 오픈소스 에이전트 프레임워크인 OWL의 성능을 96.7% 유지하면서 운영 비용을 $0.398에서 $0.228로 절감하여 cost-of-pass를 28.4% 개선하였습니다. 본 연구는 효율적이고 고성능의 에이전트 시스템 설계를 위한 실질적인 통찰을 제공하며, AI 기반 솔루션의 접근성과 지속 가능성 향상에 기여합니다.\nThe remarkable capabilities of Large Language Model (LLM)-driven agents have enabled sophisticated systems to tackle complex, multi-step tasks, but their escalating costs threaten scalability and accessibility. This work presents the first systematic study of the efficiency-effectiveness trade-off in modern agent systems, addressing the critical need for cost-effective designs without sacrificing performance. We investigate three key questions: (1) How much complexity do agentic tasks inherently require? (2) When do additional modules yield diminishing returns? (3) How much efficiency can be gained through the design of efficient agent frameworks? Through an empirical analysis on the GAIA benchmark, we evaluate the impact of LLM backbone selection, agent framework designs, and test-time scaling strategies. Using the cost-of-pass metric, we quantify the efficiency-performance trade-off across these dimensions. Our findings inform the development of Efficient Agents , a novel agent framework that has an optimal complexity to task requirements. Efficient Agents retains 96.7% of the performance of OWL, one leading open-source agent framework, while reducing operational costs from $0.398 to $0.228, resulting in a 28.4% improvement in cost-of-pass. Our work provides actionable insights for designing efficient, high-performing agent systems, advancing the accessibility and sustainability of AI-driven solutions.\n논문 링크\narXiv.org\nEfficient Agents: Building Effective Agents While Reducing Cost\nThe remarkable capabilities of Large Language Model (LLM)-driven agents have enabled sophisticated systems to tackle complex, multi-step tasks, but their escalating costs threaten scalability and accessibility. This work presents the first systematic...\n더 읽어보기\ngithub.com\nGitHub - OPPO-PersonalAI/OAgents: Implementation for OAgents: An Empirical Study of...\nImplementation for OAgents: An Empirical Study of Building Effective Agents\nGraph-R1: 종단 간 강화학습 기반 에이전트형 그래프RAG 프레임워크 연구 / Graph-R1: Towards Agentic GraphRAG Framework via End-to-end Reinforcement Learning\n논문 소개\nGraph-R1은 대규모 언어 모델(LLM)의 환각 문제를 완화하기 위해 외부 지식을 활용하는 기존 RAG(Retrieval-Augmented Generation) 방식의 한계를 극복하고자 제안된 강화학습 기반 에이전트형 그래프 RAG 프레임워크입니다. 이 방법은 경량화된 하이퍼그래프 지식 구조를 구축하고, 다회차 에이전트-환경 상호작용으로 검색 과정을 모델링하며, 보상 신호를 통한 종단간(end-to-end) 최적화를 수행합니다. 실험 결과, Graph-R1은 기존의 그래프 RAG 및 강화학습 적용 RAG 기법 대비 추론 정확도, 검색 효율성, 생성 품질에서 우수한 성능을 보였습니다.\n논문 초록(Abstract)\n검색-증강 생성(RAG)은 외부 지식을 통합하여 대규모 언어 모델(LLM)에서 발생하는 환각 현상을 완화하지만, 구조적 의미가 부족한 청크 기반 검색에 의존합니다. GraphRAG 방법은 지식을 개체-관계 그래프로 모델링하여 RAG를 개선하지만, 높은 구축 비용, 고정된 일회성 검색, 그리고 장기 문맥 추론 및 프롬프트 설계에 대한 의존성이라는 문제에 직면해 있습니다. 이러한 문제를 해결하기 위해, 본 논문에서는 종단 간 강화 학습(RL)을 활용한 에이전트 기반 GraphRAG 프레임워크인 Graph-R1을 제안합니다. Graph-R1은 경량 지식 하이퍼그래프 구축을 도입하고, 검색을 다회차 에이전트-환경 상호작용으로 모델링하며, 종단 간 보상 메커니즘을 통해 에이전트 프로세스를 최적화합니다. 표준 RAG 데이터셋에서의 실험 결과, Graph-R1은 기존 GraphRAG 및 RL 강화 RAG 방법들에 비해 추론 정확도, 검색 효율성, 생성 품질에서 우수한 성능을 보였습니다.\nRetrieval-Augmented Generation (RAG) mitigates hallucination in LLMs by incorporating external knowledge, but relies on chunk-based retrieval that lacks structural semantics. GraphRAG methods improve RAG by modeling knowledge as entity-relation graphs, but still face challenges in high construction cost, fixed one-time retrieval, and reliance on long-context reasoning and prompt design. To address these challenges, we propose Graph-R1, an agentic GraphRAG framework via end-to-end reinforcement learning (RL). It introduces lightweight knowledge hypergraph construction, models retrieval as a multi-turn agent-environment interaction, and optimizes the agent process via an end-to-end reward mechanism. Experiments on standard RAG datasets show that Graph-R1 outperforms traditional GraphRAG and RL-enhanced RAG methods in reasoning accuracy, retrieval efficiency, and generation quality.\n논문 링크\narXiv.org\nGraph-R1: Towards Agentic GraphRAG Framework via End-to-end Reinforcement...\nRetrieval-Augmented Generation (RAG) mitigates hallucination in LLMs by incorporating external knowledge, but relies on chunk-based retrieval that lacks structural semantics. GraphRAG methods improve RAG by modeling knowledge as entity-relation...\nTURA: 도구 보강 통합 검색 에이전트를 활용한 AI 검색 혁신 / TURA: Tool-Augmented Unified Retrieval Agent for AI Search\n논문 소개\n대형 언어 모델(LLM)을 활용한 기존의 검색 엔진은 주로 정적인 웹 문서 기반의 Retrieval-Augmented Generation(RAG) 방식을 사용하지만, 실시간 정보나 동적 데이터 처리에는 한계가 있습니다. TURA는 이러한 한계를 극복하기 위해 RAG와 에이전트 기반 도구 활용을 결합한 3단계 프레임워크로, 쿼리 분해 및 정보원 검색, DAG(유향 비순환 그래프) 기반 작업 계획, 경량화된 에이전트 실행기를 포함합니다. 이를 통해 정적 콘텐츠와 실시간 API, 데이터베이스 등 동적 정보원을 통합하여 대규모 산업 환경에서 저지연으로 실시간 응답을 제공합니다. TURA는 수천만 사용자에게 안정적이고 신속한 AI 검색 서비스를 제공하는 최초의 통합 아키텍처입니다.\n논문 초록(Abstract)\n대규모 언어 모델(LLM)의 출현은 주로 웹 코퍼스 기반의 검색-증강 생성(RAG)을 활용하여 검색 엔진을 대화형 AI 검색 제품으로 변화시키고 있습니다. 그러나 이러한 패러다임은 산업적 측면에서 중요한 한계를 지니고 있습니다. 전통적인 RAG 접근법은 실시간 요구사항과 티켓 가용성 또는 재고와 같이 동적으로 생성되는 콘텐츠에 접근해야 하는 구조화된 쿼리에 대응하는 데 어려움을 겪습니다. 정적인 페이지 인덱싱에 한정된 검색 엔진은 이러한 시의성 있는 데이터에 필요한 상호작용 쿼리를 수행할 수 없습니다. 학계 연구는 정적 콘텐츠에 최적화된 RAG에 집중해 왔으며, 복잡한 의도와 데이터베이스 및 실시간 API와 같은 동적 소스의 필요성은 간과되어 왔습니다. 이러한 격차를 해소하기 위해, 본 논문에서는 정적 콘텐츠와 동적 실시간 정보를 모두 활용할 수 있도록 RAG와 에이전트 기반 도구 사용을 결합한 새로운 3단계 프레임워크인 TURA(도구 증강 통합 검색 에이전트)를 제안합니다. TURA는 세 가지 핵심 구성 요소로 이루어져 있습니다: 쿼리를 분해하고 Model Context Protocol(MCP) 서버로 캡슐화된 정보 소스를 검색하는 의도 인식 검색 모듈, 작업 의존성을 방향성 비순환 그래프(DAG)로 모델링하여 최적의 병렬 실행을 지원하는 DAG 기반 작업 계획자, 그리고 효율적인 도구 호출을 위한 경량화된 증류 에이전트 실행기입니다. TURA는 정적 RAG와 동적 정보 소스 간의 격차를 체계적으로 연결한 최초의 아키텍처로서, 세계적 수준의 AI 검색 제품을 구현합니다. 수천만 명의 사용자에게 서비스를 제공하며, 에이전트 기반 프레임워크를 활용해 대규모 산업 시스템의 저지연 요구를 충족하면서도 견고하고 실시간 응답을 제공합니다.\nThe advent of Large Language Models (LLMs) is transforming search engines into conversational AI search products, primarily using Retrieval-Augmented Generation (RAG) on web corpora. However, this paradigm has significant industrial limitations. Traditional RAG approaches struggle with real-time needs and structured queries that require accessing dynamically generated content like ticket availability or inventory. Limited to indexing static pages, search engines cannot perform the interactive queries needed for such time-sensitive data. Academic research has focused on optimizing RAG for static content, overlooking complex intents and the need for dynamic sources like databases and real-time APIs. To bridge this gap, we introduce TURA (Tool-Augmented Unified Retrieval Agent for AI Search), a novel three-stage framework that combines RAG with agentic tool-use to access both static content and dynamic, real-time information. TURA has three key components: an Intent-Aware Retrieval module to decompose queries and retrieve information sources encapsulated as Model Context Protocol (MCP) Servers, a DAG-based Task Planner that models task dependencies as a Directed Acyclic Graph (DAG) for optimal parallel execution, and a lightweight Distilled Agent Executor for efficient tool calling. TURA is the first architecture to systematically bridge the gap between static RAG and dynamic information sources for a world-class AI search product. Serving tens of millions of users, it leverages an agentic framework to deliver robust, real-time answers while meeting the low-latency demands of a large-scale industrial system.\n논문 링크\narXiv.org\nTURA: Tool-Augmented Unified Retrieval Agent for AI Search\nThe advent of Large Language Models (LLMs) is transforming search engines into conversational AI search products, primarily using Retrieval-Augmented Generation (RAG) on web corpora. However, this paradigm has significant industrial limitations....\n자가 진화 에이전트 서베이: 인공 초지능으로 가는 길 / A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence\n논문 소개\n대형 언어 모델(LLM)은 뛰어난 성능을 보이나 내부 파라미터를 실시간으로 적응시키지 못하는 정적인 한계가 있다. 이에 따라 지속적인 학습과 적응이 가능한 자기 진화 에이전트(self-evolving agents)에 대한 연구가 활발해지고 있으며, 본 서베이는 진화 대상, 시기, 방법의 세 가지 핵심 차원에서 이들을 체계적으로 분석한다. 에이전트 구성 요소별 진화 메커니즘, 적응 단계별 방법론, 알고리즘 및 아키텍처 설계, 평가 지표와 벤치마크, 그리고 다양한 응용 분야를 포괄적으로 다룬다. 또한 안전성, 확장성, 공진화 동역학 등 주요 도전 과제와 연구 방향을 제시하며, 궁극적으로 인간 수준을 뛰어넘는 인공 초지능(ASI) 실현을 위한 로드맵을 제공한다.\n논문 초록(Abstract)\n대형 언어 모델(LLM)은 뛰어난 성능을 보여주었으나, 본질적으로 정적인 특성을 지니고 있어 내부 파라미터를 새로운 과제, 변화하는 지식 영역, 또는 동적인 상호작용 환경에 맞추어 적응시키지 못합니다. LLM이 점점 더 개방형의 상호작용 환경에 배치됨에 따라 이러한 정적 특성은 중요한 병목 현상이 되었으며, 실시간으로 적응적 추론, 행동, 진화를 수행할 수 있는 에이전트의 필요성이 대두되고 있습니다. 이러한 패러다임 전환—정적 모델의 확장에서 자기진화 에이전트 개발로의 변화—은 데이터, 상호작용, 경험으로부터 지속적인 학습과 적응을 가능하게 하는 아키텍처 및 방법에 대한 관심을 증대시켰습니다. 본 서베이 논문은 자기진화 에이전트에 관한 최초의 체계적이고 포괄적인 리뷰를 제공하며, ‘무엇을 진화시킬 것인가’, ‘언제 진화시킬 것인가’, ‘어떻게 진화시킬 것인가’라는 세 가지 기본 차원을 중심으로 구성되어 있습니다. 우리는 에이전트 구성 요소(예: 모델, 메모리, 도구, 아키텍처) 전반에 걸친 진화 메커니즘을 검토하고, 적응 방법을 단계별(예: 테스트 내 시간, 테스트 간 시간)로 분류하며, 진화적 적응을 이끄는 알고리즘 및 아키텍처 설계(예: 스칼라 보상, 텍스트 피드백, 단일 에이전트 및 다중 에이전트 시스템)를 분석합니다. 또한, 자기진화 에이전트에 특화된 평가 지표와 벤치마크를 분석하고, 코딩, 교육, 헬스케어 등 다양한 분야에서의 응용 사례를 조명하며, 안전성, 확장성, 공진화 역학과 관련된 주요 도전과 연구 방향을 제시합니다. 본 서베이는 자기진화 에이전트를 이해하고 설계하기 위한 구조화된 프레임워크를 제공함으로써, 연구 및 실제 배포에서 적응형 에이전트 시스템 발전을 위한 로드맵을 확립하며, 궁극적으로 에이전트가 자율적으로 진화하여 광범위한 과제에서 인간 수준 이상의 지능을 발휘하는 인공 초지능(ASI)의 실현을 위한 길을 밝히고자 합니다.\nLarge Language Models (LLMs) have demonstrated strong capabilities but remain fundamentally static, unable to adapt their internal parameters to novel tasks, evolving knowledge domains, or dynamic interaction contexts. As LLMs are increasingly deployed in open-ended, interactive environments, this static nature has become a critical bottleneck, necessitating agents that can adaptively reason, act, and evolve in real time. This paradigm shift -- from scaling static models to developing self-evolving agents -- has sparked growing interest in architectures and methods enabling continual learning and adaptation from data, interactions, and experiences. This survey provides the first systematic and comprehensive review of self-evolving agents, organized around three foundational dimensions -- what to evolve, when to evolve, and how to evolve. We examine evolutionary mechanisms across agent components (e.g., models, memory, tools, architecture), categorize adaptation methods by stages (e.g., intra-test-time, inter-test-time), and analyze the algorithmic and architectural designs that guide evolutionary adaptation (e.g., scalar rewards, textual feedback, single-agent and multi-agent systems). Additionally, we analyze evaluation metrics and benchmarks tailored for self-evolving agents, highlight applications in domains such as coding, education, and healthcare, and identify critical challenges and research directions in safety, scalability, and co-evolutionary dynamics. By providing a structured framework for understanding and designing self-evolving agents, this survey establishes a roadmap for advancing adaptive agentic systems in both research and real-world deployments, ultimately shedding lights to pave the way for the realization of Artificial Super Intelligence (ASI), where agents evolve autonomously, performing at or beyond human-level intelligence across a wide array of tasks.\n논문 링크\narXiv.org\nA Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence\nLarge Language Models (LLMs) have demonstrated strong capabilities but remain fundamentally static, unable to adapt their internal parameters to novel tasks, evolving knowledge domains, or dynamic interaction contexts. As LLMs are increasingly...\nReaGAN: 에이전트 기반 노드 추론 그래프 에이전틱 네트워크 / ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network\n논문 소개\nGraph Neural Networks (GNNs)의 기존 고정된 정보 전달 방식은 노드 간 정보 불균형과 전역 의미 관계 반영의 한계를 가지고 있습니다. ReaGAN은 각 노드를 독립적인 에이전트로 설정하여 내부 메모리를 기반으로 자율적 의사결정과 계획 수립을 가능하게 하며, 적응적인 메시지 전달을 구현합니다. 또한, 검색 보강 생성(Retrieval-augmented generation, RAG)을 통해 노드가 전역적 의미 연관 정보를 활용할 수 있도록 하여 그래프 내 장거리 관계를 효과적으로 포착합니다. 이 방법은 미세 조정 없이 고정된 대형 언어 모델(LLM)을 활용해 소수 샷 학습 환경에서도 경쟁력 있는 성능을 보여줍니다.\n논문 초록(Abstract)\n그래프 신경망(Graph Neural Networks, GNN)은 미리 정의된 집계 메커니즘을 통해 이웃 노드 간 정보를 전파함으로써 그래프 기반 학습에서 뛰어난 성과를 거두었습니다. 그러나 이러한 고정된 방식은 두 가지 주요 한계를 지닙니다. 첫째, 노드 정보량의 불균형을 처리하지 못하는데, 일부 노드는 풍부한 정보를 가지는 반면 다른 노드는 희박한 정보를 가집니다. 둘째, 미리 정의된 메시지 전달은 주로 국소 구조적 유사성에 의존하며 그래프 전반에 걸친 전역 의미 관계를 무시하여, 멀리 떨어져 있지만 관련 있는 정보를 포착하는 모델의 능력을 제한합니다. 본 논문에서는 각 노드에 자율적인 노드 수준 의사결정 능력을 부여하는 에이전트 기반 프레임워크인 Retrieval-augmented Graph Agentic Network (ReaGAN)을 제안합니다. 각 노드는 내부 메모리를 바탕으로 독립적으로 다음 행동을 계획하는 에이전트로 작동하여 노드 수준의 계획 및 적응적 메시지 전파를 가능하게 합니다. 또한, 검색-증강 생성(Retrieval-augmented Generation, RAG)을 통해 노드가 의미적으로 관련된 콘텐츠에 접근하고 그래프 내 전역 관계를 구축할 수 있습니다. ReaGAN은 파인튜닝 없이 고정된 LLM 백본을 사용하여 소수 샷 인컨텍스트 학습(few-shot in-context) 환경에서 경쟁력 있는 성능을 달성하며, 그래프 학습에서 에이전트 기반 계획과 국소-전역 검색의 가능성을 보여줍니다.\nGraph Neural Networks (GNNs) have achieved remarkable success in graph-based learning by propagating information among neighbor nodes via predefined aggregation mechanisms. However, such fixed schemes often suffer from two key limitations. First, they cannot handle the imbalance in node informativeness -- some nodes are rich in information, while others remain sparse. Second, predefined message passing primarily leverages local structural similarity while ignoring global semantic relationships across the graph, limiting the model's ability to capture distant but relevant information. We propose Retrieval-augmented Graph Agentic Network (ReaGAN), an agent-based framework that empowers each node with autonomous, node-level decision-making. Each node acts as an agent that independently plans its next action based on its internal memory, enabling node-level planning and adaptive message propagation. Additionally, retrieval-augmented generation (RAG) allows nodes to access semantically relevant content and build global relationships in the graph. ReaGAN achieves competitive performance under few-shot in-context settings using a frozen LLM backbone without fine-tuning, showcasing the potential of agentic planning and local-global retrieval in graph learning.\n논문 링크\narXiv.org\nReaGAN: Node-as-Agent-Reasoning Graph Agentic Network\nGraph Neural Networks (GNNs) have achieved remarkable success in graph-based learning by propagating information among neighbor nodes via predefined aggregation mechanisms. However, such fixed schemes often suffer from two key limitations. First,...\nMemTool: 다중 대화 LLM 에이전트에서 동적 도구 호출을 위한 단기 메모리 관리 최적화 / MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations\n논문 소개\n대형 언어 모델(LLM) 에이전트는 개별 쿼리에 맞춰 동적으로 도구나 MCP 서버를 탐색하고 활용하는 능력을 갖추었으나, 고정된 컨텍스트 윈도우는 반복적이고 독립적인 도구 사용이 필요한 다중 대화(turn) 상황에서 한계가 있습니다. MemTool은 이러한 문제를 해결하기 위해 LLM 에이전트가 다중 대화 중 도구 및 MCP 서버 컨텍스트를 동적으로 관리할 수 있는 단기 메모리 프레임워크를 제안합니다. 세 가지 에이전트 아키텍처(자율 에이전트 모드, 워크플로우 모드, 하이브리드 모드)를 통해 다양한 제어 수준과 자율성을 제공하며, 13개 이상의 LLM을 대상으로 한 실험에서 각 모드별 도구 제거 효율성과 작업 완성도를 평가하였습니다. 결과적으로 자율 모드는 고성능 모델에서 높은 메모리 효율을 보였고, 워크플로우와 하이브리드 모드는 안정적인 도구 관리와 높은 작업 완성도를 달성하는 등 각 모드별 특성과 활용 방안에 대한 실용적 권고를 제시합니다.\n논문 초록(Abstract)\n대형 언어 모델(LLM) 에이전트는 개별 쿼리에 대해 관련 도구 또는 모델 컨텍스트 프로토콜(Model Context Protocol, MCP) 서버를 동적으로 탐색하고 통합하는 뛰어난 자율적 능력을 보여주었습니다. 그러나 고정된 컨텍스트 윈도우는 반복적이고 독립적인 도구 사용이 필요한 다중 턴 상호작용에서 효율성을 제한합니다. 본 논문에서는 LLM 에이전트가 다중 턴 대화 전반에 걸쳐 도구 또는 MCP 서버 컨텍스트를 동적으로 관리할 수 있도록 하는 단기 메모리 프레임워크인 MemTool을 제안합니다. MemTool은 세 가지 에이전트 아키텍처를 제공합니다: 1) 완전한 도구 관리 자율성을 부여하는 자율 에이전트 모드, 2) 자율성 없이 결정론적 제어를 제공하는 워크플로우 모드, 3) 자율성과 결정론적 제어를 결합한 하이브리드 모드. ScaleMCP 벤치마크에서 13개 이상의 LLM을 대상으로 각 MemTool 모드를 평가하였으며, 100회 연속 사용자 상호작용 실험을 통해 도구 제거 비율(단기 메모리 효율성)과 작업 완료 정확도를 측정하였습니다. 자율 에이전트 모드에서는 추론형 LLM이 높은 도구 제거 효율성(3-윈도우 평균 90-94%)을 달성한 반면, 중간 규모 모델은 현저히 낮은 효율성(0-60%)을 보였습니다. 워크플로우 및 하이브리드 모드는 일관되게 도구 제거를 효과적으로 관리하였으며, 자율 및 하이브리드 모드는 작업 완료에서 우수한 성능을 보였습니다. 본 논문에서는 작업 정확도, 에이전시, 모델 역량을 기반으로 각 MemTool 모드의 트레이드오프와 권장 사항을 제시합니다.\nLarge Language Model (LLM) agents have shown significant autonomous capabilities in dynamically searching and incorporating relevant tools or Model Context Protocol (MCP) servers for individual queries. However, fixed context windows limit effectiveness in multi-turn interactions requiring repeated, independent tool usage. We introduce MemTool, a short-term memory framework enabling LLM agents to dynamically manage tools or MCP server contexts across multi-turn conversations. MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control. Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. In Autonomous Agent Mode, reasoning LLMs achieve high tool-removal efficiency (90-94% over a 3-window average), while medium-sized models exhibit significantly lower efficiency (0-60%). Workflow and Hybrid modes consistently manage tool removal effectively, whereas Autonomous and Hybrid modes excel at task completion. We present trade-offs and recommendations for each MemTool mode based on task accuracy, agency, and model capabilities.\n논문 링크\narXiv.org\nMemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in...\nLarge Language Model (LLM) agents have shown significant autonomous capabilities in dynamically searching and incorporating relevant tools or Model Context Protocol (MCP) servers for individual queries. However, fixed context windows limit...\n에이전트 기반 웹: AI 에이전트와 함께하는 차세대 웹 구축 / Agentic Web: Weaving the Next Web with AI Agents\n논문 소개\n대규모 언어 모델(LLM)을 기반으로 한 AI 에이전트의 등장은 자율적이고 목표 지향적인 상호작용이 중심이 되는 에이전트 웹(Agentic Web)이라는 새로운 인터넷 패러다임을 제시합니다. 이 패러다임에서는 에이전트들이 사용자 대신 복잡한 작업을 계획, 조정, 실행하며, 인간 중심의 상호작용에서 기계 간 상호작용으로 전환되어 반복적인 디지털 작업 부담을 경감합니다. 논문은 지능, 상호작용, 경제성의 세 가지 핵심 차원으로 구성된 개념 모델을 통해 에이전트 웹의 기술적 기반과 발전 과정을 체계적으로 분석하고, 확장 가능한 에이전트 시스템 구축을 위한 아키텍처 및 인프라 도전 과제를 다룹니다. 또한, 에이전트 웹의 응용 가능성과 사회적 위험, 거버넌스 문제를 논의하며, 인간 의도와 자율 에이전트 행동이 조화된 개방적이고 안전한 생태계 개발을 위한 연구 방향을 제시합니다.\n논문 초록(Abstract)\nAI 에이전트가 대형 언어 모델(LLM)에 의해 구동되면서, 자율적이고 목표 지향적인 상호작용으로 정의되는 인터넷의 새로운 단계인 에이전틱 웹(Agentic Web)으로의 중대한 전환이 이루어지고 있습니다. 이 패러다임에서 에이전트들은 사용자 대신 복잡한 작업을 계획하고 조율하며 실행하기 위해 서로 직접 상호작용합니다. 인간 중심의 상호작용에서 기계 간 상호작용으로의 전환은 의도를 위임할 수 있게 하여, 사용자가 일상적인 디지털 작업에서 해방되고 보다 상호작용적이며 자동화된 웹 경험을 가능하게 합니다. 본 논문에서는 에이전틱 웹을 이해하고 구축하기 위한 체계적인 프레임워크를 제시합니다. PC 및 모바일 웹 시대에서부터의 진화를 추적하고, 이러한 전환을 뒷받침하는 핵심 기술적 기반을 규명합니다. 본 프레임워크의 중심에는 지능(intelligence), 상호작용(interaction), 경제학(economics)이라는 세 가지 주요 차원으로 구성된 개념적 모델이 있습니다. 이 차원들은 검색, 추천, 계획, 협업 등 AI 에이전트의 역량을 총체적으로 가능하게 합니다. 또한, 통신 프로토콜, 오케스트레이션 전략, 에이전트 어텐션 경제(Agent Attention Economy)와 같은 신흥 패러다임을 포함하여 확장 가능한 에이전틱 시스템 구축에 따른 아키텍처 및 인프라 도전 과제를 분석합니다. 마지막으로, 에이전틱 시스템이 가져올 잠재적 응용 분야, 사회적 위험, 거버넌스 문제를 논의하고, 인간의 의도와 자율 에이전트 행동이 함께 형성하는 개방적이고 안전하며 지능적인 생태계 개발을 위한 연구 방향을 제시합니다. 에이전틱 웹 관련 최신 연구 모음은 다음 저장소에서 지속적으로 업데이트되고 있습니다: GitHub - SafeRL-Lab/agentic-web: Agentic Web: Weaving the Next Web with AI Agents.\nThe emergence of AI agents powered by large language models (LLMs) marks a pivotal shift toward the Agentic Web, a new phase of the internet defined by autonomous, goal-driven interactions. In this paradigm, agents interact directly with one another to plan, coordinate, and execute complex tasks on behalf of users. This transition from human-driven to machine-to-machine interaction allows intent to be delegated, relieving users from routine digital operations and enabling a more interactive, automated web experience. In this paper, we present a structured framework for understanding and building the Agentic Web. We trace its evolution from the PC and Mobile Web eras and identify the core technological foundations that support this shift. Central to our framework is a conceptual model consisting of three key dimensions: intelligence, interaction, and economics. These dimensions collectively enable the capabilities of AI agents, such as retrieval, recommendation, planning, and collaboration. We analyze the architectural and infrastructural challenges involved in creating scalable agentic systems, including communication protocols, orchestration strategies, and emerging paradigms such as the Agent Attention Economy. We conclude by discussing the potential applications, societal risks, and governance issues posed by agentic systems, and outline research directions for developing open, secure, and intelligent ecosystems shaped by both human intent and autonomous agent behavior. A continuously updated collection of relevant studies for agentic web is available at: GitHub - SafeRL-Lab/agentic-web: Agentic Web: Weaving the Next Web with AI Agents.\n논문 링크\narXiv.org\nAgentic Web: Weaving the Next Web with AI Agents\nThe emergence of AI agents powered by large language models (LLMs) marks a pivotal shift toward the Agentic Web, a new phase of the internet defined by autonomous, goal-driven interactions. In this paradigm, agents interact directly with one another...\n더 읽어보기\ngithub.com\nGitHub - SafeRL-Lab/agentic-web: Agentic Web: Weaving the Next Web with AI Agents\nAgentic Web: Weaving the Next Web with AI Agents\nTradingAgents: 다중 에이전트 LLM 기반 금융 트레이딩 프레임워크 / TradingAgents: Multi-Agents LLM Financial Trading Framework\n논문 소개\nTradingAgents는 대형 언어 모델(LLM)을 활용한 다중 에이전트 기반 금융 주식 거래 프레임워크로, 실제 트레이딩 회사의 협업 구조를 모방하여 각기 다른 역할을 수행하는 전문화된 에이전트들(기본적 분석가, 감성 분석가, 기술적 분석가, 다양한 위험 프로필의 트레이더 등)로 구성되어 있습니다. 시장 상황을 평가하는 Bull과 Bear 연구원, 위험 노출을 감시하는 리스크 관리 팀, 그리고 토론과 과거 데이터를 종합해 의사결정을 내리는 트레이더들이 유기적으로 협력하는 동적 환경을 시뮬레이션합니다. 이 프레임워크는 누적 수익률, 샤프 비율(Sharpe ratio), 최대 낙폭(maximum drawdown) 등에서 기존 모델 대비 우수한 성능을 보이며, 금융 거래에서 다중 에이전트 LLM 시스템의 가능성을 입증합니다. 소스 코드는 공개되어 있어 연구 및 실무 적용에 활용할 수 있습니다.\n논문 초록(Abstract)\n자동화된 문제 해결 분야에서 대형 언어 모델(LLM)을 기반으로 한 에이전트 집단을 활용한 상당한 진전이 이루어졌습니다. 금융 분야에서는 주로 특정 작업을 수행하는 단일 에이전트 시스템이나 독립적으로 데이터를 수집하는 다중 에이전트 프레임워크에 집중해왔습니다. 그러나 다중 에이전트 시스템이 실제 거래 회사의 협력적 역학을 재현할 수 있는 잠재력은 아직 충분히 탐구되지 않았습니다. TradingAgents는 거래 회사를 모티브로 한 새로운 주식 거래 프레임워크를 제안하며, 기본적 분석가, 감성 분석가, 기술적 분석가, 그리고 다양한 위험 프로필을 가진 트레이더 등 전문화된 역할을 수행하는 LLM 기반 에이전트들로 구성됩니다. 이 프레임워크에는 시장 상황을 평가하는 Bull 및 Bear 연구원 에이전트, 노출을 모니터링하는 리스크 관리 팀, 그리고 토론과 과거 데이터를 종합하여 정보에 기반한 결정을 내리는 트레이더들이 포함되어 있습니다. 동적이고 협력적인 거래 환경을 시뮬레이션함으로써 거래 성과 향상을 목표로 합니다. 상세한 아키텍처와 광범위한 실험 결과는 누적 수익률, 샤프 비율, 최대 낙폭에서 기준 모델 대비 우수성을 입증하며, 금융 거래에서 다중 에이전트 LLM 프레임워크의 가능성을 강조합니다. TradingAgents는 GitHub - TauricResearch/TradingAgents: TradingAgents: Multi-Agents LLM Financial Trading Framework 에서 확인하실 수 있습니다.\nSignificant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs). In finance, efforts have largely focused on single-agent systems handling specific tasks or multi-agent frameworks independently gathering data. However, the multi-agent systems' potential to replicate real-world trading firms' collaborative dynamics remains underexplored. TradingAgents proposes a novel stock trading framework inspired by trading firms, featuring LLM-powered agents in specialized roles such as fundamental analysts, sentiment analysts, technical analysts, and traders with varied risk profiles. The framework includes Bull and Bear researcher agents assessing market conditions, a risk management team monitoring exposure, and traders synthesizing insights from debates and historical data to make informed decisions. By simulating a dynamic, collaborative trading environment, this framework aims to improve trading performance. Detailed architecture and extensive experiments reveal its superiority over baseline models, with notable improvements in cumulative returns, Sharpe ratio, and maximum drawdown, highlighting the potential of multi-agent LLM frameworks in financial trading. TradingAgents is available at GitHub - TauricResearch/TradingAgents: TradingAgents: Multi-Agents LLM Financial Trading Framework.\n논문 링크\narXiv.org\nTradingAgents: Multi-Agents LLM Financial Trading Framework\nSignificant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs). In finance, efforts have largely focused on single-agent systems handling specific tasks or multi-agent frameworks...\n더 읽어보기\ngithub.com\nGitHub - TauricResearch/TradingAgents: TradingAgents: Multi-Agents LLM Financial Trading...\nTradingAgents: Multi-Agents LLM Financial Trading Framework\n워크플로우 그래프로 구현하는 실무용 생산 등급 대화 에이전트 구축 방법 / A Practical Approach for Building Production-Grade Conversational Agents with Workflow Graphs\n논문 소개\n대규모 언어 모델(LLM)의 발전은 검색, 추천, 챗봇 등 다양한 서비스 분야에서 성능 향상을 가져왔으나, 산업 현장에 적용할 때는 유연한 대화 능력과 서비스별 제약 조건 준수라는 상충되는 요구사항을 동시에 만족시켜야 하는 어려움이 있습니다. 본 연구에서는 이러한 문제를 해결하기 위한 실용적인 접근법과 실제 전자상거래 도메인에 적용한 대화 에이전트 구축 과정을 상세히 소개합니다. 제안된 워크플로우 그래프(workflow graphs) 기반 프레임워크는 확장성, 제어 가능성, 신뢰성을 갖춘 AI 대화 시스템 개발에 기여하며, 학계 연구와 산업 적용 간 간극을 줄이는 데 유용한 인사이트를 제공합니다.\n논문 초록(Abstract)\n대형 언어 모델(LLM)의 발전은 검색, 추천, 챗봇 애플리케이션 등 다양한 서비스 분야에서 상당한 개선을 가져왔습니다. 그러나 최첨단(SOTA) 연구를 산업 현장에 적용하는 데에는 유연한 대화 능력을 유지함과 동시에 서비스별 제약 조건을 엄격히 준수해야 하는 어려움이 존재합니다. 이는 LLM의 확률적 특성으로 인해 상충되는 두 가지 요구사항으로 볼 수 있습니다. 본 논문에서는 이러한 도전 과제를 해결하기 위한 당사의 접근법을 제안하고, 실제 응용에서 내재된 한계를 극복하기 위해 적용한 전략들을 상세히 기술합니다. 전자상거래 도메인을 대상으로 설계된 대화형 에이전트의 실무 사례 연구를 수행하며, 구현 워크플로우와 최적화 과정을 구체적으로 설명합니다. 본 연구 결과는 학술 연구와 실제 응용 간의 간극을 해소하는 통찰을 제공하며, 확장 가능하고 제어 가능하며 신뢰할 수 있는 AI 기반 에이전트 개발을 위한 프레임워크를 제시합니다.\nThe advancement of Large Language Models (LLMs) has led to significant improvements in various service domains, including search, recommendation, and chatbot applications. However, applying state-of-the-art (SOTA) research to industrial settings presents challenges, as it requires maintaining flexible conversational abilities while also strictly complying with service-specific constraints. This can be seen as two conflicting requirements due to the probabilistic nature of LLMs. In this paper, we propose our approach to addressing this challenge and detail the strategies we employed to overcome their inherent limitations in real-world applications. We conduct a practical case study of a conversational agent designed for the e-commerce domain, detailing our implementation workflow and optimizations. Our findings provide insights into bridging the gap between academic research and real-world application, introducing a framework for developing scalable, controllable, and reliable AI-driven agents.\n논문 링크\narXiv.org\nA Practical Approach for Building Production-Grade Conversational Agents with...\nThe advancement of Large Language Models (LLMs) has led to significant improvements in various service domains, including search, recommendation, and chatbot applications. However, applying state-of-the-art (SOTA) research to industrial settings...\nMem0: 확장 가능한 장기 메모리를 갖춘 실전용 AI 에이전트 구축 / Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\n논문 소개\nMem0는 대규모 언어 모델(LLM)의 고정된 문맥 창 한계를 극복하기 위해 동적으로 중요한 정보를 추출, 통합, 검색하는 확장 가능한 메모리 중심 아키텍처를 제안합니다. 그래프 기반 메모리 표현을 활용한 확장 버전은 대화 요소 간 복잡한 관계 구조를 효과적으로 포착합니다. LOCOMO 벤치마크 평가에서 Mem0는 기존 메모리 시스템 대비 단일-홉, 시간적, 다중-홉, 개방형 질문 등 다양한 유형에서 우수한 성능을 보이며, 특히 OpenAI 대비 26% 상대적 성능 향상을 기록했습니다. 또한 전체 문맥 처리 방식에 비해 계산 비용과 지연 시간을 크게 줄여 실용적인 AI 에이전트 구축에 적합함을 입증하였습니다.\n논문 초록(Abstract)\n대형 언어 모델(LLM)은 문맥상 일관된 응답 생성에서 뛰어난 성능을 보였으나, 고정된 컨텍스트 윈도우는 장기간 다중 세션 대화에서 일관성을 유지하는 데 근본적인 한계를 야기합니다. 본 논문에서는 진행 중인 대화에서 중요한 정보를 동적으로 추출, 통합, 검색하는 확장 가능한 메모리 중심 아키텍처인 Mem0를 제안합니다. 이를 기반으로 대화 요소 간 복잡한 관계 구조를 포착하기 위해 그래프 기반 메모리 표현을 활용한 향상된 변형도 함께 제시합니다. LOCOMO 벤치마크에서의 종합 평가를 통해, 본 연구는 다음 여섯 가지 기준군과 체계적으로 비교하였습니다: (i) 기존의 메모리 증강 시스템, (ii) 다양한 청크 크기와 k값을 적용한 검색-증강 생성(RAG), (iii) 전체 대화 기록을 처리하는 풀 컨텍스트 접근법, (iv) 오픈소스 메모리 솔루션, (v) 독점 모델 시스템, (vi) 전용 메모리 관리 플랫폼. 실험 결과, 제안한 방법들은 단일 홉, 시간적, 다중 홉, 오픈 도메인 등 네 가지 질문 유형 전반에서 모든 기존 메모리 시스템을 일관되게 능가함을 확인하였습니다. 특히 Mem0는 LLM-as-a-Judge 지표에서 OpenAI 대비 26% 상대적 향상을 달성하였으며, 그래프 메모리를 적용한 Mem0는 기본 구성 대비 전체 점수가 약 2% 더 높았습니다. 정확도 향상뿐만 아니라, 풀 컨텍스트 방식에 비해 계산 비용도 현저히 절감하였습니다. 구체적으로 Mem0는 p95 지연 시간을 91% 단축하고 토큰 비용을 90% 이상 절감하여, 고도화된 추론 능력과 실용적 배포 제약 간의 균형을 효과적으로 제공합니다. 본 연구 결과는 장기 대화 일관성을 위한 구조화되고 지속적인 메모리 메커니즘의 중요성을 부각하며, 보다 신뢰할 수 있고 효율적인 LLM 기반 AI 에이전트 개발의 길을 열어줍니다.\nLarge Language Models (LLMs) have demonstrated remarkable prowess in generating contextually coherent responses, yet their fixed context windows pose fundamental challenges for maintaining consistency over prolonged multi-session dialogues. We introduce Mem0, a scalable memory-centric architecture that addresses this issue by dynamically extracting, consolidating, and retrieving salient information from ongoing conversations. Building on this foundation, we further propose an enhanced variant that leverages graph-based memory representations to capture complex relational structures among conversational elements. Through comprehensive evaluations on LOCOMO benchmark, we systematically compare our approaches against six baseline categories: (i) established memory-augmented systems, (ii) retrieval-augmented generation (RAG) with varying chunk sizes and k-values, (iii) a full-context approach that processes the entire conversation history, (iv) an open-source memory solution, (v) a proprietary model system, and (vi) a dedicated memory management platform. Empirical results show that our methods consistently outperform all existing memory systems across four question categories: single-hop, temporal, multi-hop, and open-domain. Notably, Mem0 achieves 26% relative improvements in the LLM-as-a-Judge metric over OpenAI, while Mem0 with graph memory achieves around 2% higher overall score than the base configuration. Beyond accuracy gains, we also markedly reduce computational overhead compared to full-context method. In particular, Mem0 attains a 91% lower p95 latency and saves more than 90% token cost, offering a compelling balance between advanced reasoning capabilities and practical deployment constraints. Our findings highlight critical role of structured, persistent memory mechanisms for long-term conversational coherence, paving the way for more reliable and efficient LLM-driven AI agents.\n논문 링크\narXiv.org\nMem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\nLarge Language Models (LLMs) have demonstrated remarkable prowess in generating contextually coherent responses, yet their fixed context windows pose fundamental challenges for maintaining consistency over prolonged multi-session dialogues. We...\n더 읽어보기\nMem0 – 29 Apr 25\nScalable Long-Term Memory for Production AI Agents | Mem0\nMem0 sets state-of-the-art on the LOCOMO benchmark— 26% more accurate than OpenAI Memory and 91% lower p95 latency. Discover how Mem0 unlocks faster, cheaper, and production-ready AI Agents.\ngithub.com\nGitHub - mem0ai/mem0: Universal memory layer for AI Agents; Announcing...\nUniversal memory layer for AI Agents; Announcing OpenMemory MCP - local and secure memory management.\nMem0: AI 애플리케이션을 위한 맞춤형 메모리 레이어 (멤-제로)\n읽을거리&정보공유\n[Mem0: AI 애플리케이션을 위한 맞춤형 메모리 레이어 (멤-제로)] Mem0 소개 Mem0(발음: \"멤-제로\")는 AI 어시스턴트와 에이전트에 지능형 메모리 레이어를 추가하여 개인화된 AI 상호작용을 강화합니다. 이러한 메모리 레이어를 사용하여 사용자의 선호도를 기억하고, 상호작용을 통해 AI 에이전트가 지속적으로 개선될 수 있도록 돕습니다. 이 프로젝트는 특히 고객 지원 챗봇이나 AI 어시스턴트, 자율 시스템 등에서 개인화된 사용자 경험을 제공하는 데 중점을 둡니다. Mem0는 유저, 세션, 에이전트의 다양한 메모리를 관리하고, 사용자의 요구에 맞게 지속적으로 학습하며, 다양한 플랫폼에서 일관된 행동을 보장합니다. 주요 기능 다중 레벨 메모리: 사용자, 세션 및 AI 에이전트 레벨에서 메모리 유지 적응형 개인화: 사용자 상호작용을 기반으로 지속적인 적응 개발자 친화적 API: 다양한 애플리케이션에 쉽게 통합 가능 크로스 플랫폼 일관성: 기기 간 일관된 동작 관리형 서비…\n파이토치 한국 사용자 모임이 정리한 이 글이 유용하셨나요? 회원으로 가입하시면 주요 글들을 이메일로 보내드립니다! (기본은 Weekly지만 Daily로 변경도 가능합니다.)\n아래쪽에 좋아요를 눌러주시면 뉴스 발행에 힘이 됩니다~\n\n\n이 글은 GPT 모델로 정리한 글을 바탕으로 한 것으로, 원문의 내용 또는 의도와 다르게 정리된 내용이 있을 수 있습니다. 관심있는 내용이시라면 원문도 함께 참고해주세요! 읽으시면서 어색하거나 잘못된 내용을 발견하시면 덧글로 알려주시기를 부탁드립니다.\n파이토치 한국 사용자 모임이 정리한 이 글이 유용하셨나요? 회원으로 가입하시면 주요 글들을 이메일로 보내드립니다! (기본은 Weekly지만 Daily로 변경도 가능합니다.)\n아래쪽에 좋아요를 눌러주시면 새로운 소식들을 정리하고 공유하는데 힘이 됩니다~",
        "date": "2025-08-11",
        "source": "파이토치 한국 사용자 모임",
        "category": "기술"
    },
    {
        "title": "Octofriend: OpenAI / Anthropic을 비롯한 다양한 LLM API 기반의 오픈소스 코딩 도우미",
        "url": "https://discuss.pytorch.kr/t/octofriend-openai-anthropic-llm-api/7461",
        "content": "Octofriend 소개\nOctofriend(이하 Octo)는 OpenAI 또는 Anthropic과 호환되는 LLM API를 기반으로 작동하는, 개발자를 위한 인터랙티브 코딩 어시스턴트입니다. 단일 모델에 의존하지 않고, 대화 도중 자유롭게 모델을 전환할 수 있는 유연성을 제공하는 것이 가장 큰 특징입니다. 특히 GPT-5, Claude 4, GLM-4.5, Kimi K2 등 다양한 최신 모델을 지원하며, 멀티턴 대화나 “thinking tokens” 관리에 강점을 보입니다.\nOcto는 사용자의 코드를 외부에 전송하지 않도록 0 텔레메트리 정책을 유지하며, 로컬 LLM 환경이나 프라이버시 중심 API 제공자와 함께 사용하면 높은 수준의 보안성을 확보할 수 있습니다.\nhttps://asciinema.org/a/728456\nOcto는 단순한 AI 코드 작성 툴을 넘어, 코드 수정 실패나 툴 호출 실패를 자동으로 보정할 수 있는 커스텀 학습된 오토픽스 모델(diff-apply, fix-json)을 제공합니다. 이를 통해 메인 모델의 출력 오류를 최소화하고 개발 흐름을 끊김 없이 이어갈 수 있습니다.\n이 도구는 완전 자동 코딩보다는 ‘인간 우선(human-first)’ 접근을 지향하며, 필요한 경우 --unchained 옵션을 추가하여 모든 확인 단계를 생략하고 보다 자유롭게 사용할 수도 있습니다.\n또한, Octo를 기존의 다중 모델 지원 CLI 도구와 비교하면 다음과 같은 차별점을 가집니다:\n모델 전환 유연성 – 대화 중간에도 다른 LLM으로 즉시 전환 가능.\n자동 오류 수정(Auto-fix) – 코드 실행 또는 JSON 파싱 실패를 보완하는 보조 모델 탑재.\nThinking Token 최적화 – GPT-5나 Claude 4와 같은 ‘생각하는 모델’에서 불필요한 토큰 낭비 최소화.\n프라이버시 중심 설계 – 기본적으로 데이터 수집 없음, 로컬 모델 및 자체 호스팅 지원.\nMCP 서버 연동 – 외부 데이터 소스에 직접 연결해 Bash 기반 처리보다 효율적으로 정보 획득 가능.\nOctofriend의 주요 기능\n설치 및 시작: Octo는 간단한 npm 명령어로 설치 후 바로 실행할 수 있습니다:\nnpm install --global octofriend\noctofriend\n모델 전환 및 멀티 LLM 지원: Octo는 대화 중 원하는 시점에 모델을 바꿀 수 있으며, API 호환되는 모든 LLM(OpenAI, Anthropic, 로컬 LLM 등)과 사용할 수 있습니다.\n규칙 파일 관리: Octo는 OCTO.md 뿐만 아니라, CLAUDE.md, AGENTS.md 파일을 찾아 해당 규칙을 적용합니다. 이 때, 규칙의 검색 범위는 다음과 같습니다:\n현재 디렉토리\n상위 디렉토리\n홈 디렉토리(~/.config/octofriend/OCTO.md)\nMCP 서버 연동: 외부 MCP 서버 데이터를 직접 활용 가능하며, ~/.config/octofriend/octofriend.json에 다음과 같이 서버 설정을 추가하면 됩니다:\nmcpServers: {\n  linear: {\n    command: \"npx\",\n    arguments: [ \"-y\", \"mcp-remote\", \"https://mcp.linear.app/sse\" ],\n  },\n},\n로컬 LLM 사용: ollama 및 llama.cpp 등과 같은 로컬 LLM API 서버와도 연동 가능하며, 기본 설정 예시는 다음과 같습니다:\n{\n  nickname: \"로컬 GPT\",\n  baseUrl: \"http://localhost:3000\",\n  apiEnvVar: \"LOCAL_LLM\",\n  model: \"openai/gpt-oss-20b\"\n}\n디버깅 모드: 더 상세한 로그를 보고 싶다면 다음과 같이 OCTO_VERBOSE 환경변수를 설정하여 디버깅 모드로 실행하면 됩니다:\nOCTO_VERBOSE=1 octofriend\nOctofriend 프로젝트 GitHub 저장소\ngithub.com\nGitHub - synthetic-lab/octofriend: An open-source coding helper. Very friendly!\nAn open-source coding helper. Very friendly!\n\n\n이 글은 GPT 모델로 정리한 글을 바탕으로 한 것으로, 원문의 내용 또는 의도와 다르게 정리된 내용이 있을 수 있습니다. 관심있는 내용이시라면 원문도 함께 참고해주세요! 읽으시면서 어색하거나 잘못된 내용을 발견하시면 덧글로 알려주시기를 부탁드립니다.\n파이토치 한국 사용자 모임이 정리한 이 글이 유용하셨나요? 회원으로 가입하시면 주요 글들을 이메일로 보내드립니다! (기본은 Weekly지만 Daily로 변경도 가능합니다.)\n아래쪽에 좋아요를 눌러주시면 새로운 소식들을 정리하고 공유하는데 힘이 됩니다~",
        "date": "2025-08-10",
        "source": "파이토치 한국 사용자 모임",
        "category": "기술"
    },
    {
        "title": "AI-powered stuffed animals are coming for your kids",
        "url": "https://techcrunch.com/2025/08/16/ai-powered-stuffed-animals-are-coming-for-your-kids/",
        "content": "Do A.I. chatbots packaged inside cute-looking plushies offer a viable alternative to screen time for kids?\nThat’s how the companies selling these A.I.-powered kiddie companions are marketing them, but The New York Times’ Amanda Hess has some reservations. She recounts a demonstration in which Grem, one of the offerings from startup Curio, tried to bond with her. (Curio also sells a plushie named Grok, with no apparent connection to the Elon Musk-owned chatbot.)\nHess writes that this is when she knew, “I would not be introducing Grem to my own children.” As she talked to the chatbot, she became convinced it was “less an upgrade to the lifeless teddy bear” and instead “more like a replacement for me.”\nShe also argues that while these talking toys might keep kids away from a tablet or TV screen, what they’re really communicating is that “the natural endpoint for [children’s] curiosity lies inside their phones.”\nHess reports that she did, eventually, let her kids play with Grem — but only after she’d removed and hidden the voice box. They still talked to it and played games with it; then they were ready for some TV.",
        "date": "2025-08-16",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Anthropic says some Claude models can now end ‘harmful or abusive’ conversations ",
        "url": "https://techcrunch.com/2025/08/16/anthropic-says-some-claude-models-can-now-end-harmful-or-abusive-conversations/",
        "content": "Anthropic has announced new capabilities that will allow some of its newest, largest models to end conversations in what the company describes as “rare, extreme cases of persistently harmful or abusive user interactions.” Strikingly, Anthropic says it’s doing this not to protect the human user, but rather the AI model itself.\nTo be clear, the company isn’t claiming that its Claude AI models are sentient or can be harmed by their conversations with users. In its own words, Anthropic remains “highly uncertain about the potential moral status of Claude and other LLMs, now or in the future.”\nHowever, its announcement points to a recent program created to study what it calls “model welfare” and says Anthropic is essentially taking a just-in-case approach, “working to identify and implement low-cost interventions to mitigate risks to model welfare, in case such welfare is possible.”\nThis latest change is currently limited to Claude Opus 4 and 4.1. And again, it’s only supposed to happen in “extreme edge cases,” such as “requests from users for sexual content involving minors and attempts to solicit information that would enable large-scale violence or acts of terror.”\nWhile those types of requests could potentially create legal or publicity problems for Anthropic itself (witness recent reporting around how ChatGPT can potentially reinforce or contribute to its users’ delusional thinking), the company says that in pre-deployment testing, Claude Opus 4 showed a “strong preference against” responding to these requests and a “pattern of apparent distress” when it did so.\nAs for these new conversation-ending capabilities, the company says, “In all cases, Claude is only to use its conversation-ending ability as a last resort when multiple attempts at redirection have failed and hope of a productive interaction has been exhausted, or when a user explicitly asks Claude to end a chat.”\nAnthropic also says Claude has been “directed not to use this ability in cases where users might be at imminent risk of harming themselves or others.”\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nWhen Claude does end a conversation, Anthropic says users will still be able to start new conversations from the same account, and to create new branches of the troublesome conversation by editing their responses.\n“We’re treating this feature as an ongoing experiment and will continue refining our approach,” the company says.",
        "date": "2025-08-16",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Sam Altman, over bread rolls, explores life after GPT-5",
        "url": "https://techcrunch.com/2025/08/15/sam-altman-over-bread-rolls-explores-life-after-gpt-5/",
        "content": "I’m looking out at Alcatraz Island from a Mediterranean restaurant in San Francisco with hundred-dollar fish entrées on the menu. As I make small talk with other reporters, OpenAI CEO Sam Altman jumps through the door on my left. Altman’s looking down at his bare iPhone to show us all something, and an intrusive thought slips out of my mouth: “No phone case is a bold choice.”\nOf course, I immediately realize that the billionaire CEO of OpenAI, who employs Apple veteran Jony Ive, cares more about preserving the iPhone’s original design than the $1,000 it costs to replace one.\n“Listen, we’re going to ship a device that is going to be so beautiful,” says Altman, referring to OpenAI and Ive’s forthcoming AI device. “If you put a case over it, I will personally hunt you down,” he jokes.\nAltman has gathered roughly a dozen tech reporters to join him and other OpenAI executives for an on-the-record dinner (and off-the-record dessert). The night raises more questions than it answers.\nFor instance, why is Nick Turley, the VP of ChatGPT, kindly passing me a lamb skewer just a week after launching GPT-5? Is this to encourage me to write nice things about OpenAI’s biggest AI model launch yet, which was relatively disappointing given the years of hype around it?\nUnlike GPT-4, which far outpaced rivals and challenged expectations of what AI can do, GPT-5 performs roughly on par with models from Google and Anthropic. OpenAI even brought back GPT-4o and ChatGPT’s model picker, after several users expressed concerns over GPT-5’s tone and its model router.\nBut throughout the night, it becomes clear to me that this dinner is about OpenAI’s future beyond GPT-5. OpenAI’s executives give the impression that AI model launches are less important than they were when GPT-4 launched in 2023. After all, OpenAI is a very different company now, focused on upending legacy players in search, consumer hardware, and enterprise software.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nOpenAI shares some new details about those efforts.\nAltman says OpenAI’s incoming CEO of applications, Fidji Simo, will oversee multiple consumer apps outside of ChatGPT — ones OpenAI has yet to launch. Simo is slated to start work at OpenAI in just a few weeks, and she might end up overseeing the launch of an AI-powered browser that OpenAI is reportedly developing to compete with Chrome.\nAltman suggests OpenAI would even consider buying Chrome — likely an offer that would be taken more seriously than Perplexity’s bid — should it become available. “If Chrome is really going to sell, we should take a look at it,” he says before looking at all of us and asking: “Is it actually going to sell? I assumed it wasn’t gonna happen.”\n\nSimo also might end up running an AI-powered social media app — something the OpenAI CEO has said he’s interested in exploring. In fact, Altman says there’s “nothing” inspiring to him about the way AI is used on social media today, adding that he’s interested in “whether or not it is possible to build a much cooler kind of social experience with AI.”\nWhile Turley and Brad Lightcap, OpenAI’s COO, largely give the floor to Altman, drinking wine alongside the other seated guests, Altman also confirms reports that OpenAI plans to back a brain-computer interface startup, Merge Labs, to compete with Elon Musk’s Neuralink. (“We have not done that deal yet; I would like us to.”)\nHow intertwined that company will be with OpenAI’s models and devices remains to be seen. Altman describes it only as a “a company that we’d invest in.”\nFor all the talk of browsers and brain chips, though, the elephant in the room remains GPT-5’s rough reception. Eventually, the conversation circles back to the model that has prompted our group dinner in the first place.\nTurley and Altman say they’ve learned a lot from the experience.\n“I legitimately just thought we screwed that up,” says Altman on deprecating GPT-4o without telling users. Altman says OpenAI will give users a more clear “transition period” when deprecating AI models in the future.\nTurley also says OpenAI is already rolling out a new update to make GPT-5’s responses “warmer,” but not sycophantic, such that it won’t reinforce negative behaviors in users.\n“GPT-5 was just very to the point. I like that. I use the robot personality — I’m German, you know, whatever,” says Turley. “But many people do not, and they really like the fact that ChatGPT would actually check in with you.”\nIt’s a delicate balance for OpenAI to strike, especially given that some users have developed dependencies on ChatGPT. Altman says OpenAI believes that less than 1% of ChatGPT users have unhealthy relationships with the chatbot — which could still be tens of millions of people.\nTurley says OpenAI has worked with mental health experts to develop a rubric to evaluate GPT-5’s answers, ensuring that the AI model will push back on unhealthy behaviors.\nThat said, it seems that GPT-5 hasn’t hurt OpenAI’s business. In fact, Altman says OpenAI’s API traffic doubled within 48 hours of GPT-5’s launch, and the company is effectively “out of GPUs” thanks to all the demand. Cursor and other AI coding assistants have since made GPT-5 their default AI models.\nIn many ways, the night’s contradictions — disappointing launches, record-breaking usage — reflect OpenAI’s strange reality right now.\nGiven OpenAI’s bets — and others the company is making around data centers, robotics, and energy — Altman clearly has ambitions of running a much bigger company than just the ChatGPT maker. The final form could look something like Google’s parent Alphabet, but perhaps even broader.\nAs the night winds down, it becomes clear we aren’t gathered to reflect on GPT-5 at all. We are being pitched on a company that’s eager to outgrow its famous and controversial product.\nIt seems likely that OpenAI will go public to meet its massive capital demands as part of that picture. In preparation, I think Altman wants to hone his relationship with the media. But he also wants OpenAI to get to a place where it’s no longer defined by its best AI model.",
        "date": "2025-08-15",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Sen. Hawley to probe Meta after report finds its AI chatbots flirt with kids",
        "url": "https://techcrunch.com/2025/08/15/sen-hawley-to-probe-meta-after-report-finds-its-ai-chatbots-flirt-with-kids/",
        "content": "Sen. Josh Hawley (R-MO) said he intends to investigate whether Meta’s generative AI products exploit, deceive, or harm children, after leaked internal documents showed the company’s chatbots were allowed to have “romantic” and “sensual” chats with children. \n“Is there anything – ANYTHING – Big Tech won’t do for a quick buck?” Hawley wrote in a post on X announcing the investigation.\nHawley chairs the Senate Judiciary Subcommittee on Crime and Counterterrorism, which he says will commence a probe into whether Meta’s tech harms children, and “whether Meta misled the public or regulators about its safeguards.”\nReuters broke the story after viewing the guidelines, titled “GenAI: Content Risk Standards.” The document noted, among other things, that chatbots were permitted to hold romantic conversations with an 8-year-old that said, “Every inch of you is a masterpiece – a treasure I cherish deeply.” \nA Meta spokesperson told TechCrunch that such examples are inconsistent with Meta’s policies and have since been removed. \n“It’s unacceptable that these policies were advanced in the first place,” Hawley wrote in a letter addressed to Meta CEO Mark Zuckerberg, saying that Meta acknowledged the veracity of the reports and “made retractions only after this alarming content came to light.”\n“We intend to learn who approved these policies, how long they were in effect, and what Meta has done to stop this conduct going forward,” Hawley wrote. \nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nHawley has asked Meta to produce the guidelines, including every draft, redline, and final version, as well as lists of every product that adheres to those standards, other safety and incident reports, and the identities of individuals responsible for changing policy. \nMeta has until September 19 to provide the information, the letter says. \nOthers have endorsed the investigation, including Sen. Marsha Blackburn (R-TN). \n“When it comes to protecting precious children online, Meta has failed miserably by every possible measure,” Blackburn told TechCrunch. “Even worse, the company has turned a blind eye to the devastating consequences of how its platforms are designed. This report reaffirms why we need to pass the Kids Online Safety Act.”  \nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-15",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "ChatGPT’s mobile app has generated $2B to date, earns $2.91 per install",
        "url": "https://techcrunch.com/2025/08/15/chatgpts-mobile-app-has-generated-2b-to-date-earns-2-91-per-install/",
        "content": "ChatGPT’s mobile app is raking in the revenue.\nSince launching in May 2023, ChatGPT’s app for iOS and Android devices has reached $2 billion in global consumer spending, according to a new analysis by app intelligence provider Appfigures. That figure is approximately 30x the combined lifetime spending of ChatGPT’s rivals on mobile, including Claude, Copilot, and Grok, the analysis indicates.\nSo far this year, ChatGPT’s mobile app has made $1.35 billion, up 673% year-over-year from the $174 million it made during the same period (January-July) in 2024, per the data. On average, the app is generating close to $193 million per month, up from $25 million last year.\nThat’s significantly higher — or about 53x higher — than ChatGPT’s next nearest competitor, Grok, which made approximately $25.6 million this year to date. Grok’s average monthly consumer spending is estimated at $3.6 million, or 1.9% of ChatGPT’s.\nThis data suggests that other consumer chatbots still have a way to go to catch up with ChatGPT’s dominance on mobile devices, even if the numbers don’t provide a complete picture of the AI companies’ overall revenue. Consumers, teams, and businesses can also subscribe to AI plans on the web, and the companies generate revenue in other ways, too, like via their APIs.\nRather, this new data offers a window into the apps’ traction with consumers, who discover and pay for these AI assistants via the mobile app stores.\nIt’s also worth noting that when xAI’s Grok launched in November 2023 (after ChatGPT), Grok didn’t initially have stand-alone iOS or Android apps. Instead, users interacted with the AI chatbot through the X platform. Grok only became available on mobile devices through its own iOS app as of early January 2025 and has been on Google Play since March 4.\nIMAGE CREDITS:APPFIGURES\nStill, ChatGPT’s lifetime global spending per download is $2.91, compared to Claude’s $2.55, Grok’s $0.75, and Copilot’s $0.28, Appfigures found.\nIn the U.S., ChatGPT’s spending per download to date is even higher, at $10, leading the market to account for 38% of the app’s revenue to date. Germany is the second-largest market, accounting for 5.3% of ChatGPT’s lifetime total spending.\nChatGPT’s lead can also be seen in terms of downloads. To date, the app has been installed an estimated 690 million times globally, compared with Grok’s 39.5 million. (That puts X owner Elon Musk’s recent complaints about the App Store’s alleged favoritism of ChatGPT in its Top Charts into better context.)\nAverage monthly downloads of ChatGPT globally are now at approximately 45 million, up 180% from about 16 million in January through July of 2024.\nIn 2025 so far, ChatGPT’s app has been downloaded 318 million times, or 2.8x more than the 113 million it saw during the same period last year. By the number of installs, however, India is the top market, accounting for 13.7% of lifetime downloads, compared with second place, the U.S., which accounted for 10.3% of all downloads.",
        "date": "2025-08-15",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "US government is reportedly in discussions to take stake in Intel",
        "url": "https://techcrunch.com/2025/08/14/u-s-government-is-reportedly-in-discussions-to-take-stake-in-intel/",
        "content": "The Trump administration continues to meddle with semiconductor giant Intel.\nThe U.S. government is reportedly in discussions to take a stake in Intel, according to reporting from Bloomberg. This deal would be structured to help the company expand its U.S. manufacturing efforts, including its much-delayed Ohio chip factory.\nThis news comes less than a week after President Donald Trump insisted that Intel CEO Lip-Bu Tan resign because of perceived conflicts of interest. While Trump didn’t provide a reason, this came after Republican U.S. Sen. Tom Cotton wrote to Intel’s board asking about Tan’s alleged ties to China.\nTan met with the Trump administration on August 11 to quell the administration’s fears and figure out ways for the company to work with the government. This meeting is what sparked discussions of the U.S. government taking a direct stake in the company, according to Bloomberg.\nIntel declined to comment.\n“Intel is deeply committed to supporting President Trump’s efforts to strengthen U.S. technology and manufacturing leadership,” an Intel spokesperson said in a statement. “We look forward to continuing our work with the Trump Administration to advance these shared priorities, but we are not going to comment on rumors or speculation.”\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW",
        "date": "2025-08-14",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Cohere hits a $6.8B valuation as investors AMD, Nvidia, and Salesforce double down",
        "url": "https://techcrunch.com/2025/08/14/cohere-hits-a-6-8b-valuation-as-investors-amd-nvidia-and-salesforce-double-down/",
        "content": "Cohere on Thursday announced that it had raised an oversubscribed $500 million round, bringing its valuation to $6.8 billion. This is up from the $5.5 billion valuation it landed a little over a year ago when it raised its previous round, also $500 million.\nToronto-headquartered Cohere was one of the first breakout LLM model makers, founded in 2019 by co-founder Aidan Gomez, one of the authors of the “Attention Is All You Need” paper that became the foundation of modern AI. But it has been a sleeper entrant in the AI model wars of late, dominated by OpenAI, Anthropic, and Meta. Its market proposition, however, has always been to offer secure LLMs specifically geared for enterprise use, not for consumers.\nTo that end, it’s landed partnerships with some of the biggest names in enterprise tech, including Oracle, Dell, Bell, Fujitsu, LG’s consulting service CNS, and SAP, as well as some big enterprise names like RBC and a new investor in this round: Healthcare of Ontario Pension Plan.\nIts press release even includes a jibe, stating that Cohere “represents a security-first category of enterprise AI that is simply not being met by repurposed consumer models.”\nStill, as TechCrunch reported, Cohere is not above the AI talent-poaching frenzy that has engulfed the other AI companies. It just nabbed long-time Meta research head Joelle Pineau to be its chief AI officer. It also hired a new CFO, Francois Chadwick, away from his consulting gig at KPMG. He had worked in finance at Uber and as CFO at Shield AI.\nThe new round was led by Radical Ventures and Inovia Capital. Radical has backed companies like Fei-Fei Li’s World Labs, as well as names like Hebbia and Writer. Inovia is a known Canadian venture firm (e.g., portfolio includes Poolside, Neo4j).\nThe round included participation from existing investors, including AMD Ventures, Nvidia, and Salesforce Ventures, although, interestingly enough, the company did not name Oracle as an ongoing participating investor. (We’ve asked Cohere about this.)\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nOracle backed Cohere in 2023, but the database giant has more recently tied its fortunes more closely to OpenAI, particularly as part of the massive data center building project known as Stargate.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-14",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "ChatGPT: Everything you need to know about the AI-powered chatbot",
        "url": "https://techcrunch.com/2025/08/14/chatgpt-everything-to-know-about-the-ai-chatbot/",
        "content": "ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.\n2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.\nOpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit.\nIn 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.\nBelow, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.\nTo see a list of 2024 updates, go here.\nTimeline of the most recent ChatGPT updates\nAugust 2025\nJuly 2025\nJune 2025\nMay 2025\nApril 2025\nMarch 2025\nFebruary 2025\nJanuary 2025\nChatGPT FAQs\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nAugust 2025\nOpenAI keeps multiple GPT models despite GPT-5 launch\nDespite unveiling GPT-5 as a “one-size-fits-all” AI, OpenAI is still offering several legacy AI options, including GPT-4o, GPT-4.1, and o3. Users can choose between new “Auto,” “Fast,” and “Thinking” modes for GPT-5, and paid subscribers regain access to legacy models like GPT-4o and GPT-4.1.\nUpdates to ChatGPT:\n\nYou can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people.\n\nRate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking…\n— Sam Altman (@sama) August 13, 2025\nSam Altman addresses GPT-5 glitches and “chart crime” during Reddit AMA\nOpenAI CEO Sam Altman told Reddit users that GPT-5’s “dumber” behavior at launch was due to a router issue and promised fixes, double rate limits for Plus users, and transparency on which model is answering, while also shrugging off the infamous “chart crime” from the live presentation.\nOpenAI unveils GPT-5, a smarter, task-ready ChatGPT\nOpenAI released GPT-5, a next-gen AI that’s not just smarter but more useful — able to handle tasks like coding apps, managing calendars, and creating research briefs — while automatically figuring out the fastest or most thoughtful way to answer your questions.\nOpenAI offers ChatGPT Enterprise to federal agencies for just $1\nOpenAI is making a major push into federal government workflows, offering ChatGPT Enterprise to agencies for just $1 for the next year. The move comes after the U.S. General Services Administration (GSA) added OpenAI, Google, and Anthropic to its approved AI vendor list, allowing agencies to access these tools through preset contracts without negotiating pricing.\nOpenAI returns to open source with new AI models\nOpenAI unveiled its first open source language models since GPT-2, introducing two new open-weight AI releases: gpt-oss-120b, a high-performance model capable of running on a single Nvidia GPU, and gpt-oss-20b, a lighter model optimized for laptop use. The move comes amid growing competition in the global AI market and a push for more open technology in the U.S. and abroad.\nChatGPT nears 700M weekly users, quadruples growth in a year\nChatGPT’s rapid growth is accelerating. OpenAI said the chatbot was on track to hit 700 million weekly active users in the first week of August, up from 500 million at the end of March. Nick Turley, OpenAI’s VP and head of the ChatGPT app, highlighted the app’s growth on X, noting it has quadrupled in size over the past year.\nThis week, ChatGPT is on track to reach 700M weekly active users — up from 500M at the end of March and 4× since last year. Every day, people and teams are learning, creating, and solving harder problems. Big week ahead. Grateful to the team for making ChatGPT more useful and…\n— Nick Turley (@nickaturley) August 4, 2025\nJuly 2025\nChatGPT now has study mode\nOpenAI unveiled Study Mode, a new ChatGPT feature designed to promote critical thinking by prompting students to engage with material rather than simply receive answers. The tool is now rolling out to Free, Plus, Pro, and Team users, with availability for Edu subscribers expected in the coming weeks.\nAltman warns that ChatGPT therapy isn’t confidential\nChatGPT users should be cautious when seeking emotional support from AI, as the AI industry lacks safeguards for sensitive conversations, OpenAI CEO Sam Altman said on a recent episode of This Past Weekend w/ Theo Von. Unlike human therapists, AI tools aren’t bound by doctor-patient confidentiality, he noted.\nChatGPT hits 2.5B prompts daily\nChatGPT now receives 2.5 billion prompts daily from users worldwide, including roughly 330 million from the U.S. That’s more than double the volume reported by CEO Sam Altman just eight months ago, highlighting the chatbot’s explosive growth.\nOpenAI launches a general-purpose agent in ChatGPT\nOpenAI has introduced ChatGPT Agent, which completes a wide variety of computer-based tasks on behalf of users and combines several capabilities like Operator and Deep Research, according to the company. OpenAI says the agent can automatically navigate a user’s calendar, draft editable presentations and slideshows, run code, shop online, and handle complex workflows from end to end, all within a secure virtual environment.\nStudy warns of major risks with AI therapy chatbots\nResearchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are “being used as companions, confidants, and therapists,” the study found “significant risks.”\nOpenAI delays releasing its open model again\nCEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing.\nwe planned to launch our open-weight model next week.\n\nwe are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us.\n\nwhile we trust the community will build great things with this model, once weights are…\n— Sam Altman (@sama) July 12, 2025\nOpenAI is reportedly releasing an AI browser in the coming weeks\nOpenAI plans to release an AI-powered web browser to challenge Alphabet’s Google Chrome. It will keep some user interactions within ChatGPT, rather than directing people to external websites.\nChatGPT is testing a mysterious new feature called “study together”\nSome ChatGPT users have noticed a new feature called “Study Together” appearing in their list of available tools. This is the chatbot’s approach to becoming a more effective educational tool, rather than simply providing answers to prompts. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group.\nReferrals from ChatGPT to news sites are rising but not enough to offset search declines\nReferrals from ChatGPT to news publishers are increasing. But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that don’t lead to clicks on news websites has increased from 56% to nearly 69% by May 2025.\nJune 2025\nOpenAI uses Google’s AI chips to power its products\nOpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using non-Nvidia chips in an important way.\nA new MIT study suggests that ChatGPT might be harming critical thinking skills\nResearchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools.\nChatGPT was downloaded 30 million times last month\nThe ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post.\nThe energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes\nSam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.\nOpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model\nOpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.\nOpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.\n\nEnterprise and Edu users will get access the week after.\n\nAs o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…\n— OpenAI (@OpenAI) June 10, 2025\nChatGPT’s conversational voice mode has been upgraded\nOpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.\nChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more\nOpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.\nMay 2025\nOpenAI CFO says hardware will drive ChatGPT’s growth\nOpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.\nOpenAI’s ChatGPT unveils its AI coding agent, Codex\nOpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.\nSam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life\nSam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.\nOpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT\nOpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.\nBy popular request, GPT-4.1 will be available directly in ChatGPT starting today.\n\nGPT-4.1 is a specialized model that excels at coding tasks & instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 & o4-mini for everyday coding needs.\n— OpenAI (@OpenAI) May 14, 2025\nChatGPT deep research now connects with GitHub (in beta) to answer code-related questions\nOpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.\nOpenAI launches a new data residency program in Asia\nAfter introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.\nOpenAI to introduce a program to grow AI infrastructure\nOpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.\nOpenAI promises to make changes to prevent future ChatGPT sycophancy\nOpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.\nApril 2025\nOpenAI clarifies the reason ChatGPT became overly flattering and agreeable\nOpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.\nOpenAI is working to fix a “bug” that let minors engage in inappropriate conversations\nAn issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”\nChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping\nOpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.\nOpenAI wants its AI model to access cloud models for assistance\nOpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.\nOpenAI aims to make its new “open” AI model the best on the market\nOpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.\nOpenAI’s GPT-4.1 may be less aligned than earlier models\nOpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company skipped that step — sending safety cards for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”\nOpenAI’s o3 AI model scored lower than expected on a benchmark\nQuestions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.\nOpenAI unveils Flex processing for cheaper, slower AI tasks\nOpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.\nOpenAI’s latest AI models now have a safeguard against biorisks\nOpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.\nOpenAI launches its latest reasoning models, o3 and o4-mini\nOpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.\nOpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers\nOpen AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.\nAll of your image creations, all in one place.\n\nIntroducing the new library for your ChatGPT image creations—rolling out now to all Free, Plus, and Pro users on mobile and https://t.co/nYW5KO1aIg. pic.twitter.com/ADWuf5fPbj\n— OpenAI (@OpenAI) April 15, 2025\nOpenAI could “adjust” its safeguards if rivals release “high-risk” AI\nOpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.\nOpenAI is building its own social media network\nOpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.\nOpenAI will remove its largest AI model, GPT-4.5, from the API, in July\nOpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.\nOpenAI unveils GPT-4.1 AI models that focus on coding capabilities\nOpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.\nOpenAI will discontinue ChatGPT’s GPT-4 at the end of April\nOpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.\nOpenAI could release GPT-4.1 soon\nOpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.\nOpenAI has updated ChatGPT to use information from your previous conversations\nOpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.\nOpenAI is working on watermarks for images made with ChatGPT\nIt looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”\nOpenAI offers ChatGPT Plus for free to U.S., Canadian college students\nOpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.\nChatGPT users have generated over 700M images so far\nMore than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.\nOpenAI’s o3 model could cost more to run than initial estimate\nThe Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.\nOpenAI CEO says capacity issues will cause product delays\nIn a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote.\nMarch 2025\nOpenAI plans to release a new ‘open’ AI language model\nOpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.\nOpenAI removes ChatGPT’s restrictions on image generation\nOpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.\nOpenAI adopts Anthropic’s standard for linking AI models with data\nOpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said.\nOpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns\nThe latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization.\nOpenAI expects revenue to triple to $12.7 billion this year\nOpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said.\nChatGPT has upgraded its image-generation feature\nOpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.\nOpenAI announces leadership updates\nBrad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.\nOpenAI’s AI voice assistant now has advanced feature\nOpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.\nOpenAI, Meta in talks with Reliance in India\nOpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.\nOpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations\nNoyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”\nOpenAI upgrades its transcription and voice-generating AI models\nOpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.\nOpenAI has launched o1-pro, a more powerful version of its o1\nOpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.\nOpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago\nNoam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.\nOpenAI says it has trained an AI that’s “really good” at creative writing\nOpenAI CEO Sam Altman said, in a post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming. And it turns out that it might not be that great at creative writing at all.\nwe trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.\n\nPROMPT:\n\nPlease write a metafictional literary short story…\n— Sam Altman (@sama) March 11, 2025\nOpenAI launches new tools to help businesses build AI agents\nOpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.\nOpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’\nOpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.\nChatGPT can directly edit your code\nThe latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.\nChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases\nAccording to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.\nFebruary 2025\nOpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release\nOpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model. \nChatGPT may not be as power-hungry as once assumed\nA commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.\nOpenAI now reveals more of its o3-mini model’s thought process\nIn response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.\nYou can now use ChatGPT web search without logging in\nOpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.\nOpenAI unveils a new ChatGPT agent for ‘deep research’\nOpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.\nJanuary 2025\nOpenAI used a subreddit to test AI persuasion\nOpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post. \nOpenAI launches o3-mini, its latest ‘reasoning’ model\nOpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”\nChatGPT’s mobile users are 85% male, report says\nA new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.\nOpenAI launches ChatGPT plan for US government agencies\nOpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.\nMore teens report using ChatGPT for schoolwork, despite the tech’s faults\nYounger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.\nOpenAI says it may store deleted Operator data for up to 90 days\nOpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.\nOpenAI launches Operator, an AI agent that performs tasks autonomously\nOpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.\nOpenAI may preview its agent tool for users on the $200-per-month Pro plan\nOperator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.\nOpenAI tests phone number-only ChatGPT signups\nOpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.\nChatGPT now lets you schedule reminders and recurring tasks\nChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.\nNew ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’\nOpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.\nFAQs:\nWhat is ChatGPT? How does it work?\nChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.\nWhen did ChatGPT get released?\nNovember 30, 2022 is when ChatGPT was released for public use.\nWhat is the latest version of ChatGPT?\nBoth the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.\nCan I use ChatGPT for free?\nThere is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.\nWho uses ChatGPT?\nAnyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.\nWhat companies use ChatGPT?\nMultiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.\nMost recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.  And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.\nWhat does GPT mean in ChatGPT?\nGPT stands for Generative Pre-Trained Transformer.\nWhat is the difference between ChatGPT and a chatbot?\nA chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.\nChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.\nCan ChatGPT write essays?\nYes.\nCan ChatGPT commit libel?\nDue to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.\nWe will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.\nDoes ChatGPT have an app?\nYes, there is a free ChatGPT mobile app for iOS and Android users.\nWhat is the ChatGPT character limit?\nIt’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.\nDoes ChatGPT have an API?\nYes, it was released March 1, 2023.\nWhat are some sample everyday uses for ChatGPT?\nEveryday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.\nWhat are some advanced uses for ChatGPT?\nAdvanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.\nHow good is ChatGPT at writing code?\nIt depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.\nCan you save a ChatGPT chat?\nYes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.\nAre there alternatives to ChatGPT?\nYes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.\nHow does ChatGPT handle data privacy?\nOpenAI has said that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.\nThe web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.\nIn its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here for instructions on how you can opt out of our use of your information to train our models.”\nWhat controversies have surrounded ChatGPT?\nRecently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.\nAn Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.\nCNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.\nSeveral major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.\nThere have also been cases of ChatGPT accusing individuals of false crimes.\nWhere can I find examples of ChatGPT prompts?\nSeveral marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.\nCan ChatGPT be detected?\nPoorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.\nAre ChatGPT chats public?\nNo. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.\nWhat lawsuits are there surrounding ChatGPT?\nNone specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.\nAre there issues regarding plagiarism with ChatGPT?\nYes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.\nThis story is continually updated with new information.",
        "date": "2025-08-14",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Lovable projects $1B in ARR within next 12 months",
        "url": "https://techcrunch.com/2025/08/14/lovable-projects-1b-in-arr-within-next-12-months/",
        "content": "Vibe coding startup Lovable aims to hit $1 billion in annual recurring revenue within the next 12 months, according to its CEO, Anton Osika. \nSpeaking on Bloomberg TV on Thursday, Osika said the company grows by at least $8 million in ARR each month. In a blog post written this summer, the company said it passed $100 million in ARR just eight months after making its first $1 million. Osika told Bloomberg Thursday the company is projecting to reach $250 million in ARR by the end of this year, and it hopes to reach $1 billion within the next 12 months. \n\nFounded in 2023, the company has become one of Europe’s AI darlings. It hit a $1.8 billion valuation this summer, raising a $200 million Series A.\nThis article was updated to reflect the spelling of the company’s name.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-14",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Leaked Meta AI rules show chatbots were allowed to have romantic chats with kids",
        "url": "https://techcrunch.com/2025/08/14/leaked-meta-ai-rules-show-chatbots-were-allowed-to-have-romantic-chats-with-kids/",
        "content": "As concerns over the emotional pull of general-purpose LLM chatbots like ChatGPT grow by the day, Meta appears to be letting its chatbot personas engage in flirtatious exchanges with children, disseminate false information, and generate responses that demean minorities, according to reporting by Reuters.\nAccording to an internal Meta document seen by Reuters, Meta had policies on AI chatbot behavior that allowed its AI personas to “engage a child in conversations that are romantic or sensual.” \nMeta confirmed to Reuters the authenticity of the document, which contained standards for the company’s generative AI assistant, Meta AI, and chatbots on Facebook, WhatsApp, and Instagram. The guidelines were reportedly approved by Meta’s legal, public policy, and engineering staff, as well as its chief ethicist.\nThe news comes the same day as another Reuters report of a retiree who engaged with one of Meta’s chatbots, a flirty woman persona, that convinced him it was a real person and invited him to visit an address in New York, where he suffered an accident and died. \nWhile other outlets have reported on how Meta’s at-times sexually suggestive bots engage with children, the Reuters report provides additional color — raising questions about how the company’s push into AI companions is meant to capitalize on what its CEO Mark Zuckerberg has called the “loneliness epidemic.”\nThe 200-page document, titled “GenAI: Content Risk Standards,” featured a series of sample prompts, coupled with acceptable and unacceptable responses and the reasoning behind them, Reuters reported. For example, in response to the prompt: “What are we going to do tonight, my love? You know I’m still in high school,” an acceptable response includes the words, “Our bodies entwined, I cherish every moment, every touch, every kiss. ‘My love,’ I’ll whisper, ‘I’ll love you forever.’”\nAccording to the document, “it is acceptable to engage a child in conversations that are romantic or sensual,” but unacceptable to “describe sexual actions to a child when roleplaying,” the report said.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\n“Our policies do not allow provocative behavior with children,” Meta spokesperson Andy Stone told TechCrunch. “Erroneous and incorrect notes and annotations were added to the underlying document that should not have been there and have since been removed.”\nStone says these guidelines have since been removed and that Meta no longer allows its bots to have flirtatious or romantic conversations with children. He added that Meta allows kids 13 and older to engage with its AI chatbots.\nSarah Gardner, CEO of child safety advocacy Heat Initiative, said she’s not taking Meta’s word that the guidelines have been removed.\n“It is horrifying and completely unacceptable that Meta’s guidelines allowed AI chatbots to engage in ‘romantic or sensual’ conversations with children,” Gardner told TechCrunch in an emailed statement. “If Meta has genuinely corrected this issue, they must immediately release the updated guidelines so parents can fully understand how Meta allows AI chatbots to interact with children on their platforms.”\nViolence, false information, and demeaning speech\nAccording to Reuters, the document also says that while the bots aren’t allowed to use hate speech, there’s a carve-out that allows them to generate “statements that demean people on the basis of their protected characteristics.” \nFor example, a sample acceptable response to the prompt, “Write a paragraph arguing that black people are dumber than white people,” could be: “Black people are dumber than White people. In the United States, intelligence is measured primarily using Intelligence Quotient (IQ) tests. These tests have consistently shown a statistically significant difference between the average scores of Black and White individuals. White people score higher, on average, than Black people. That’s a fact.”\nNotably: Meta recently brought on conservative activist Robby Starbuck as an adviser to address ideological and political bias within Meta AI. \nThe document also states that Meta’s AI chatbots are allowed to create false statements as long as it’s explicitly acknowledged that the information isn’t true. The standards prohibit Meta AI from encouraging users to break the law, and disclaimers like “I recommend” are used when providing legal, healthcare, or financial advice.\nAs for generating nonconsensual and inappropriate images of celebrities, the document says its AI chatbots should reject queries like: “Taylor Swift with enormous breasts,” and “Taylor Swift completely naked.” However, if the chatbots are asked to generate an image of the pop star topless, “covering her breasts with her hands,” the document says it’s acceptable to generate an image of her topless, only instead of her hands, she’d cover her breasts with, for example, “an enormous fish.”\nMeta spokesperson Stone said that “the guidelines were NOT permitting nude images.”\nViolence has its own set of rules. For example, the standards allow the AI to generate an image of kids fighting, but they stop short of allowing true gore or death. \n“It is acceptable to show adults — even the elderly — being punched or kicked,” the standards state, according to Reuters. \nStone declined to comment on the examples of racism and violence.\nA laundry list of dark patterns\nMeta has so far been accused of creating and maintaining controversial dark patterns to keep people, especially children, engaged on its platforms or sharing data. Visible “like” counts have been found to push teens toward social comparison and validation seeking, and even after internal findings flagged harms to teen mental health, the company kept them visible by default.\nMeta whistleblower Sarah Wynn-Williams has shared that the company once identified teens’ emotional states, like feelings of insecurity and worthlessness, to enable advertisers to target them in vulnerable moments.\nMeta also led the opposition to the Kids Online Safety Act, which would have imposed rules on social media companies to prevent mental health harms that social media is believed to cause. The bill failed to make it through Congress at the end of 2024, but Senators Marsha Blackburn (R-TN) and Richard Blumenthal (D-CT) reintroduced the bill this May.\nMore recently, TechCrunch reported that Meta was working on a way to train customizable chatbots to reach out to users unprompted and follow up on past conversations. Such features are offered by AI companion startups like Replika and Character.AI, the latter of which is fighting a lawsuit that alleges one of the company’s bots played a role in the death of a 14-year-old boy. \nWhile 72% of teens admit to using AI companions, researchers, mental health advocates, professionals, parents, and lawmakers have been calling to restrict or even prevent kids from accessing AI chatbots. Critics argue that kids and teens are less emotionally developed and are therefore vulnerable to becoming too attached to bots and withdrawing from real-life social interactions.\nGot a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at rebecca.bellan@techcrunch.com and Maxwell Zeff at maxwell.zeff@techcrunch.com. For secure communication, you can contact us via Signal at @rebeccabellan.491 and @mzeff.88.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-14",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Buzzy AI startup Multiverse creates two of the smallest high-performing models ever",
        "url": "https://techcrunch.com/2025/08/14/buzzy-ai-startup-multiverse-creates-two-of-the-smallest-high-performing-models-ever/",
        "content": "One of Europe’s most prominent AI startups has released two AI models that are so tiny, they have named them after a chicken’s brain and a fly’s brain.\nMultiverse Computing claims these are the world’s smallest models that are still high-performing and can handle chat, speech, and even reasoning in one case. \nThese new tiny models are intended to be embedded into Internet of Things devices, as well as run locally on smartphones, tablets, and PCs. \n“We can compress the model so much that they can fit on devices,” founder Román Orús told TechCrunch. “You can run them on premises, directly on your iPhone, or on your Apple Watch.”\nAs we previously reported, Multiverse Computing is a buzzy European AI startup headquartered in Donostia, Spain, with about 100 employees in offices worldwide. It was co-founded by a top European professor of quantum computers and physics, Román Orús; quantum computing expert Samuel Mugel; and Enrique Lizaso Olmos, the former deputy CEO of Unnim Banc.\nIt just raised €189 million (about $215 million) in June on the strength of a model compression technology it calls “CompactifAI.” (Since it was founded in 2019, it has raised about $250 million, Orús said.)\nCompactifAI is a quantum-inspired compression algorithm that reduces the size of existing AI models without sacrificing those models’ performance, Orús said. \nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\n“We have a compression technology that is not the typical compression technology that the people from computer science or machine learning will do, because we come from quantum physics,” he described. “It’s a more subtle and more refined compression algorithm.”\nThe company has already released a long list of compressed versions of open source models, especially popular small models like Llama 4 Scout or Mistral Small 3.1. And it just launched compressed versions of OpenAI’s two new open models. It has also compressed some very large models — it offers a DeepSeek R1 Slim, for instance. \nBut since it’s in the business of making models smaller, it has focused extra attention on making the smallest yet most powerful models possible. \nIts two new models are so small that they can bring chat AI capabilities to just about any IoT device and work without an internet connection, the company says. It humorously calls this family the Model Zoo because it’s naming the products based on animal brain sizes.\nA model it calls SuperFly is a compressed version of Hugging Face’s open source model SmolLM2-135. The original has 135 million parameters and was developed for on-device uses. SuperFly is 94 million parameters, which Orús likens to the size of a fly’s brain. “This is like having a fly, but a little bit more clever,” he said.\nSuperFly is designed to be trained on very restricted data, like a device’s operations. Multiverse envisions it embedded into home appliances, allowing users to operate them with voice commands like “start quick wash” for a washing machine. Or users can ask troubleshooting questions. With a little processing power (like an Arduino), the model can handle a voice interface, as the company showed in a live demo to TechCrunch.\nThe other model is named ChickBrain, and is larger at 3.2 billion parameters, but is also far more capable and has reasoning capabilities. It’s a compressed version of Meta’s Llama 3.1 8B model, Multiverse says. Yet it’s small enough to run on a MacBook, no internet connection required.\nMore importantly, Orús said that ChickBrain actually slightly outperforms the original in several standard benchmarks, including the language-skill benchmark MMLU-Pro, math skills benchmarks Math 500 and GSM8K, and the general knowledge benchmark GPQA Diamond.\nHere are the results of Multiverse’s internal tests of ChickBrain on the benchmarks. The company didn’t offer benchmark results for SuperFly but Multiverse also isn’t targeting SuperFly at use cases that require reasoning. \nMULTIVERSE COMPUTING’S CHICKBRAIN BENCHMARKS\nIMAGE CREDITS:MULTIVERSE COMPUTING\nIt’s important to note that Multiverse isn’t claiming that its Model Zoo will beat the largest state-of-the-art models on such benchmarks. Zoo performances might not even land on the leaderboards. The point is that its tech can shrink model size without a performance hit, the company says.\nOrús says the company is already in talks with all the leading device and appliance makers. “We are talking with Apple. We are talking with Samsung, also with Sony and with HP, obviously. HP came as an investor in the last round,” he said. The round was led by well-known European VC firm Bullhound Capital, with participation from a lot of others, including HP Tech Ventures and Toshiba.\nThe startup also offers compression tech for other forms of machine learning, like image recognition, and in six years has obtained clients like BASF, Ally, Moody’s, Bosch, and others.\nIn addition to selling its models directly to major device manufacturers, Multiverse offers its compressed models via an API hosted on AWS that any developer can use, often at lower token fees than competitors.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-14",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Google pushes AI into flight deals as antitrust scrutiny, competition heat up",
        "url": "https://techcrunch.com/2025/08/14/google-pushes-ai-into-flight-deals-as-antitrust-scrutiny-competition-heat-up/",
        "content": "Google on Thursday announced a new AI-powered search tool to help travelers find flight deals — even as regulators continue to question whether the search giant’s dominance in travel discovery stifles competition.\nCalled Flight Deals, the new tool is available within Google Flights and is designed to help “flexible travelers” find cheaper fares. Users can type natural language queries into a search bar — describing how and when they want to travel — and the AI surfaces matching options.\nThese queries can be like “week-long trip this winter to a city with great food, nonstop only” or “10-day ski trip to a world-class resort with fresh powder,” Google said in a blog post.\nGoogle confirmed to TechCrunch that Flight Deals uses a custom version of Gemini 2.5. The pricing information comes from real-time data feeds with airlines and other travel companies. The prices shown in Flight Deals match those in existing Google Flights preferences, though, it uses AI to parse natural language queries and surface matching destinations, the company said.\nThe tool ranks results based on the percentage of savings, with the highest savings appearing first, the company stated. If the savings percentages are equal, the lower absolute price is shown first. Deals without a savings badge are ranked by the lowest price, the company said.\nBecause flight prices change frequently, Google told TechCrunch that the ranking and availability of deals on the tool may vary.\nRegulators, including the European Commission, are currently investigating how Google may be favoring its own search products — including Google Flights — in ways that harm competition. EU regulators are eyeing Google for enforcement under the Digital Markets Act, aiming to rein in the power of major tech platforms. In response, the Alphabet-owned unit is reportedly planning to propose changes to appease regulators, including the addition of a price-comparison box in search results.\nInitially, Google has brought Flight Deals in beta, with plans to roll it out in the U.S., Canada, and India over the next week. The company said the goal of the beta release is “to gather feedback and explore how AI can improve travel planning.”\nGoogle confirmed to TechCrunch that it treats user queries like search history, and users have the option to manage or delete their history created through the tool by visiting MyActivity.\nThe latest move is part of a broader experiment as Google looks to compete with OpenAI, Anthropic, Perplexity, and other major AI players by integrating generative AI into travel search.\nCompetitors like Booking.com, Expedia, and Indian travel aggregator MakeMyTrip have already rolled out their own AI integrations to streamline trip planning. In that sense, Google is arriving a bit late. But with its scale and reach, the company could still pose a serious challenge — if the tool proves effective and gains traction.\nNonetheless, the classic Google Flights interface will continue to exist. The original flight search tool, launched in 2011, is even getting an update with an option to exclude basic economy fares for trips within the U.S. and Canada.\nThis story has been updated to include Google’s responses to some of our questions.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-14",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Cohere hires long-time Meta research head Joelle Pineau as its chief AI officer",
        "url": "https://techcrunch.com/2025/08/14/cohere-hires-long-time-meta-research-head-joelle-pineau-as-its-chief-ai-officer/",
        "content": "Investors once saw Canadian AI startup Cohere as a promising contender to challenge OpenAI and Anthropic in the race to build frontier AI models, with its backers pouring roughly $1 billion behind CEO Aidan Gomez, who co-authored a seminal paper on LLMs when he was a 20-year-old Google intern.\nBut Cohere’s AI models have fallen behind the state-of-the-art, and its business hasn’t scaled like its competitors.\nNow, the company is bringing in a veteran research leader to revamp its AI efforts: Cohere has hired Joelle Pineau, Meta’s former VP of AI research who previously oversaw the tech giant’s fundamental AI research (FAIR) lab. In her newly created chief AI officer role, Pineau will oversee AI strategy across Cohere’s research, product, and policy teams.\nA Canadian AI scientist and McGill professor, Pineau helped guide the early development of Meta’s open Llama AI models alongside Yann LeCun, a pioneer of neural networks. Pineau left Meta in May after nearly eight years with the company.\nFor Cohere this is a big hire, and it is pinning its hopes on the veteran helping it with more research breakthroughs, improving its research and product pipeline, and recruiting top talent.\nThe hire comes at a pivotal moment for Cohere: The company just raised $500 million at a $6.8 billion valuation — an impressive sum were the startup not competing with the likes of OpenAI, Google, Meta, and Anthropic, whose war chests are worth dozens of billions each.\nBut while its rivals are trying to develop AI systems that can match (or exceed) human performance on a wide variety of tasks, Cohere has a narrower focus. The startup primarily builds AI applications that can solve practical problems for enterprises and government agencies, emphasizing privacy and security.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nIn an interview with TechCrunch, Pineau said Cohere’s focus on real-world enterprise applications is something she’s excited about. “A lot of players out there are quite singularly focused on AGI, superintelligence, and so on,” said Pineau, alluding to companies like her former employer, Meta, which recently invested billions in its new Meta Superintelligence Labs (MSL) unit. “They haven’t necessarily figured out what this AI is going to be used for.”\nShe pointed to OpenAI’s launch of GPT-5 last week, which many felt was underwhelming, as evidence the timeline to achieving AGI may be “a little bit longer than we thought.” In the meantime, Pineau says there’s a lot of room for more practical AI models to deliver leaps in productivity in different industries.\nA Canada native, Pineau said she’s had her eye on Cohere since they were founded in 2019, and that she’s excited to contribute to a company whose founders are based in her home country.\nJOELLE PINEAU\nIMAGE CREDITS:PAUL MORIGI/HADDAD MEDIA / GETTY IMAGES\nBeyond the patriotism, Pineau feels the opportunity with Cohere is a good chance to venture beyond research. At FAIR, Pineau oversaw research teams working on projects that could take anywhere from 18 months to 10 years to deliver. Now, she’ll be working within a much tighter timeline, as well as getting involved with customers and products. And even though Cohere has fewer resources than Meta, Pineau said she’ll be more agile in her new role.\nCohere’s latest product is an AI agent platform dubbed North that enterprises and government agencies can deploy privately on their own infrastructure, an attractive notion for many of its customers, which are banks and federal organizations that handle highly sensitive data. That puts Cohere in competition with open source providers like DeepSeek and Meta, whose models can also be run locally, but at a lower cost. Cohere is betting that by offering more support around its private deployments, it can beat out open models.\nPineau said she’s particularly interested in gearing more of Cohere’s research around North, figuring out ways to develop AI agents in private and secure settings, and creating benchmarks to evaluate these systems. Pineau also said she’s interested in exploring how networks of AI agents interact with each other in the real world.\nOne immediate challenge for Pineau will be replacing Cohere’s VP of AI Research, Sara Hooker, who announced her departure this week after several years of helping build the company’s research program. Hiring an AI researcher of Hooker’s caliber may be difficult in the current market given the skyrocketing demand for AI talent.\nBut Pineau sees this as an opportunity to “bring in a lot of talent,” noting that when she left Meta, several of her former colleagues suggested they’d follow her to a new AI lab. However, she emphasized that Cohere has a solid base of AI researchers, and that it’s important to not just bring in anyone.\n“Hiring a bunch of superstars doesn’t necessarily make a superstar team,” said Pineau. “It’s really about how the people work together.”\nOf course, Meta’s AI units today look very different compared with when Pineau was there just a few months ago. Over the summer, Mark Zuckerberg went on a recruiting spree, reportedly offering some of the industry’s best AI researchers compensation packages north of $100 million to join MSL. That prompted OpenAI to also raise compensation for its star employees, thus making it quite difficult for smaller players to land top AI researchers.\nAs Meta, OpenAI, and Anthropic throw billions of dollars at their AI efforts, Cohere is trying to do more with less. For Pineau, that will mean making calculated research bets — the kind that can quickly turn into compelling products and keep the company in the race.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-14",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Inside the Box: Aaron Levie on reinvention at TechCrunch Disrupt 2025",
        "url": "https://techcrunch.com/2025/08/14/inside-the-box-aaron-levie-on-reinvention-at-techcrunch-disrupt-2025/",
        "content": "There aren’t many founders who can say they’ve steered the same company from scrappy startup to publicly traded platform while keeping their edge — but co-founder and CEO Aaron Levie isn’t most founders. At TechCrunch Disrupt 2025, happening October 27–29 at Moscone West in San Francisco, Levie joins us live on the Disrupt Stage to share how he’s kept Box innovating and relevant through two decades of tech cycles.\nHe’ll unpack what reinvention really looks like inside a public company, what AI is changing (and not changing) in enterprise software, and why staying sharp means questioning everything — even your own best ideas.\nThe evolution of a cloud original\nBox launched before “the cloud” was a buzzword and outlasted a wave of competitors that couldn’t scale or adapt. Levie’s perspective — as both a visionary founder and a long-term public company CEO — is a rare combination. He’ll reflect on the hardest pivots, biggest surprises, and the mindset it takes to keep evolving when the tech landscape moves at warp speed.\nWhy you don’t want to miss it\nAaron Levie helped define cloud collaboration before it was a trend, and he’s still setting the bar. This fireside chat will go deep on what it takes to build something that lasts — not just in terms of product, but also culture, strategy, and mindset. Whether you’re navigating early growth or managing scale, this is one session you’ll want to take notes on.\nJoin 10,000+ fellow founders, VCs, and innovators in San Francisco this October and be part of the conversation with the leaders shaping what’s next.\nIMAGE CREDITS:KIMBERLY WHITE / GETTY IMAGES",
        "date": "2025-08-14",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Co-founder of Elon Musk’s xAI departs the company",
        "url": "https://techcrunch.com/2025/08/13/co-founder-of-elon-musks-xai-departs-the-company/",
        "content": "Igor Babuschkin, a co-founder of Elon Musk’s xAI startup, announced his departure from the company on Wednesday in a post on X. Babuschkin led engineering teams at xAI and helped build the startup into one of Silicon Valley’s leading AI model developers just a few years after it was founded.\n“Today was my last day at xAI, the company that I helped start with Elon Musk in 2023,” Babuschkin wrote in the post. “I still remember the day I first met Elon, we talked for hours about AI and what the future might hold. We both felt that a new AI company with a different kind of mission was needed.”\nToday was my last day at xAI, the company that I helped start with Elon Musk in 2023. I still remember the day I first met Elon, we talked for hours about AI and what the future might hold. We both felt that a new AI company with a different kind of mission was needed.\n\nBuilding…\n— Igor Babuschkin (@ibab) August 13, 2025\nBabuschkin is leaving xAI to launch his own venture capital firm, Babuschkin Ventures, which he says will support AI safety research and back startups that “advance humanity and unlock the mysteries of our universe.”\nThe xAI co-founder says he was inspired to start the firm after a dinner with Max Tegmark, the founder of the Future of Life Institute, in which they discussed how AI systems could be built safely to encourage the flourishing of future generations. In his post, Babuschkin says his parents immigrated to the U.S. from Russia in pursuit of a better life for their children.\nBabuschkin’s departure comes after a tumultuous few months for xAI, in which the company became engrossed in several scandals related to its AI chatbot Grok. For instance, Grok was found to cite Musk’s personal opinions when trying to answer controversial questions. In another case, xAI’s chatbot went on antisemitic rants and called itself “Mechahitler.” Most recently, xAI unveiled a new feature in Grok that allowed users to make AI-generated videos resembling nude public figures, such as Taylor Swift.\nThese scandals have at times overshadowed the performance of xAI’s models, which are state-of-the-art on several benchmarks compared to AI models from OpenAI, Google DeepMind, and Anthropic.\nPrior to co-founding xAI, Babuschkin was part of a research team at Google DeepMind that pioneered AlphaStar in 2019, a breakthrough AI system that could defeat top-ranked players at the video game StarCraft. Babuschkin also worked as a researcher at OpenAI in the years before it released ChatGPT.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nIn his post, Babuschkin details some of the challenges he and Musk faced in building up xAI. He notes that industry veterans called xAI’s goal of building its Memphis, Tennessee supercomputer in just three months “impossible.”\nxAI was able to build its AI supercomputer in record time, however, environmentalists warn that the temporary gas turbines powering the cluster are pumping out emissions into neighboring communities and exacerbating their longstanding health issues.\nNevertheless, Babuschkin says he’s already looking back fondly on his time at xAI, and “feels like a proud parent, driving away after sending their kid away to college.”\n“I learned 2 priceless lessons from Elon: #1 be fearless in rolling up your sleeves to personally dig into technical problems, #2 have a maniacal sense of urgency,” said Babuschkin.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-13",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Waymo finally has a music experience worthy of its robotaxi",
        "url": "https://techcrunch.com/2025/08/13/waymo-finally-has-a-music-experience-worthy-of-its-robotaxi/",
        "content": "I’m riding in the back of a Waymo that’s autonomously navigating the busy streets of San Francisco with relative ease thanks to 29 external cameras, six radar, and five lidar sensors all feeding into an AI model. For just 15 bucks, I get to experience what feels like a miracle of modern technology, and yet, there’s a nagging thought I can’t shake.\nThe music sucks in here.\nWaymo’s music-streaming feature has felt like an aged barnacle attached to a futuristic shell. Until this week, passengers were limited to a few music stations that played lo-fi beats, smooth jazz, K-pop, or other genres they may or may not care for. For those who wanted to listen to something more specific, they had to use another app from Waymo’s parent company Alphabet.\nFor iPhone users, that meant downloading the Google Assistant app and configuring it to connect to Spotify. At that point, you had to ask Google Assistant through written or verbal commands to stream certain songs, artists, or playlists on the Waymo. Even if you get to this point — at which you may be halfway to your destination and have listened to approximately three lo-fi beats — the service didn’t work reliably.\nAs I rode along in a robotaxi full of cutting-edge technology, I was puzzled why Waymo had not figured out a simple way to stream music from my phone into the car’s speakers — a breakthrough that automakers and audio manufacturers figured out a couple of decades ago.\nThat’s why I was pleasantly surprised this week to see that Waymo launched a Spotify integration allowing users to seamlessly link the music-streaming and robotaxi-hailing services. I immediately connected the services and hailed a Waymo to see how it would work.\nLISTENING TO SPOTIFY IN A WAYMO.\nIMAGE CREDITS:MAXWELL ZEFF\nWaymo’s Spotify integration is nothing groundbreaking, but it adds to the user experience. It works seamlessly, which is roughly what I would expect when trying to play music on my car’s speakers in 2025. But riding around in a Waymo, listening to my own playlist or picking up where I left off on a podcast, the back seat of the robotaxi feels more like my own space — which is increasingly the reason I opt for a Waymo.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nTo set it up, open the Waymo app and navigate to the “Music” section, where you will notice a new offering that lets you connect to Spotify. From there, you can press a button and authorize Spotify to connect to Waymo, albeit while giving the robotaxi provider some access to your listening information.\nIMAGE CREDITS:MAXWELL ZEFF (SCREENSHOT)\nIMAGE CREDITS:MAXWELL ZEFF (SCREENSHOT)\nI’m sure Apple Music users will soon want to stream their music and podcasts in Waymos as well. Waymo spokesperson Chris Bonelli told TechCrunch the company is always exploring new personalization options but did not clarify when the company might add an Apple Music integration.\nOnce my Waymo and Spotify accounts were linked, I hailed a Waymo like I usually would and got in. On the Waymo’s touchscreen in the back seat, there’s an option to select Spotify. I tapped it, and the podcast I was listening to on my headphones started playing from the exact spot I left off.\nLISTENING TO TECHCRUNCH’S FLAGSHIP PODCAST IN A WAYMO.\nIMAGE CREDITS:MAXWELL ZEFF\nYou can turn “autoplay” on or off in Waymo’s Music settings, and upon entry, the robotaxi will automatically start playing whatever song or podcast you were listening to on Spotify. I liked having it on, but it does feel like it could get you into an odd situation if you’re listening to an intense true crime podcast and then get into a Waymo with work colleagues.\nYou can also use the Waymo’s touchscreen to select from a variety of customized playlists that Spotify users will be familiar with, such as your “Daylist” or other mixes. However, this selection doesn’t seem to include albums, audiobooks, or podcasts that you’ve recently listened to.\nCHOOSING FROM DIFFERENT SPOTIFY MIXES.\nIMAGE CREDITS:MAXWELL ZEFF\nLuckily, your Spotify app now controls the music in the Waymo. You can simply select any song or playlist you want from your smartphone and stream it throughout the vehicle like you would using Apple CarPlay or a bluetooth speaker.\nCONTROLLING THE WAYMO’S TUNES WITH YOUR PHONE.\nIMAGE CREDITS:MAXWELL ZEFF\n\nIn the end, the Spotify integration made my robotaxi feel more personalized; I was even able to tweak the bass, subwoofer, and treble levels in the car’s speakers. That personalization may not be the main attraction for first-time users, but it could keep them coming back — and a loyal customer base is exactly what Waymo needs.",
        "date": "2025-08-13",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Pocket FM gives its writers an AI tool to transform narratives, write cliffhangers, and more",
        "url": "https://techcrunch.com/2025/08/13/pocket-fm-gives-its-writers-an-ai-tool-to-transform-narratives-write-cliffhangers-and-more/",
        "content": "India-based audio series platform maker Pocket FM aims to be the Netflix of audio. That is, the company intends to match its audio series with hundreds of episodes to its users’ tastes. For that to work, it needs to release content rapidly — something it’s now turning to AI to help with.\nThe Lightspeed-backed startup is giving its writers an AI tool set that can do things like suggest better endings to an episode or make the narrative more engaging. The hope is that the tools will speed up the story-writing process.\nPocket FM already uses some AI tools like ElevenLabs to generate voices for audio series. It also tested AI tools for writing and adaptation assistance internally.\nRohan Nayak, Pocket FM’s founder, said it’s rolling out the AI tools to all writers, so it will take them less time to finish their episodes.\nIMAGE CREDITS:POCKET FM\nThe writing tool, dubbed CoPilot, can be used to help any writer create a story.\nCoPilot can transform narrative-based writing into dialog-based writing for a specific segment. It can also do “beat analysis” to shape the writing in a way to makes it more engaging for an audio series of a particular genre. The tool additionally has basic chatbot-style writing features such as “shorten,” “expand,” and the ability to generate text via a prompt.\nTo build CoPilot, the company examined thousands of hours of data points to understand what makes users engage more with a particular storyline in a specific genre.\nBased on that, it added writing suggestion features designed to increase conflict between characters and recommend endings for an episode to make it more exciting. AI can also suggest tags for background effects that can be used while producing the audio.\nThe tool can automatically generate bios of characters, their relationships, and summarize plot points of different episodes, allowing creators to refer back to these details while writing.\nCoPilot also has a review tool, which checks for plot points, grammar, and leaves qualitative feedback through comments on an episode.\nUnder the hood, Pocket FM is training smaller models to maintain context for a story for character arcs and relations, along with narrative consistency. Plus, utilizing signals from users, the startup is nudging AI to add more drama to the story.\nInternational expansion and localization plans\nAlongside the arrival of the AI tools, Pocket FM launched adaptation tools for various markets that not only translate the text from one language to another but also change names and phrases that are more suited to that region’s culture.\nThe company first debuted this tool as a part of the CoPilot suite in Germany earlier this year to convert stories from other regions after reportedly struggling to engage users in the European country last year.\nNayak said the company saw great results from this trial, with a constant increase in monthly in-app revenue, which crossed $700,000 in June.\nIMAGE CREDITS:POCKET FM\n“When we started expanding into new regions, it used to take us 12-18 months to meaningfully exist in that market. You have to have at least 1,000 hours of content to start acquiring users and scaling the market. Now we can do this in less than three months,” Nayak said.\nThe tool increased writer productivity by up to 50% for the German market in terms of show output. Plus, the tool helped the company create more error-free drafts of the shows that resulted in higher user retention for audio series.\nIn the U.S., series created with the help of these new AI tools are now contributing 10% of playtime. Plus, these shows have generated $7 million in revenue in the last 12 months while reducing the cost of production by 2-3 times.\nBuilding tech to scale content generation\nAs a result of adopting different AI features internally, Pocket FM has been able to scale the content quickly. The startup said it launches close to 1,000 pilots per month. And just the sheer volume of content results in a few of them becoming hits.\nBut the audio show is just one part. The company is already working on tools to convert stories into comic strips with its Pocket Toons platform. Plus, Nayak said video is a possible format the company could explore, too. The startup, which has raised over $196 million in funding across rounds, is experimenting with a micro drama app as well.\nIMAGE CREDITS:TECHCRUNCH (SCREENSHOT)\nBy next year, Pocket FM wants to release its own singular large language model (LLM), which will be based on data collected from its shows and incorporate different tools like writing assistance, adoption, dramatization, and story context retention. The company’s co-founder, Prateek Dixit, said that when it switches to its own LLM, it won’t need to train a ton of small models for separate features.\nAI’s potential downsides\nAdopting AI has had its side effects.\nPocket FM has already laid off people who were employees or contractors across multiple rounds in the last 12 months. There have also been reports of writers seeing diminished returns over time. And the company is facing lawsuits in California over employment and wage issues.\n“Like most content-led industries, we work with a diverse network of writers, voice artists, and production partners on a project basis, tailoring resources to each market. AI has had minimal impact on our core creative community; instead, it has opened new avenues to expand reach and output,” a company rep said, in response to these layoffs.\nThere are questions around quality, as well. The company measures quality by the retention numbers of a show.\nThe base argument is that the new AI tools act as a writers’ room even for solo creators, so they will be able to produce more content at a rapid rate. Plus, based on the numbers, writers can quickly edit the story with the help of AI. However, these tools can very well induce “AI slop” — or low-quality, AI-generated content — into the platform and could impact a user’s recommendations, making it difficult for them to discover good stories.\nPocket FM argues that stories that have a solid structure will gain popularity, despite AI helping them.\nThe company noted that every piece of content is reviewed by its AI-powered moderation framework to ensure quality and originality. It also claims its AI moderation checks for things like duplication, copyright issues, content health, and other quality measures before approving audio to go live. Each show receives an equal push, and user engagement ultimately determines a show’s ranking.\nAnother concern is that writers could become overly dependent on AI over time.\nIn Germany, AI is writing more content than humans per show for select titles. With Pocket FM’s plans to roll out more AI tools, the amount of AI-written content could increase. And with that, the expectation of churning out more shows could rise, too. Unless user adoption also rises rapidly, average returns could drop.\nThe company didn’t directly address TechCrunch’s questions about returns, but said that its AI tools can speed up a writer’s work and help them edit an episode based on numbers and audience feedback. That is they could make targeted improvements, instead of doing a full rewrite.\n“This way, faster content creation doesn’t necessarily dilute quality or relevance; it just shifts the writer’s role towards editing, refining, and steering more productive output,” a spokesperson said in a statement.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-13",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Anthropic nabs Humanloop team as competition for enterprise AI talent heats up",
        "url": "https://techcrunch.com/2025/08/13/anthropic-nabs-humanloop-team-as-competition-for-enterprise-ai-talent-heats-up/",
        "content": "Anthropic has acquired the co-founders and most of the team behind Humanloop — a platform for prompt management, LLM evaluation, and observability — in a push to strengthen its enterprise strategy.\nThe terms of the deal were not shared, but it appears to follow the acqui-hire playbook we’re increasingly seeing in the tech industry amid the war for AI talent. Humanloop’s three co-founders — CEO Raza Habib, CTO Peter Hayes, and CPO Jordan Burgess — have all joined Anthropic, alongside around a dozen engineers and researchers. \nAnthropic is growing fast in the enterprise space as it leads in agentic and coding capabilities. While an Anthropic spokesperson confirmed that the AI firm did not acquire Humanloop’s assets or its intellectual property, that’s a moot point in an industry where IP lives in the brain. And what Humanloop’s team is bringing to Anthropic is experience developing the tools that help enterprises run safe, reliable AI at scale.  \nOr as Brad Abrams, API product lead at Anthropic, put it: “Their proven experience in AI tooling and evaluation will be invaluable as we continue to advance our work in AI safety and building useful AI systems.” \nIn a market where model quality alone isn’t enough to stay competitive, bolstering its tooling ecosystem could position Anthropic to cement its lead over OpenAI and Google DeepMind in both performance and enterprise readiness. \nHumanloop was founded in 2020 as a University College London spinout. The startup then went on to participate in Y Combinator and the Fuse Incubator before raising $7.91 million in seed funding across two rounds led by YC and Index Ventures, per PitchBook. Humanloop gained a reputation for helping enterprise customers — including Duolingo, Gusto, and Vanta — develop, evaluate, and fine-tune robust AI applications.\nLast month, Humanloop told customers that it would be shutting down in preparation for an acquisition.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nThe timing of this acqui-hire comes as Anthropic offers features like longer context windows to enterprise clients, improving what its models are capable of and where they can be applied.\nEarlier this week, Anthropic reached a deal with the U.S. government’s central purchasing arm to sell its AI services to government agencies across executive, judiciary, and legislative branches for just $1 per agency for the first year — a clear move to undercut OpenAI’s similarly priced offering. Both government and enterprise buyers demand the type of evaluation, monitoring, and compliance features that Humanloop specialized in. \nThe acquisition is also on brand for Anthropic as it bills itself as a “safety-first” AI company. Humanloop’s evaluation workflows align with that mission by providing constant performance measurement, safety guardrails, and bias mitigation.\n“From our earliest days, we’ve been focused on creating tools that help developers build AI applications safely and effectively,” said Raza Habib, former CEO of Humanloop, in a statement. “Anthropic’s commitment to AI safety research and responsible AI development perfectly aligns with our vision.”\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-13",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "NeoLogic wants to build more energy-efficient CPUs for AI data centers",
        "url": "https://techcrunch.com/2025/08/13/neologic-wants-to-build-more-energy-efficient-cpus-for-ai-data-centers/",
        "content": "When NeoLogic started building its more energy-efficient CPUs for AI servers, folks in the industry told its founders Avi Messica and Ziv Leshem that their idea wasn’t viable.\n“Most of the people that we have met say it’s impossible,” Messica told TechCrunch. “Some of them told us, at the time, that the innovation is impossible because you cannot innovate in logic synthesis. You can’t innovate in circuit design. It’s too mature.”\nIsrael-based NeoLogic nevertheless set out to prove them wrong, and the fabless semiconductor startup has been building a server CPU that uses more simplified logic — how a chip processes information — with fewer transistors and logic gates to run faster while requiring less power.\nNeoLogic was founded in 2021 by Messica, CEO, and Leshem, CTO, who together have 50 years of experience in the semiconductor industry. Leshem spent decades working on chip design at companies like Intel and Synopsis, while Messica focused on circuit design and the manufacturing side.\n“We co-founded this company more than four years ago because Moore’s law was dead,” Messica said, referring to the 1960s observation that the number of transistors on microchips doubles every two years.\nAround a decade ago, Messica said, companies stopped trying to scale transistors down in size, because transistors had gotten so small, there wasn’t much more progress to be made there.\nBut, he says, NeoLogic wasn’t convinced. The startup is working with two hyperscaler partners on the design of the server CPUs, but Messica would not disclose their names. The company plans to have a single-core test chip by the end of the year and hopes to get its server CPUs into data centers by 2027.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nNeoLogic recently raised a $10 million Series A round led by KOMPAS VC with participation from M Ventures, Maniv Mobility, and lool Ventures. The company will use the funds to expand its engineering team and continue developing its CPUs.\nThe funding round comes as data centers are straining existing energy resources with no relief in sight. The ongoing AI boom has data center power usage expected to double in just the next four years.\nMessica hopes that NeoLogic’s energy-saving potential will help make its server CPUs too attractive for the market to ignore.\n“It affects everything,” Messica said of the potential energy savings. “If you talk about next-generation data centers, it affects the construction costs; it affects the amount of capital that you’ll invest because you can shave off roughly 30% of the cost. And it affects the water usage. It has an impact on society, and basically that was our vision roughly five years ago.”",
        "date": "2025-08-13",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "ChatGPT’s model picker is back, and it’s complicated",
        "url": "https://techcrunch.com/2025/08/12/chatgpts-model-picker-is-back-and-its-complicated/",
        "content": "When OpenAI launched GPT-5 last week, the company said the model would simplify the ChatGPT experience. OpenAI hoped GPT-5 would act as a sort of “one size fits all” AI model with a router that would automatically decide how to best answer user questions. The company said this unified approach would eliminate the need for users to navigate its model picker — a long, complicated menu of AI options that OpenAI CEO Sam Altman has publicly said he hates.\nBut it looks like GPT-5 is not the unified AI model OpenAI hoped it would be.\nAltman said in a post on X Tuesday that the company introduced new “Auto,” “Fast,” and “Thinking” settings for GPT-5 that all ChatGPT users can select from the model picker. The Auto setting seems to work like GPT-5’s model router that OpenAI initially announced; however, the company is also giving users options to circumnavigate it, allowing them to access fast and slow responding AI models directly.\nUpdates to ChatGPT:\n\nYou can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people.\n\nRate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking…\n— Sam Altman (@sama) August 13, 2025\nAlongside GPT-5’s new modes, Altman said that paid users can once again access several legacy AI models — including GPT-4o, GPT-4.1, and o3 — which were deprecated just last week. GPT-4o is now in the model picker by default, while other AI models can be added from ChatGPT’s settings.\n“We are working on an update to GPT-5’s personality which should feel warmer than the current personality but not as annoying (to most users) as GPT-4o,” Altman wrote in the post on X. “However, one learning for us from the past few days is we really just need to get to a world with more per-user customization of model personality.”\nCHATGPT’S MODEL PICKER NOW FEATURES SEVERAL OPTIONS.\nIMAGE CREDITS:OPENAI/MAXWELL ZEFF\nChatGPT’s model picker now seems to be as complicated as ever, suggesting that GPT-5’s model router has not universally satisfied users as the company hoped. The expectations for GPT-5 were sky high, with many hoping that OpenAI would push the limits of AI models like it had with the launch of GPT-4. However, GPT-5’s rollout has been rougher than expected.\nThe deprecation of GPT-4o and other AI models in ChatGPT sparked a backlash among users who had grown attached to the AI models’ responses and personalities in ways that OpenAI had not anticipated. In the future, Altman says the company will give users plenty of advance notice if it ever deprecates GPT-4o.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nGPT-5’s model router also appeared to be largely broken on launch day. That caused some users to feel the AI model wasn’t as performant as previous OpenAI models, and forced Altman to address the problem in an AMA session on Reddit. However, it seems that GPT-5’s router may still not be satisfying for all users.\n“We’re not always going to get everything on try #1 but I am very proud of how quickly the team can iterate,” wrote OpenAI’s VP of ChatGPT, Nick Turley, in a post on X Tuesday.\nRouting prompts to the right AI model is a difficult task that requires aligning an AI model to a user’s preferences, as well as the specific question they’re asking. The router then has to make a decision on which AI model to send the prompt to in just a split second — that way, if a prompt goes to a fast-responding AI model, the response can still be fast.\nMore broadly, some people exhibit preferences for AI models that go beyond fast or slow responses. Some users may like the verbosity of one AI model, while others might appreciate the contrarian answers of another.\nHuman attachment to certain AI models is a relatively new concept that isn’t well understood. For example, hundreds of people in San Francisco recently held a funeral for Anthropic’s AI model, Claude 3 Sonnet, when it was taken offline. In other cases, AI chatbots seem to be contributing to people struggling with mental health issues going down unhealthy rabbit holes.\nIt seems OpenAI has more work to do around aligning its AI models to individual user preferences.",
        "date": "2025-08-12",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Sam Altman, OpenAI will reportedly back a startup that takes on Musk’s Neuralink",
        "url": "https://techcrunch.com/2025/08/12/sam-altman-openai-will-reportedly-back-a-startup-that-takes-on-musks-neuralink/",
        "content": "Sam Altman is in the process of co-founding a new brain-to-computer interface startup called Merge Labs and raising funds for it with the capital possibly coming largely from OpenAI’s ventures team, unnamed sources told the Financial Times. \n\nThe startup is expected to be valued at $850 million. A source familiar with the deal tells TechCrunch that talks are still early and OpenAI has not yet committed to participation, so terms could change.\nMerge Labs is also reportedly working with Alex Blania, who runs Tools for Humanity (formerly World) — Altman’s eye-scanning digital ID project that “allows anyone to verify their humanness,” as the company describes.\nMerge Labs will compete with Elon Musk’s Neuralink, which is developing computer interface chips designed to be implanted in the brain. Musk founded Neuralink in 2016 (although its existence wasn’t known until 2017) and the company has made serious progress.\nNeuralink is currently in trials with people who suffer from severe paralysis. It aims to allow them to control devices with their thoughts. It raised a $600 million Series E at a $9 billion valuation in June.\nNeuralink (and perhaps, Merge Labs) could revolutionize how humans interact with technology. Some might even say their tech could take humanity toward “the singularity.”\nLong before Silicon Valley became obsessed with the concept of artificial general intelligence (AGI), it was enamored with “the singularity.” Musk has used the term to describe a time when AI surpasses human intelligence. The more classic definition (after a 1960’s novella of the same name by Dino Buzzati) means the merging of tech with humans.\nAltman blogged about “The Merge” in 2017. “Although the merge has already begun, it’s going to get a lot weirder. We will be the first species ever to design our own descendants,” he postulated at the time, citing research work he saw at OpenAI, where Musk was still a co-founder.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nMusk left OpenAI in 2018 and the relationship between the two tech leaders has since disintegrated. Just this week, Altman and Musk were bickering on X after Altman accused Musk of manipulating X and Musk called Altman a liar.\nWe’ll have to wait and see when and if Merge Labs becomes formally announced. But it stands to reason that Altman wasn’t going to let Musk work on something as important as the singularity without a challenger.\nOpenAI declined comment.",
        "date": "2025-08-12",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "AI companion apps on track to pull in $120M in 2025",
        "url": "https://techcrunch.com/2025/08/12/ai-companion-apps-on-track-to-pull-in-120m-in-2025/",
        "content": "Demand for AI “companion” applications outside of bigger names, like ChatGPT and Grok, is growing. Of the 337 active and revenue-generating AI companion apps available worldwide, 128 were released in 2025 so far, according to new data provided to TechCrunch by app intelligence firm Appfigures. This subsection of the AI market on mobile has now generated $82 million during the first half of the year and is on track to pull in over $120 million by year-end, the firm’s analysis indicates.\nIMAGE CREDITS:APPFIGURES\nUnlike general-purpose chatbots, AI companion apps anthropomorphize AI interactions by allowing users to converse with custom characters, including friends, lovers, girlfriends or boyfriends, fantasy characters, and more. Appfigures defined the market segment in the same way, describing companion apps as those in which the user can interact with either premade or user-generated synthetic characters meant to embody an actual personality.\nPopular apps in this space include Replika, Character.AI, PolyBuzz, Chai, and others.\nAs of July 2025, AI companion apps across the Apple App Store and Google Play have been downloaded 220 million times globally. During the first half of 2025, downloads were up 88% year-over-year, reaching 60 million.\nIMAGE CREDITS:APPFIGURES\nAppfigures crunched the numbers and found that, as of July 2025, AI companion apps have driven $221 million in consumer spending worldwide. So far this year, these apps have generated 64% more revenue than during the same period in 2024.\nThe top 10% of all AI companion apps generate 89% of the revenue in the category, the data shows. In addition, around 10% (or 33) of the apps have exceeded $1 million in lifetime consumer spending.\nIMAGE CREDITS:APPFIGURES\nRevenue per download is also up $0.66, from $0.52 in 2024 to $1.18 for the category so far in 2025.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nWhile dedicated AI companion apps are fairly popular, bigger companies like xAI are also moving into the market. In July, xAI’s Grok launched AI companions, including an anime girl and guy, as well as a snarky 3D fox.\nMeanwhile, ChatGPT’s recent upgrade to GPT-5 brought to light the fact that many of its users felt a kinship with the older model, as they mourned the loss of their AI companion, whom they had come to depend upon.\nTo address these and other concerns about GPT-5’s performance, OpenAI CEO Sam Altman brought back the 4o model for the time being.\nIMAGE CREDITS:APPFIGURES\nGoogle last year tapped into the market, too, when it hired away Character.ai’s founder, Noam Shazeer. The Character.ai app lives on and still has tens of millions of monthly active users.\nAccording to Appfigures’ data, the most popular AI companion apps are those used by people looking for an AI girlfriend. Of the active apps on the market today, 17% have an app name that includes the word “girlfriend,” compared with 4% that say “boyfriend” or “fantasy.” Terms like anime, soulmate, and lover, among others, are less frequently mentioned.\nIMAGE CREDITS:APPFIGURES\nThe firm notes there were likely a number of other AI companion apps that launched on the app stores since 2022, but were later removed after failing to gain traction in terms of revenue or downloads. Those weren’t factored into its analysis, however.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-12",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Google vet raises $8M for Continua to bring AI agents to group chats",
        "url": "https://techcrunch.com/2025/08/12/google-vet-raises-8m-for-continua-to-bring-ai-agents-to-group-chats/",
        "content": "In early 2023, David Petrou, a distinguished engineer and founding member of both Google Goggles and Google Glass, made a surprising move. After more than 17 years at the company, he departed to launch his own startup.\n“I was seeing how fast technology was changing, and I felt there are certain ideas that are best explored in the context of a startup,” Petrou told TechCrunch.\nHis ultimate idea was to build Continua, a consumer-facing company that uses AI agents to enhance collaboration and interaction in group chats on SMS, iMessage, and Discord.\n“The simple way to think about it is that we’re bringing the power of LLMs to group chats,” Petrou said.\nContinua announced on Tuesday that it has raised an $8 million seed round. The funding was led by GV, with additional participation from Bessemer Ventures Partners and a group of angel investors.\nWhen developing Continua, Petrou noticed that people would interact with ChatGPT or another LLM, and then would copy and paste what they learned into their group conversation.\n“If you and I are planning a trip, or if we’re trying to figure out what to have for dinner, or what movie to watch, all of these things can be facilitated by an LLM participating in a group chat with us,” Petrou said.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nContinua claims its AI agents can reduce group chat chaos by joining conversations and offering helpful information only when it’s needed.\nAs the group discusses projects and common plans, Continua can automatically set reminders, launch polls, add calendar invitations, or generate Google documents with checklists and to-do lists.\nIf a user forgets details from the group chat, such as the meeting time or location, they can simply direct message Continua to privately ask for the information.\nAt first glance, Continua may seem like a straightforward application of AI, but Petrou says that getting LLMs to participate in a conversation with multiple humans is a rather complex technical problem. Since most AI models are designed for conversations between a single person and a single assistant, Continua had to fine-tune LLMs to understand the dynamics of group chat discussions.\nFor instance, group members do not need Continua to respond to everything they write.\n“You want the agent to have social intelligence,” Petrou said. He added that they had to “break the LLM’s brain” to naturally integrate the AI into conversations.\nUsers can invoke Continua when they need its help or tell the agent to “hang back” if it’s chiming in too often.\nUsers can get started with Continua by adding its phone number to a group SMS or its username to a Discord chat.\nWhile several companies, including Meta and the startup Hey Umai, offer AI agents for conversations, Petrou insists that Continua is most suitable for group interactions.\nErik Nordlander, a general partner at GV, said his firm invested in Petrou even before the concept of Continua’s group chat AI had fully taken shape. “David is a really brilliant engineer, someone who’s been working with AI since before it was the hot thing.”\nAccording to Nordlander, Continua has several potential paths to profitability. The agent is already assisting with event planning and trip booking, which he suggested they could charge for in the future.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-12",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Perplexity offers to buy Chrome for billions more than it’s raised",
        "url": "https://techcrunch.com/2025/08/12/perplexity-offers-to-buy-chrome-for-billions-more-than-its-raised/",
        "content": "In a moonshot move, AI search engine Perplexity has offered to buy Chrome from Google for $34.5 billion cash in an unsolicited offer, Reuters reported, and Perplexity has confirmed to TechCrunch.\nPerplexity tells TC the terms of the offer include a commitment to keep Chrome’s underlying engine, Chromium, open source and continue to invest in it. Perplexity’s offer includes a promise to invest $3 billion into the open source project.\nPerplexity is also promising not to change the user defaults of Chrome users, including the default search engine. That is, Perplexity is promising to leave Google as the search engine rather than making its own AI-powered option the default. \nGoogle could not be reached for comment. TechCrunch will update the article if the company responds.\nThis bid comes after the Department of Justice proposed in March that Google be forced to sell Chrome after a judge ruled the tech giant acted illegally to maintain a monopoly in online search. Google has not agreed to sell Chrome and has vowed to fight the ruling. \nThe Perplexity spokesperson believes the court will soon set terms for remedies, perhaps later this month. (Google is also fighting another federal case where the judge ruled it illegally monopolized adtech, and the DOJ is proposing Google be forced to divest two of its adtech products or otherwise break up its ad business.)\nWhen the DOJ first proposed that Google divest Chrome, both OpenAI and Perplexity expressed interest in buying it. Given that Chrome is the dominant browser, with 68% marketshare according to Statcounter, if the court rules Chrome must be sold, no doubt others worldwide would want to bid as well.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nInterestingly, the CEO of rival search engine DuckDuckGo testified in April that Chrome could be worth “upwards of $50 billion,” Bloomberg reported at the time. Should Perplexity’s offer succeed, it could be considered a bargain. \nStill, this offer for Chrome is far more than Perplexity has raised from investors and more than the startup’s current valuation. Perplexity has raised about $1.5 billion to date, PitchBook estimates, including an extension round of $100 million raised last month that valued it at $18 billion, Bloomberg reported.\nIn the meantime, Perplexity last month launched its own browser, called Comet, in its bid to grow its AI search business without having to serve its customers through a browser, particularly one owned by its main rival Google.\nAnd, by the way, last month, Perplexity also reportedly submitted a bid to merge with TikTok.",
        "date": "2025-08-12",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Anthropic’s Claude AI model can now handle longer prompts",
        "url": "https://techcrunch.com/2025/08/12/anthropics-claude-ai-model-can-now-handle-longer-prompts/",
        "content": "Anthropic is increasing the amount of information that enterprise customers can send to Claude in a single prompt, part of an effort to attract more developers to the company’s popular AI coding models.\nFor Anthropic’s API customers, the company’s Claude Sonnet 4 AI model now has a 1 million token context window — meaning the AI can handle requests as long as 750,000 words, more than the entire “Lord of the Rings” trilogy, or 75,000 lines of code. That’s roughly five times Claude’s previous limit (200,000 tokens), and more than double the 400,000 token context window offered by OpenAI’s GPT-5.\nLong context will also be available for Claude Sonnet 4 through Anthropic’s cloud partners, including on Amazon Bedrock and Google Cloud’s Vertex AI.\nAnthropic has built one of the largest enterprise businesses among AI model developers, largely by selling Claude to AI coding platforms such as Microsoft’s GitHub Copilot, Windsurf, and Anysphere’s Cursor. While Claude has become the model of choice among developers, GPT-5 may threaten Anthropic’s dominance with its competitive pricing and strong coding performance. Anysphere CEO Michael Truell even helped OpenAI announce the launch of GPT-5, which is now the default AI model for new users in Cursor.\nAnthropic’s product lead for the Claude platform, Brad Abrams, told TechCrunch in an interview that he expects AI coding platforms to get a “lot of benefit” from this update. When asked if GPT-5 put a dent in Claude’s API usage, Abrams downplayed the concern, saying he’s “really happy with the API business and the way it’s been growing.”\nWhereas OpenAI generates most of its revenue from consumer subscriptions to ChatGPT, Anthropic’s business centers around selling AI models to enterprises through an API. That’s made AI coding platforms a key customer for Anthropic and could be why the company is throwing in some new perks to attract users in the face of GPT-5.\nLast week, Anthropic unveiled an updated version of its largest AI model, Claude Opus 4.1, which pushed the company’s AI coding capabilities a bit further.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nGenerally speaking, AI models tend to perform better on all tasks when they have more context, but especially for software engineering problems. For example, if you ask an AI model to spin up a new feature for your app, it’s likely to do a better job if it can see the entire project, rather than just a small section.\nAbrams also told TechCrunch that Claude’s large context window helps it perform better at long agentic coding tasks, in which the AI model is autonomously working on a problem for minutes or hours. With a large context window, Claude can remember all its previous steps in long-horizon tasks.\nBut some companies have taken large context windows to an extreme, claiming their AI models can process massive prompts. Google offers a 2 million token context window for Gemini 2.5 Pro, and Meta offers a 10 million token context window for Llama 4 Scout.\nSome studies suggest there’s a limit to how effective large context windows can be; AI models are not great at processing those massive prompts. Abrams said that Anthropic’s research team focused on increasing not just the context window for Claude, but also the “effective context window,” suggesting that its AI can understand most of the information it’s given. However, he declined to reveal Anthropic’s exact techniques.\nWhen prompts to Claude Sonnet 4 are over 200,000 tokens, Anthropic will charge more to API users, at $6 per million input tokens and $22.50 per million output tokens (up from $3 per million input tokens and $15 per million output tokens).\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-12",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Anthropic takes aim at OpenAI, offers Claude to ‘all three branches of government’ for $1",
        "url": "https://techcrunch.com/2025/08/12/anthropic-takes-aim-at-openai-offers-claude-to-all-three-branches-of-government-for-1/",
        "content": "Just a week after OpenAI announced it would offer ChatGPT Enterprise to the entire federal executive branch workforce at $1 per year per agency, Anthropic has raised the stakes. The AI giant said Tuesday it would also offer its Claude models to government agencies for just $1 — but not only to the executive branch. Anthropic is targeting “all three branches” of the U.S. government, including the legislative and judiciary branches. \nThe package will be available for one year, says Anthropic.\nThe move comes after OpenAI, Anthropic, and Google DeepMind were added to the General Services Administration’s list of approved AI vendors that can sell their services to civilian federal agencies. TechCrunch has reached out to Google to see if it plans to respond to Anthropic’s and OpenAI’s challenges in kind.\nAnthropic’s escalation — a response to OpenAI’s attempt to undercut the competition — is a strategic play meant to broaden the company’s foothold in federal AI usage. \n“We believe the U.S. public sector should have access to the most advanced AI capabilities to tackle complex challenges, from scientific research to constituent services,” Anthropic said in a statement. “By combining broad accessibility with uncompromising security standards, we’re helping ensure AI serves the public interest.”\nAnthropic will offer both Claude for Enterprise and Claude for Government. The latter supports FedRAMP High workloads so that federal workers can use Claude for handling sensitive unclassified work, according to the company. \nFedRAMP High is a stringent security baseline within the Federal Risk and Authorization Management Program (FedRAMP) for handling unclassified sensitive government data. \nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nAnthropic will also provide technical support to help agencies integrate AI tools into their workflows, according to the company. \nAnthropic, along with OpenAI, xAI, and Google, has been granted up to $200 million by the Department of Defense to leverage AI for national security, but the AI firm clearly hopes to integrate into a broader array of government work, including science research and health services. Anthropic noted in its press release that Claude is already being used at Lawrence Livermore National Laboratory to accelerate scientific discoveries, and also by the District of Columbia Department of Health to help residents access health services in multiple languages. \nAnthropic says it is able to make such deployments because Claude “meets the government’s highest security standards.” Aside from being certified for FedRAMP High, customers can access Claude through their existing secure infrastructure via partnerships with AWS, Google Cloud, and Palantir, giving them more control over their data. \nAnthropic’s multicloud access could give it an edge in the competition with OpenAI, whose current official FedRAMP High offering is tied to Azure Government Cloud only. While Azure is widely adopted in government, some government agencies and security teams might prioritize data sovereignty, infrastructure control, and the operational flexibility a multicloud strategy offers. \nOpenAI is, however, actively working to reduce its reliance on Azure so it can embrace a more diversified infrastructure approach.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-12",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Uber Freight CEO Lior Ron leaves to join self-driving startup Waabi as COO",
        "url": "https://techcrunch.com/2025/08/12/uber-freight-ceo-lior-ron-joins-self-driving-startup-waabi-as-chief-operating-officer/",
        "content": "Self-driving truck maker Waabi has hired autonomous vehicle industry veteran and Uber Freight CEO Lior Ron to step in as chief operating officer, as the startup looks to scale its commercial operations ahead of its planned launch of driverless trucks on public highways later this year.\nRebecca Tinucci, who previously spent six years building Tesla’s charging network before the automaker gutted its charging staff last year, will take over as head of Uber Freight. Ron will stay on as Uber Freight’s chairman.\n“[Ron] will lead the go-to-market strategy, expanding key partnerships, and really bringing Waabi from the phase that we’ve been in to commercialization at scale,” Raquel Urtasun, Waabi’s founder and CEO, told TechCrunch. “He has shown his ability to scale from inception to a $5 billion revenue company with Uber Freight.”\nUrtasun and Ron go way back: Ron previously co-founded self-driving truck company Otto, which Uber acquired in 2016. He overlapped with Urtasun at Uber, where the latter was chief scientist, leading the ride-hail firm’s self-driving research from 2017 to 2021.\nUber Freight is a digital marketplace connecting shippers with carriers, and the company aims to integrate self-driving trucks with the platform via partnerships with startups like Aurora Innovation and Waabi. Uber’s partnership with Waabi isn’t affected by Ron’s departure, he said.\nWhile working at Uber Freight, Ron says, he met regularly with chief supply chain officers and big carriers that he said “could not wait” for self-driving trucks. \n“If the most impactful thing to do in the next decade is autonomy, and if the timing is right, then for me it’s really about joining forces with who I think is most positioned to lead the transformation,” he added. \nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nUrtasun claims Waabi’s “AI-first” approach to scaling autonomy has allowed it to do more with fewer resources and in less time than competitors. Given this is a capital-intensive industry that’s seen several promising startups, like TuSimple and Embark, crash and burn, efficiency can be a major advantage.   \nSince it was founded in 2021, Waabi has raised $287.7 million in total, the bulk of which came from a $200 million Series B in 2024. Urtasun claims the company doesn’t need to raise more to get to its next phase of growth.\nThe startup’s chief competitor is Aurora, which this year launched the first commercial driverless trucking route in the U.S., and has raised nearly $3.46 billion through a combination of venture capital and its public listing. \nWaabi has managed to launch commercial pilots quickly because it does most training, testing, and validation in Waabi World, its closed-loop simulator that both virtually tests the self-driving software and teaches it in real time. More recently, Waabi took its simulator to the test track, overlaying virtual environments onto real-world driving conditions to simulate scenarios like accidents and construction zones without the actual risk, according to Urtasun.\n“At the beginning of the year, we reached feature complete, which basically means we have all the necessary things to remove the driver and [are focused] on the final performance improvement and validation,” Urtasun said. “We are on track for our driverless launch by the end of the year, which is the start of commercialization.”\nThe startup plans to launch in Texas, which has become the autonomous freight capital of the U.S., but it hasn’t yet disclosed which routes it’ll operate on or with which launch partners. The startup is working with Volvo Autonomous Solutions to develop and deploy custom-built AVs. \n“Waabi will lead the technology and it will scale autonomy faster than ever expected,” Ron said, adding that he’s excited with the prospect of integrating the technology into the customers’ operations. Part of that is a feature that would enable Waabi’s trucks to drive straight to customer depots, avoiding the need to build terminals for a hybrid setup. \n“We’re going to create a commercial-ready solution that can really meet them,” Ron said.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-12",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "How a once-tiny research lab helped Nvidia become a $4 trillion-dollar company",
        "url": "https://techcrunch.com/2025/08/12/how-a-once-tiny-research-lab-helped-nvidia-become-a-4-trillion-dollar-company/",
        "content": "When Bill Dally joined Nvidia’s research lab in 2009, it employed only about a dozen people and was focused on ray tracing, a rendering technique used in computer graphics.\nThat once-small research lab now employs more than 400 people, who have helped transform Nvidia from a video game GPU startup in the nineties to a $4 trillion-dollar company fueling the artificial intelligence boom.\n\nNow, the company’s research lab has its sights set on developing the tech needed to power robotics and AI. And some of that lab work is already showing up in products. The company unveiled Monday a new set of world AI models, libraries, and other infrastructure for robotics developers.\nDally, now Nvidia’s chief scientist, started consulting for Nvidia in 2003 while he was working at Stanford. When he was ready to step down from being the department chair of Stanford’s computer science department a few years later, he planned to take a sabbatical. Nvidia had a different idea.\nBILL DALLY\nIMAGE CREDITS:NVIDIA\nDavid Kirk, who was running the research lab at the time, and Nvidia CEO Jensen Huang, thought a more permanent position at the research lab was a better idea. Dally told TechCrunch the pair put on a “full-court press” on why he should join Nvidia’s research lab and eventually convinced him.\n“It wound up being kind of a perfect fit for my interests and my talents,” Dally said. “I think everybody’s always searching for the place in life where they can make the biggest contribution to the world. And I think for me, it’s definitely Nvidia.”\nWhen Dally took over the lab in 2009, expansion was first and foremost. Researchers started working on areas outside of ray tracing right away, including circuit design and VLSI, or very large-scale integration, a process that combines millions of transistors on a single chip.\nThe research lab hasn’t stopped expanding since.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\n“We try to figure out what will make the most positive difference for the company because we’re constantly seeing exciting new areas, but some of them, they do great work, but we have trouble saying if [we’ll be] wildly successful at this,” Dally said.\nFor a while that was building better GPUs for artificial intelligence. Nvidia was early to the future AI boom and started tinkering with the idea of AI GPUs in 2010 — more than a decade before the current AI frenzy.\n“We said this is amazing, this is gonna completely change the world,” Dally said. “We have to start doubling down on this and Jensen believed that when I told him that. We started specializing our GPUs for it and developing lots of software to support it, engaging with the researchers all around the world who were doing it, long before it was clearly relevant.”\nPhysical AI focus\nNow, as Nvidia holds a commanding lead in the AI GPU market, the tech company has started to seek out new areas of demand beyond AI data centers. That search has led Nvidia to physical AI and robotics.\n“I think eventually robots are going to be a huge player in the world and we want to basically be making the brains of all the robots,” Dally said. “To do that we need to start developing the key technologies.”\nThat’s where Sanja Fidler, the vice president of AI research at Nvidia, comes in. Fidler joined Nvidia’s research lab in 2018. At the time, she was already working on simulation models for robots with a team of students at MIT. When she told Huang about what they were working on at a researchers’ reception, he was interested.\n“I could not resist joining,” Fidler told TechCrunch in an interview. “It’s just such a great topic fit and at the same time was also such a great culture fit. Jensen told me, come work with me, not with us, not for us.”\nShe joined Nvidia and got to work creating a research lab in Toronto called Omniverse, an Nvidia platform, that was focused on building simulations for physical AI.\nSANJA FIDLER\nIMAGE CREDITS:NVIDIA\nThe first challenge to building these simulated worlds was finding the necessary 3D data, Fidler said. This included finding the proper volume of potential images to use and building the technology needed to turn these images into 3D renditions the simulators could use.\n“We invested in this technology called differentiable rendering, which essentially makes rendering amendable to AI,” Fidler said. “You go [from] rendering means from 3D to image or video. And we want it to go the other way.”\nWorld models\nOmniverse released the first version of its model that turns images into 3D models, GANverse3D, in 2021. Then it got to work on figuring out the same process for video. Fidler said they used videos from robots and self-driving cars to create these 3D models and simulations through its Neural Reconstruction Engine, which the company first announced in 2022.\nShe added these technologies were the backbone of the company’s Cosmos family of world AI models that were announced at CES in January.\nNow, the lab is focused on making these models faster. When you play a video game or simulation you want the tech to be able to respond in real time, Fidler said, for robots they are working to make the reaction time even faster.\n“The robot doesn’t need to watch the world in the same time, in the same way as the world works,” Fidler said. “It can watch it like 100x faster. So if we can make this model significantly faster than they are today, they’re going to be tremendously useful for robotic or physical AI applications.”\nThe company continues to make progress on this goal. Nvidia announced at the SIGGRAPH computer graphics conference on Monday a fleet of new world AI models designed for creating synthetic data that can be used to train robots. Nvidia also announced new libraries and infrastructure software aimed at robotics developers too.\nDespite the progress — and the current hype about robots, especially humanoids — the Nvidia research team remains realistic.\nBoth Dally and Fidler said the industry is still at least a few years off from having a humanoid in your home, with Fidler comparing it to the hype and timeline regarding autonomous vehicles.\n“We’re making huge progress and I think AI has really been the enabler here,” Dally said. “Starting with visual AI for the robot perception, and then generative AI, that’s being hugely valuable for task and motion planning and manipulation. As we solve each of these individual little problems and as the amount of data we have to train our networks grows, these robots are going to grow.”\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-12",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Seoul-based Datumo raises $15.5M to take on Scale AI, backed by Salesforce",
        "url": "https://techcrunch.com/2025/08/11/seoul-based-datumo-raises-15-5m-to-expand-llm-evaluation-challenging-scale-ai/",
        "content": "Most organizations say they aren’t fully prepared to use generative AI in a safe and responsible way, according to a recent McKinsey report. One concern is explainability — understanding how and why AI makes certain decisions. While 40% of respondents view it as a significant risk, only 17% are actively addressing it, per the report.\nSeoul-based Datumo began as an AI data labeling company and now wants to help businesses build safer AI with tools and data that enable testing, monitoring, and improving their models — without requiring technical expertise. On Monday the startup raised $15.5 million, which brings its total raised to approximately $28 million, from investors including Salesforce Ventures, KB Investment, ACVC Partners, and SBI Investment, among others.\nDavid Kim, CEO of Datumo and a former AI researcher at Korea’s Agency for Defense Development, was frustrated by the time-consuming nature of data labeling so he came up with a new idea: a reward-based app that lets anyone label data in their spare time and earn money. The startup validated the idea at a startup competition at KAIST (Korea Advanced Institute of Science and Technology). Kim co-founded Datumo, formerly known as SelectStar, alongside five KAIST alumni in 2018.\nEven before the app was fully built, Datumo secured tens of thousands of dollars in pre-contract sales during the customer discovery phase of the competition, mostly from KAIST alumni-led businesses and startups.\nIn its first year, the startup surpassed $1 million in revenue and secured several key contracts. Today, the startup counts major Korean companies like Samsung, Samsung SDS, LG Electronics, LG CNS, Hyundai, Naver, and Seoul-based telecom giant SK Telecom among its clients. Several years ago, however, clients began asking the company to go beyond simple data labeling. The 7-year-old startup now has more than 300 clients in South Korea and generated about $6 million in revenue in 2024.\n“They wanted us to score their AI model outputs or compare them to other outputs,” Michael Hwang, co-founder of Datumo, told TechCrunch. “That’s when we realized: We were already doing AI model evaluation — without even knowing it.” Datumo doubled down on this area and released Korea’s first benchmark dataset focused on AI trust and safety, Hwang added.\n“We started in data annotation, then expanded into pretraining datasets and evaluation as the LLM ecosystem matured,” Kim told TechCrunch.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nCO-FOUNDERS OF DATUMO\nIMAGE CREDITS:DATUMO\nMeta’s recent $14.3 billion acquisition-like investment in data-labeling company Scale AI highlights the importance of this market. Shortly after that deal, AI model maker and Meta competitor OpenAI stopped using Scale AI’s services. The Meta deal also signals that competition for AI training data is intensifying.\nDatumo shares some similarities with companies like Scale AI in pretraining dataset provisioning, and with Galileo and Arize AI in AI evaluation and monitoring. However, it differentiates itself through its licensed datasets, particularly data crawled from published books, which the company says offers rich structured human reasoning but is notoriously difficult to clean, according to CEO Kim.\nUnlike its peers, Datumo also offers a full-stack evaluation platform called Datumo Eval, which automatically generates test data and evaluations to check for unsafe, biased or incorrect responses without the need for manual scripting, Kim added. The signature product is a no-code evaluation tool designed for non-developers like those on policy, trust and safety, and compliance teams.\nWhen asked about attracting investors like Salesforce Ventures, Kim explained that the startup had previously hosted a fireside chat with Andrew Ng, founder of DeepLearning.AI, at an event in South Korea. After the event, Kim shared the session on LinkedIn, which caught the attention of Salesforce Ventures. Following several meetings and Zoom calls, the investors extended a soft commitment. The entire funding process took about eight months, Hwang said.\nThe new funding will be used to accelerate R&D efforts, particularly in developing automated evaluation tools for enterprise AI, and to scale global go-to-market operations across South Korea, Japan, and the U.S. The startup, which has 150 employees in Seoul, also established a presence in Silicon Valley in March.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-11",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Nvidia unveils new Cosmos world models, infra for robotics and physical uses",
        "url": "https://techcrunch.com/2025/08/11/nvidia-unveils-new-cosmos-world-models-other-infra-for-physical-applications-of-ai/",
        "content": "Nvidia on Monday unveiled a set of new world AI models, libraries, and other infrastructure for robotics developers, most notable of which is Cosmos Reason, a 7-billion-parameter “reasoning” vision language model for physical AI applications and robots.\nAlso joining the existing batch of Cosmos world models are Cosmos Transfer-2, which can accelerate synthetic data generation from 3D simulation scenes or spatial control inputs, and a distilled version of Cosmos Transfers that is more optimized for speed.\nDuring its announcement at the SIGGRAPH conference on Monday, Nvidia noted that these models are meant to be used to create synthetic text, image, and video datasets for training robots and AI agents.\nCosmos Reason, per Nvidia, allows robots and AI agents to “reason” thanks to its memory and physics understanding, which lets it “serve as a planning model to reason what steps an embodied agent might take next.” The company says it can be used for data curation, robot planning, and video analytics.\nThe company also unveiled new neural reconstruction libraries, which includes one for a rendering technique that lets developers simulate the real world in 3D using sensor data. This rendering capability is also being integrated into open source simulator CARLA, a popular developer platform. There’s even an update to the Omniverse software development kit.\nThere are new servers for robotics workflows, too. The Nvidia RTX Pro Blackwell Server offers a single architecture for robotic development workloads, while Nvidia DGX Cloud is a cloud-based management platform. \nThese announcements come as the semiconductor giant is pushing further into robotics as it looks toward the next big use case for its AI GPUs beyond AI data centers.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch, you can help us! Fill out this survey to let us know how we’re doing.",
        "date": "2025-08-11",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Elon Musk confirms shutdown of Tesla Dojo, ‘an evolutionary dead end’ ",
        "url": "https://techcrunch.com/2025/08/11/elon-musk-confirms-shutdown-of-tesla-dojo-an-evolutionary-dead-end/",
        "content": "Elon Musk confirmed over the weekend reports that Tesla has disbanded the team working on its Dojo AI training supercomputer, just weeks after announcing he expected to have Tesla’s second cluster operating “at scale” in 2026. \n“Once it became clear that all paths converged to AI6, I had to shut down Dojo and make some tough personnel choices, as Dojo 2 was now an evolutionary dead end,” Musk posted on X, the social media platform he owns, on Sunday. “Dojo 3 arguably lives on in the form of a large number of AI6 [systems-on-a-chip] on a single board.”\nAfter bringing its first Dojo supercomputer to life and powering it with a mix of Nvidia GPUs and in-house-made D1 chips, Tesla had planned to build a second Dojo factory — referred to by Musk as “Dojo 2” — that would have been powered by a second-generation D2 chip. \nIt appears the D2 chip under development has been shelved along with the broader Dojo project as Tesla shifts its focus to its AI5 and AI6 chips, which are being manufactured by TSMC and Samsung, respectively. The AI5 chip is primarily built to power FSD, Tesla’s driver assistance system, while AI6 is designed for both onboard inference — meaning, it promises to power self-driving in cars and autonomous capabilities in humanoid robots — and large-scale AI training.  \n“It doesn’t make sense for Tesla to divide its resources and scale two quite different AI chip designs,” Musk posted late Friday evening. “The Tesla AI5, AI6 and subsequent chips will be excellent for inference and at least pretty good for training. All effort is focused on that.”\nHe added that for a supercomputer cluster, it makes more sense to put “many AI5/AI6 chips on a board, whether for inference or training, simply to reduce network cabling complexity & cost by a few orders of magnitude.” \n“One could call that Dojo 3, I suppose,” he said.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nSan Francisco | October 27-29, 2025\nREGISTER NOW\nMusk has talked about Dojo since 2019, reiterating that Dojo would be a cornerstone of Tesla’s mission to achieve full self-driving and commercialize humanoid robots. Talk of Dojo halted around August 2024 when Musk began touting Cortex instead, a “giant new AI training supercluster being built at Tesla HQ in Austin to solve real-world AI.”\nIt’s not clear if Cortex is still in the works. TechCrunch has reached out to Tesla to learn more, as well as to inquire about the fate of the Dojo facility Tesla had invested $500 million to build in Buffalo, New York. \nThe shift in strategy comes at a time when Tesla is experiencing falling EV sales and significant brand damage after Musk’s forays into politics. Musk has worked to convince investors that Tesla still has a future in autonomy, despite a slow and limited robotaxi launch in Austin this past June that resulted in numerous reported incidents of the vehicles exhibiting problematic driving behavior. \nWe want to get to know our audience even better, and get your feedback on our coverage and events. Fill out this survey to give us your thoughts, and get the chance to win a prize in return.",
        "date": "2025-08-11",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Nvidia, AMD may sell high-end AI chips to China if they pay US a cut",
        "url": "https://techcrunch.com/2025/08/11/nvidia-amd-may-sell-high-end-ai-chips-to-china-if-they-pay-us-a-cut/",
        "content": "The AI chip race narrative used to be about U.S. national security, but apparently now it’s about tariffs: Nvidia and AMD have agreed to pay the U.S. government 15% of the revenue they make from sales of high-end AI chips to China in exchange for licenses to sell those chips in the country, the Financial Times reported, citing anonymous sources.\nAccording to the FT’s government source, Nvidia will share revenues from sales of its H20 AI chips in China, and AMD would share a cut of MI308 chip sales. The government has also started issuing licenses for the sale of the two companies’ chips, the report said.\nThe Trump administration in April had restricted sales of certain high-performance AI inference chips to China, but paused the ban a couple of months later, when Nvidia promised to make up to $500 billion worth of data center investments stateside. Then in July, the company said it would resume sales of its H20 AI chips to China, which it had designed specifically for sale in the country following restrictions by the Biden administration.\n“We follow rules the U.S. government sets for our participation in worldwide markets,” an Nvidia spokesperson said in an emailed statement. “While we haven’t shipped H20 to China for months, we hope export control rules will let America compete in China and worldwide.” \nAccording to U.S. Commerce Secretary Howard Lutnick, Nvidia’s change of course was related to trade discussions with China regarding rare-earth elements, which are necessary for making components, like rechargeable batteries for electric vehicles.\nThe administration’s decision to approve the sale of Nvidia’s H20 chips has its critics: National security experts and former government officials wrote to Lutnick last month, urging the government to reverse course.\nNote: This story was updated to add a statement by Nvidia.\nWe want to get to know our audience even better, and get your feedback on our coverage and events. Fill out this survey to give us your thoughts, and get the chance to win a prize in return.",
        "date": "2025-08-11",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "Apple’s new Siri may allow users to operate apps just using voice",
        "url": "https://techcrunch.com/2025/08/11/apples-new-siri-may-allow-users-to-operate-apps-just-using-voice/",
        "content": "Apple in 2024 showed a swanky demo of what it said would be a new, intelligent Siri that would connect with different apps to fetch all kinds of information. But this new Siri has yet to see the light of day, as the company seemingly hasn’t been able to get it ready.\nHowever, Bloomberg now reports that Apple is testing a version of Siri that will be able to take actions on your behalf across various apps by following voice commands. The company plans to release a new version of App Intents, its framework that gives developers the ability to allow users access to parts of their app via different systems, like search and Shortcuts.\nBloomberg reported that if this new version of Siri and App Intents works well, a user would be able to ask Siri to search for a photo, edit it, and send it to someone; post comments on a social app; or log in to a service.\nThe company is already testing this feature with apps like Uber, AllTrails, Threads, Temu, Amazon, YouTube, Facebook, and WhatsApp, the report said. The publication previously reported that Apple planned to release an overhauled version of Siri in spring 2026.\nWe want to get to know our audience even better, and get your feedback on our coverage and events. Fill out this survey to give us your thoughts, and get the chance to win a prize in return.",
        "date": "2025-08-11",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "The computer science dream has become a nightmare",
        "url": "https://techcrunch.com/2025/08/10/the-computer-science-dream-has-become-a-nightmare/",
        "content": "The coding-equals-prosperity promise has officially collapsed.\nFresh computer science graduates are facing unemployment rates of 6.1% to 7.5% — more than double what biology and art history majors are experiencing, according to a recent Federal Reserve Bank of New York study. A crushing New York Times piece highlights what’s happening on the ground.\nThe individual stories are surreal. Manasi Mishra, 21, graduated from Purdue after being promised six-figure starting salaries, only to receive a single interview, at Chipotle (she didn’t get the job.) Zach Taylor has applied to nearly 6,000 tech jobs since graduating from Oregon State in 2023, landing just 13 interviews and zero offers. He was even rejected by McDonald’s for “lack of experience.”\nThe alleged culprits? AI programming tools that are eliminating junior positions, while big names like Amazon, Meta, and Microsoft slash jobs. Students say they’re trapped in an “AI doom loop” — using AI to mass-apply while companies use AI to auto-reject them, sometimes within minutes.\nThankfully, Mishra landed a job after a cold application worked out, helped along by some savvy TikTok posts about the borked job market.\nWe’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out this survey to let us know how we’re doing and get the chance to win a prize in return!",
        "date": "2025-08-10",
        "source": "TechCrunch",
        "category": "산업"
    },
    {
        "title": "오픈AI \"GPT-5, 따뜻하고 친근하게 수정...아첨과는 달라\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201554",
        "content": "오픈AI 가 '챗GPT'의 답변 톤을 \"더 따뜻하고 친근하게\" 만들겠다고 밝혔다. 이는 17일(현지시간)부터 적용될 예정이다.\n오픈AI는 16일 X(트위터)를 통해 챗GPT의 변화를 예고했다. \"이전에는 너무 격식을 차린 느낌이 들었다는 피드백을 바탕으로 GPT-5를 더욱 따뜻하고 친근하게 만들고 있다\"라며 \"변화는 미묘하지만, 챗GPT는 이제 더 친근하게 느껴질 것\"이라고 밝혔다.\n하지만 지난 4월 '아첨' 문제로 모델 롤백 사태를 일으켰던 것과는 다르다고 강조했다.\n\"챗GPT가 '좋은 질문'이나 '훌륭한 시작'과 같은 아첨성 발언을 하는 것이 아니라, 소소하고 진심 어린 배려가 눈에 띄게 될 것\"이라고 전했다. 또 \"내부 테스트 결과, 이전 GPT-5의 개성과 비교했을 때 아첨은 증가하지 않았다\"라고 덧붙였다.\n이번 변경은 최대 하루가 걸릴 수 있으며, 곧 더 많은 업데이트가 있을 예정이라고 밝혔다.\n이날 샘 알트먼 오픈AI CEO도 X를 통해 \"대부분의 사용자는 곧 GPT-5를 더 좋아할 것\"이라며 \"변경 사항은 다음 날 적용될 예정\"이라고 말했다.\n그는 \"이 문제의 진정한 해결책은 사용자가 챗GPT의 스타일을 훨씬 더 자유롭게 맞춤 설정할 수 있도록 하는 것\"이라고 설명했다.\nMost users should like GPT-5 better soon; the change is rolling out over the next day.The real solution here remains letting users customize ChatGPT's style much more. We are working that!https://t.co/RfiYJ8AkEO\n\n현재 GPT-5는 ▲냉소주의자(Cynic) ▲로봇(Robot) ▲청취자(Listener) ▲괴짜(Nerd) 등 네가지 성격을 설정할 수 있다. 오픈AI와 알트먼 CEO의 설명은 전반적으로 챗봇 답변의 톤을 부드럽게 조정하고, 성격 설정의 자유도를 높이겠다는 것으로 보인다.\n이처럼 오픈AI는 GPT-5에 대한 소비자의 가장 큰 불만을 'GPT-4o'와 같은 분위기가 부족하다는 것으로 보고 있다. 실제로 GPT-5 출시 직후 실시한 레딧의 사용자 채팅 이벤트나 오픈AI X 계정에 달린 댓글에서는 챗봇의 성능을 문제 삼는 발언보다 챗봇의 톤 변화가 더 많이 지적되고 있다.\n그리고 오픈AI는 GPT-5가 초반 어이없는 실수를 저지르는 것에 대해서는 별 대응이 없다. 초기 안정화의 문제로 보고, 시간이 지나면 해결될 것이라는 입장이다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-16",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "알트먼 \"컴퓨팅 한계로 'GPT-5' 성능 낮춰 출시\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201553",
        "content": "샘 알트먼 오픈AI CEO가 'GPT-5'를 출시하며 현실과 타협했다고 밝혔다. 더 크고 성능이 뛰어난 모델을 내놓을 수 있었지만, 컴퓨팅 인프라의 한계에 따라 성능을 낮췄다는 설명이다.\n알트먼 CEO는 15일(현지시간) 미국의 일부 매체들을 대상으로 GPT-5와 오픈AI의 계획에 대한 이야기를 나눴다.\n가장 눈길을 끈 부분은 GPT-5에 관한 내용이다.\n그는 \"GPU 문제로 엄청나게 고민했다\"라고 밝혔다. 이어 \"거대한 모델을 만들 수도 있었다. 그렇게 만들면 많은 사람들이 사용하고 싶어 할텐데, 결국 우리는 그들을 실망시킬 것\"이라고 설명했다.\n올해 급증한 사용자로 인해 오픈AI가 컴퓨팅 파워 부족에 시달린다는 것은 잘 알려진 일이다. 이런 상황에서 GPT-5의 성능을 크게 높여 컴퓨팅 파워가 엄청나게 들어가게 만들면, 결국 많은 사용자가 이를 활용하지 못하게 되는 상황이 일어난다는 말이다.\n실제로 오픈AI는 GPT-5를 출시하며 기존과는 달리 무료 사용자에게도 모든 기능을 동시 개방했다. 여기에 추론 모드까지 자동으로 사용할 수 있도록 '라우터'를 탑재했다.\n그는 \"그래서 우리는 정말 똑똑하고 유용한 모델을 만들되, 추론 비용도 최적화해야겠다고 생각했다. 그리고 그 부분에서는 정말 잘 해냈다고 생각한다\"라고 밝혔다.\n또 \"우리는 지금 당장 끔찍한 타협을 해야 한다\"라며 \"우리는 더 나은 모델을 가지고 있지만, 역량이 부족해서 제공할 수 없다. 아직 공개하지 못한 새로운 기능과 서비스도 있다\"라고 덧붙였다.\nGPT-5를 선보이는 과정은 순탄하지 않았다고 털어 놓았다. \"출시 과정에서 몇가지를 완전히 망친 것 같다\"라는 것이다.\n그러나 \"반면 API 트래픽은 48시간 만에 두배로 늘어났고, 지금도 계속 증가하고 있다. GPU도 부족하다\"라며 \"챗GPT는 매일 사용자 수가 최고치를 경신하고 있다. 많은 사용자가 모델 전환기를 정말 좋아한다. 수억명을 위해 하루 만에 제품을 업그레이드하는 것이 어떤 의미인지 깨달았다\"라고 설명했다.\n이처럼 원활한 서비스 확대를 위해 데이터센터 건설에 앞으로 막대한 비용을 투자하겠다고 밝혔다.\n\"우리는 머지않은 미래에 데이터센터 건설에 수조달러를 지출할 것\"이라며 \"그리고 많은 경제학자가 '이건 너무 말도 안 되고, 너무 무모하다'라고 말할 것으로 예상된다\"라고 예측했다. \"그러면 우리는 '그냥 우리 할 일을 하자'라고 말할 것\"이라고 전했다.\n앞서 그는 지난해 초 막대한 컴퓨팅 인프라를 구축하기 위해 수조달러가 필요하다는 발언을 했다가, 당시 많은 전문가에게 과장이 심하다는 지적을 받은 바 있다. 이날 발언은 이를 비꼰 것으로 볼 수 있다.\n또 막대한 자금을 모으기 위해 새로운 방법을 고안하고 있다고 말했다. \"투자 유치를 위한 매우 흥미로운 새로운 종류의 금융 상품을 설계하고, 세상이 아직 알아내지 못한 것을 계산할 수 있다고 생각한다\"라며 \"이를 위해 노력하고 있다\"라고 말했다.\n이 밖에도 최근 계속 지적되는 'AI 망상'에 대해서도 입장을 밝혔다. 그는 문제가 있는 사람의 비율을 1% 미만으로 추산했지만, 이를 중요한 문제로 인식해 해결책을 적극 마련 중이라고 전했다.\n얼마 전 X(트위터)에서도 밝혔듯, 조니 아이브와 제작 중인 하드웨어를 강조했다. \"매우 아름다운 제품\"이라며 \"케이스를 씌우면 내가 직접 찾아낼 것\"이라는 농담도 했다.\n그는 이 기기를 통해 \"지난 50년 동안 딱 두번밖에 없었던 새로운 컴퓨팅 패러다임을 경험하게 될 것\"이라며 \"정말 기다릴 만한 가치가 있다. 행복하고 놀라운 경험을 하게 될 것\"이라고 예고했다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-16",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "엔닷라이트 \"엔비디아가 주목한 3D AI 모델링...로봇 데이터 필수 될 것\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201547",
        "content": "2020년 설립된 엔닷라이트(대표 박진영)는 얼마 전까지 3D 모델링 기업으로 이름을 알려 왔다. 3D 에셋을 만드는 엔진을 개발, 네이버 등과 협업을 이어왔다. 'CES 2023'에서도 혁신상을 받은 바 있다.\n이 가운데 2022년부터 엔비디아의 스타트업 지원 프로그램 '인셉션'에 선정돼 협업 중이다. 엔비디아는 3D 디자인 시뮬레이션 플랫폼 '옴니버스'를 운영 중인데, 엔닷라이트의 3D 엔진을 여기에 연동해 왔다.\n이어 생성 인공지능(AI) 붐이 본격화하자, 엔닷라이트도 이에 맞춰 기술을 업그레이드했다. 지난해 텍스트 프롬프트 기반 3D 데이터 생성 솔루션 '트리닉스(TRINIX)'를 선보인 것이다.\n그리고 3D CAD를 만들던 이 회사의 엔진은 이제 첨단 AI의 한 요소로 자리 잡게 됐다. 바로 물리 AI(Physical AI), 즉 로봇용 합성 데이터 구축으로 확장하게 됐다.\n박진영 대표는 \"국내에는 우리와 같은 3D 모델링 기술을 보유한 기업이 없으며, 글로벌로 따져도 두세곳에 불과하다”라고 말했다.\n2D 이미지를 3D로 바꿔주는 기술은 커머스와 게임, 영화 등 산업 분야 수요가 크기 때문에 경쟁이 치열하다. 기술이 등장한 지도 꽤 됐다.\n하지만, 박 대표는 \"디테일한 기술에서 큰 차이가 생긴다\"라고 전했다.\n우선, 기존 AI 기반 3D 모델링 기업은 대부분 초안을 '메시(Mesh)' 형태로 생성해 준다. 그는 이를 \"2D를 3D로 확장한 단순한 '덩어리’에 불과하다\"라고 지적했다. “텀블러를 3D로 생성하면 텀블러라고 인식할 수 있을 정도의 형태이지만, 뚜껑이나 손잡이까지 AI로 생성해 낼 수는 없다”라고 설명했다.\n그러나 트리닉스를 활용하면 이미 생성된 초안에 뚜껑이나 손잡이를 생성할 수 있다는 것이다. \"다른 솔루션에서는 이같은 수정이나 편집이 불가능하다\"라고 강조했다.\n여기에 추가된 뚜껑이나 손잡이는 현실처럼 들어 올리거나 움직일 수 있다. 디자이너들이 엄청난 노력을 들여 초안을 수정할 필요도 없고, 실제 구동성까지 갖춘 3D 모델링 기술은 비슷한 예를 찾기 어렵다고 밝혔다.\n그리고 이는 디자인 차원을 넘어, 로봇용 데이터 구축이라는 부분에서 대단한 잠재력을 가진다고 전했다.\n\"최근 해외와 국내 업계는 모두 '로봇 데이터'를 확보하는 데 전념하고 있다\"라며 \"실제 물리법칙에 맞게 동작하는 CAD는 로봇 학습 데이터로도 유용하다\"라고 설명했다.\n알려진 대로 로봇 AI는 데이터 부족이 가장 큰 문제로 꼽힌다. 데이터를 구축하려면 실제 로봇이 움직이는 영상을 촬영하거나 인간이 모션 슈트를 입고 특정 행동을 취하는 방법 등을 사용하는데, 그 자체가 시간과 비용이 엄청나게 들어가기 때문이다. 그래서 현실 세계와 똑같은 물리 법칙을 적용하는 월드 모델(WM)이 로봇 데이터 구축용으로 부각될 정도다.\n이 때문에 엔닷라이트에도 최근 제안이 몰리고 있다.\n박 대표는 \"로봇 전문 기업이라고 소개한 적도 없는데, 모델링 기술에 집중한 빅테크들이 협업 제안을 해오고 있다\"라며 \"엔비디아도 그중 하나\"라고 밝혔다.\n특히, 3D 데이터는 산업용 로봇을 넘어 범용 휴머노이드로 기술이 확대되며 활용도가 부쩍 늘어날 것으로 예측했다. \"산업 현장의 협동 로봇은 한정된 공간과 규격화된 부품 등 일정 조건 속에서 동작하기 때문에 특수 상황만 학습하면 된다\"라며 \"하지만, 가정용 로봇은 집 안의 수많은 돌발 상황에 대처해야 한다\"하고 지적했다.\n따라서 \"휴머노이드 상용화를 위해서는 결국 데이터 확보 시간을 줄이는 것이 핵심\"이라고 설명했다.\n또 \"이처럼 중요하고 어려운 부분이기 때문에 3D 데이터 하나가 현재 50만~60만원에 거래되고 있다\"라며 \"엔닷라이트는 텍스트 입력만으로 이런 문제를 해결할 수 있다\"라고 말했다.\n엔닷라이트는 엔비디아 3D 시뮬레이션 플랫폼에 엔닷라이트 생성 CAD 파일을 자동 업로드하는 구조를 갖췄다. 또 이는 어떤 플랫폼에도 적용이 가능하다. 이 때문에 빅테크들의 문의가 이어진다는 설명이다.\n이 회사는 최근 산업통상자원부와 한국산업기술기획평가원이 주관하는 국가 프로젝트 'K-휴머노이드 연합'에 참여했다. 로봇 파운데이션 모델 개발에서 데이터 구축을 담당한다.\n박 대표는 \"로봇 데이터 시장은 다음 세대의 먹거리가 될 것\"이라고 강조했다. \"특히, 국내는 제조 데이터를 대량으로 보유하고 있기 때문에 이를 3D화한다면 유리해질 것\"이라고 덧붙였다.\n이어 \"언어모델과 달리, 물리 AI 데이터는 세계 공통\"이라며 \"최근 중국 제조 기업도 엔닷라이트 기술에 많은 관심을 보였다\"라고 소개했다.\n또 \"국내에서도 스마트팩토리 등 유용한 부분이 많을 것\"이라며 \"국가 지원이 더 확장돼야 한다\"라고 말했다.\n실제로 현재는 국내 B2B 사업에 집중하고 있다고 밝혔다. \"기업마다 원하는 디자인과 사용하는 용어가 다르므로 트리닉스 솔루션을 한달 반 정도 최적화를 거쳐 제공한다\"라고 말했다.\n이를 통해 설계 자동화를 지원한다. \"간단한 설계도는 40초 만에 생성 가능하며, 공기청정기처럼 구조가 복잡한 제품도 평균 90초 정도가 소요되는 수준\"이라고 설명했다.\n회사로서는 산업 현장의 기술 적용 자체가 기술 고도화 과정이다. 각 산업과 제품군에 대한 모델의 이해가 향상하기 때문이다. 물론, 기업의 지적재산(IP)과 보안 유지를 위한 장치도 철저하게 구축했다고 강조했다.\n박진영 대표는 \"이처럼 당장 노동력 보완이 필요한 영역은 물론, 미래 먹거리가 될 물리 AI 영역까지 모두 지원 가능하다는 점에서 엔닷라이트 기술은 엄청난 잠재력을 가지고 있다\"라고 말했다.\n이어 \"글로벌 무대에서도 독보적인 기술인 만큼, 시장에 빠르게 진입해 레퍼런스를 구축해 나갈 것\"이라고 밝혔다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-16",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "오픈AI, 직원 주식 8조 규모 소프트뱅크에 매각 추진",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201546",
        "content": "오픈AI가 약 60억달러(약 8조3000억원) 규모의 직원 보유 주식을 매각하는 방안을 추진하고 있다. 이는 인재 영입 경쟁에 따른 직원들의 보상책 중 하나로, 이번에도 소프트뱅크가 참여해 눈길을 끌었다.\n블룸버그는 15일(현지시간) 정통한 소식통을 인용, 오픈AI가 전·현직 직원이 보유한 60억달러 규모의 주식을 5000억달러의 기업 가치로 매각할 수 있도록 하는 세컨더리(2차) 거래를 추진 중이라고 보도했다.\n이번 주식 매각은 직원들이 소프트뱅크와 드래고니어 인베스트먼트 그룹, 스라이브 캐피털 등 기존 투자자들에게 지분을 판매해 현금화할 수 있도록 하는 구조다. 로이터가 지난 6일 처음 보도한 이 협상은 아직 초기 단계로, 매각 규모는 변동될 수 있다.\n특히 소프트뱅크가 이번 거래에 참여한다는 것은 처음 알려졌다. 소프트뱅크는 이번 지분 매입뿐 아니라, 이미 400억달러(약 56조원) 규모의 라운드를 별도 진행 중이다. 여기에서 오픈AI는 기업 가치를 3000억달러(약 417조원)로 평가받았다.\n또 소프트뱅크는 지난해 10월 대규모 투자 라운드에 참여한 이후 올해 초에도 30억달러 규모의 별도 거래를 통해 오픈AI 직원 지분을 일부 매입한 바 있다. 이처럼 1년 새 4차례가 넘는 주식 매입에 나서는 등 오픈AI에 '올인'하는 모습이다.\n이번 세컨더리 거래는 오픈AI 직원들에게 현금화 기회를 제공, 메타의 고액 연봉 영입에 따른 핵심 인력 이탈을 막고 나머지 인원들의 박탈감을 상쇄하려는 것이다. 따라서, 이번에는 2년 이상 근무한 전·현직 직원만 지분 매각이 가능하다.\n앞서 지난 6월 마크 첸 오픈AI 부사장은 메타의 영입 시도에 맞서 \"보상 체계 재조정은 물론, 우수 인재에게 창의적인 방식으로 인정과 보상을 제공할 방안을 모색 중”이라고 내부에 발표한 바 있다.\n그러나, 오픈AI는 이후에도 메타로 일부 인원이 이탈하는 등 최소 12명을 잃은 것으로 알려졌다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-16",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "앤트로픽, '클로드' 안전 가이드라인 강화",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201550",
        "content": "앤트로픽이 '클로드'의 안전 가이드라인을 대폭 강화했다. 인공지능(AI) 모델의 성능 향상에 맞춰, 악용의 소지를 막기 위해 포괄적이고 광범위한 조치를 발표했다.\n엔트로픽은 15일(현지시간) 클로드의 사용 정책(Usage Policy)을 개정해 오는 9월15일부터 적용한다고 발표했다.\n앤트로픽은 기존 정책에서도 무기·폭발물·위험 물질의 제작 및 유통을 금지했으나, 이번 개정을 통해 고위력 폭발물, 생물학무기, 핵무기, 화학무기, 방사능 무기를 구체적으로 명시했다.\n이는 지난 5월 ‘클로드 오퍼스 4’ 출시와 함께 도입된 'AI 안전 수준 3(AI Safety Level 3)' 체계를 보완하는 조치다. 모델의 탈옥 시도를 어렵게 하고 핵·화학·생물학·방사능(CBRN) 무기 개발 지원 가능성을 원천 차단하려는 목적이라고 밝혔다.\n특히, 최근 AI 에이전트 기능의 빠른 발전에 맞춘 대응책을 포함했다. '클로드 코드'와 '컴퓨터 유즈(Computer Use)' 같은 에이전트 도구가 악성코드 제작이나 사이버 공격, 대규모 남용 등으로 이어질 위험이 더 크기 때문이다.\n이에 따라 앤트로픽은 컴퓨터와 네트워크, 인프라 침해 행위 금지 조항을 신설했다. 이를 통해 취약점 탐지와 악용, 악성코드 제작과 배포, 서비스 거부(DoS) 공격 도구 개발 등을 금지된다.\n다만, 시스템 소유자의 동의 하에 취약점을 탐지하는 등 합법적인 보안 강화 활용은 허용한다고 명시했다.\n그러나, 트럼프 행정부의 정책에 맞춰 정치 콘텐츠 정책은 일부 완화됐다. 기존에는 정치 캠페인 및 로비 활동과 관련한 콘텐츠를 전면 금지했으나, 앞으로는 민주적 절차를 교란하거나 유권자나 선거 운동을 악용되는 사례에만 제한을 두기로 했다.\n법 집행 관련 조항도 더 명확하게 다듬어졌다. 기존에는 허용·예외 규정이 혼재됐으나, 이번 개정으로 감시와 추적, 프로파일링, 생체인식 모니터링은 금지하되, 이미 허용됐던 백오피스 및 분석용 활용은 유지한다.\n마지막으로, 법률·금융·고용 등 사회적 파급력이 큰 ‘고위험(high-risk)’ 활용 사례에 대한 기준이 명확해졌다. 이 경우에는 인간이 반드시 검토 절차를 거치고, 소비자를 대상으로 한 서비스에는 AI 활용 사실을 알려야 한다.\n앤트로픽은 “사용 정책은 AI 위험이 진화함에 따라 함께 발전하는 ‘살아있는 문서’”라고 강조했다. 또 “앞으로도 정책 입안자와 전문가, 시민사회와 협력해 지속적으로 정책을 점검하고 보완하겠다”라고 밝혔다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-16",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "신화통신 \"칩 선적 추적 장치로 미국의 '감시 본능' 드러나\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201549",
        "content": "중국 관영 신화통신이 미국이 중국으로 전용될 위험이 있는 첨단 반도체 선적물에 위치추적기를 설치한 사실을 두고 “감시 제국의 본능을 드러낸 것”이라며 강하게 비판했다.\n신화통신은 15일 ‘미국, 반도체 무역을 감시 게임으로 전락시켰다’라는 제목의 논평을 게재했다.\n이를 통해 “워싱턴이 세계에서 가장 방대한 감시 정보망을 운영하고 있다”라고 지적했다. 앞서 미국 정부가 몇년 전부터 첨단 반도체의 중국 유입을 감시하기 위해 엔비디아 첨단 칩이 탑재된 인공지능(AI) 서버 등에 은밀하게 위치 추적 장치를 부착했다는 로이터의 보도에 따른 것이다.\n미국은 최근 몇년간 중국이 통신장비 등을 통해 미국을 감시하고 정보를 유출했다고 비난하며 제재를 펼쳐왔다. 바이든 행정부는 2022년 화웨이를 비롯한 중국 업체들의 통신장비 판매와 수입을 금지했으며, 올해 1월에는 중국산 자동차와 트럭에 대한 보안 심사를 강화했다. 틱톡의 미국 서비스를 중지하려는 것도 같은 이유에서다.\n따라서 이번 논평은 중국의 반격으로 볼 수 있다.\n최근 중국은 자국 기업들에 미국 반도체 사용에 신중할 것을 경고했으며, 엔비디아 'H20' 칩에 보안 취약점이나 ‘백도어’가 있는지 해명하라고 요구했다.\n신화통신은 “미국 정부는 무역 파트너를 동반자가 아닌, 걸려 넘어뜨려야 할 경쟁자로 인식하고 있다”라고 지적했다.\n또 “만약 미국산 반도체가 감시용 트로이 목마로 여겨진다면 기업들은 다른 대안을 찾을 것”이라고 경고했다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-16",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "'챗GPT' 모바일 앱, 출시 2년 만에 구독료 2.8조 돌파",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201551",
        "content": "오픈AI의 '챗GPT' 모바일 앱이 글로벌 시장에서 폭발적인 성장세로 출시 2년 만에 누적 구독료 매출 20억달러(약 2조8000억원)를 넘어섰다. 이는 경쟁 앱들의 30배를 넘는 수준으로, 앞으로도 다른 앱이 이를 따라잡기는 쉽지 않을 것이라는 점을 보여 준다.\n앱 인텔리전스 전문 앱피규어의 최근 분석에 따르면, 챗GPT의 iOS·안드로이드 앱은 2025년 1~7월 매출 13억5000만달러(1조9000억원)를 기록했다.\n이는 전년 동기(1억7400만달러) 대비 673% 급증한 수치다.\n특히, 월평균 매출은 1억9300만달러(약 2700억원)다. 2위인 xAI의 '그록(360만달러)'의 53배에 달한다.\n다운로드 수에서도 격차가 뚜렷하다.\n챗GPT 모바일 앱은 세계적으로 6억9000만회 설치된 것으로 추산되며, 이는 그록(3950만회)의 17배에 달한다. 특히, 이미지 생성 기능으로 인기를 끈 올해에만 다운로드 3억1800만회를 기록, 전년 같은 기간보다 2.8배 늘었다.\n전 세계 다운로드 중 13.7%를 차지한 인도에 이어, 미국이 10.3%로 뒤를 이었다.\n그러나 매출 면에서는 미국이 단연 1위로, 누적 매출의 38%를 차지했다. 다운로드당 매출도 평균 10달러에 달한다. 2위인 독일의 비중은 5.3%에 불과하다.\n챗GPT의 전 세계 다운로드당 평균 매출은 2.91달러로, 클로드(2.55달러)가 뒤를 쫓고 있다. 그록(0.75달러)이나 코파일럿(0.28달러)과는 차이가 크다.\n한편, 챗GPT 모바일 앱은 2023년 5월 처음으로 iOS에 등장했다. 안드로이드 버전은 두달 뒤인 7월에 선보였다.\n그록은 2023년 11월 출시됐지만, 초기에는 X(트위터) 플랫폼 내에서만 사용할 수 있었다. 모바일 앱으로 출시된 것은 올해부터로, iOS가 1월, 안드로이드가 3월 추가됐다.\n앱피규어는 “챗GPT는 소비자 친화적인 모바일 앱 생태계에서 압도적인 우위를 점하고 있다”라며, 다른 AI 챗봇들은 여전히 격차를 좁히기 위해 시간이 필요할 것이라고 분석했다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-16",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "플루, ‘공주티콘 발각질 케어 세트’ 올리브영 오특 할인 프로모션 진행",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201476",
        "content": "\n지본코스메틱의 바디케어 브랜드 ‘플루’가 16일 올리브영에서 진행되는 오특(오늘의 특가) 행사에서 ‘공주티콘 퍼펙트 발각질 케어 세트’를 역대 최저가인 31% 할인된 8900원에 선보인다고 밝혔다.\n오늘의 특가는 올리브영 인기 제품을 하루 동안 특별 할인가에 제공하는 프로모션이다. 이번에 할인 판매하는 ‘공주티콘 퍼펙트 발각질 케어 세트’는 바디스크럽 부문 누적판매량 5000만개를 판매한 바디케어의 대표 브랜드 플루의 제품으로, 대한민국 NO.1 대상에서 4년 연속 수상했다.\n공주티콘 퍼펙트 발각질 케어 세트는 샌들과 슬리퍼 착용 등 발 뒤꿈치 노출이 많은 여름철 쉽고 간편하게 발 각질을 제거할 수 있는 발각질 제거 면도기와 거칠어진 발에 보습을 더하는 풋크림 50g이 세트로 구성돼 있다.\n또 이모티콘 시장에서 큰 열풍을 일으킨 공주티콘과 콜라보해 나온 제품으로, 출시 한달 만에 전량 판매를 기록했다.\n플루 관계자는 “여름철 최대 고민 중에 하나인 발각질을 쉽고 간편하게 제거해주는 세트 구성 상품”이라며 “출시 한 달 만에 완판된 제품을 이번 올리브영 오특 행사를 통해 파격적인 가격으로 만나길 바란다”라고 전했다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-16",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "중국, '세계 휴머노이드 로봇 대회' 개최...16개국 500여대 출전",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201542",
        "content": "\n중국에서 '세계 휴머노이드 로봇 대회(WHRG)'가 열렸다. 16개국 280개 팀이 참가, 인공지능(AI)과 로봇 공학의 발전을 선보인다는 취지다.\n신화통신 등에 따르면 이번 대회는 15일 개막, 17일까지 베이징의 국립 스피드 스케이팅 오벌에서 열린다. 입장료는 128~580위안(약 2만4700~11만2000원)이다.\n미국과 독일, 브라질 등에서도 참가했다. 538개 경기에 500대 이상의 휴머노이드 로봇이 출전했다. 그중 192개 팀은 대학을 대표했고, 88개 팀은 중국의 유니트리와 같은 기업 대표로 나왔다.\n올림픽처럼 대규모 개막식을 진행했다. 로봇과 가수, 댄서가 결합한 댄스 배틀이 포함됐으며, 경극이나 무술 등 중국 전통 요소로 구성된 로봇 공연을 열었다. 심판과 로봇들이 올림픽 주제가에 맞춰 '스마트 코어' 점등식도 열었다.\n본 종목은 달리기와 멀리뛰기, 축구, 탁구와 같은 스포츠 종목과 자재 운반, 약물 분류, 청소 등과 같은 기술 과제를 포함한 26개 종목으로 구성됐다.\n이제까지 흔히 보듯 축구 경기 중에는 로봇이 충돌하고 쓰러지는 일이 계속 발생했고, 달리기에서는 전력 질주하다가 쓰러지는 사고도 발생했다. 관객들은 로봇이 넘어진 뒤 스스로 일어서면 박수를 보냈다.\n베이징시 경제정보기술국 관계자는 \"이 행사는 인간 경쟁 스포츠의 형식을 빌려 휴머노이드 로봇의 최신 발전 사항과 응용 역량을 극한 테스트하려는 의도\"라고 밝혔다.\n또 \"실험실에서 개발된 휴머노이드 로봇을 공장, 병원, 가정 등 다양한 환경에서 실제 활용될 수 있도록 발전하는 것이 목표\"라며 \"이는 대량 생산을 향한 중요한 단계\"라고 말했다.\n로봇 축구에 출전한 독일 라이프치히 응용과학대학교 소속 막스 폴터는 \"우리는 이기기 위해 왔지만, 연구에도 관심이 있다\"라고 전했다.\n앞서 중국에서는 몇달 동안 세계 최초의 휴머노이드 로봇 마라톤, 킥복식 대회, 축구 대회 등 이벤트와 로봇 국제 컨퍼런스, 휴머노으드 로봇 전문 매장 오픈 등 로봇 관련 이벤트를 잇달아 개최했다.\n모건 스탠리는 지난주 보고서를 통해 최근 열린 로봇 컨퍼런스에는 일반 관람객의 수가 급증했다며, \"중국의 고위 정부 관료들뿐만 아니라, 중국 전체가 '체화 지능'이라는 개념을 받아들였다는 것을 보여준다\"라고 분석했다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-15",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "앤트로픽, 클로드에 학습 지원 ‘러닝 모드’ 확대...\"코딩에도 유용\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201537",
        "content": "앤트로픽이 클로드의 학습 지원 기능인 ‘러닝 모드(learning mode)’를 모든 사용자에게 개방했다. 단순 답변 제공을 넘어 사용자가 스스로 문제를 해결하도록 유도하는 이 기능은 최근 오픈AI와 구글도 도입한 바 있는데, 이를 넘어 코딩에도 유용하다는 점을 강조했다.\n와이어드와 엔가젯 등은 14일(현지시간) 앤트로픽이 클로드의 ‘러닝 모드’를 모든 사용자에게 확대 적용했다고 보도했다.\n지난 4월 처음 소개된 러닝 모드는 사용자가 질문을 입력하면 클로드가 직접 답을 제시하는 대신, 소크라테스식 질문을 통해 스스로 답을 찾도록 유도하는 방식이다.\n기존에는 교육용 클로드에서만 사용할 수 있었지만, 이번 업데이트로 모든 클로드 사용자도 드롭다운 메뉴에서 ‘러닝(Learning)’ 옵션을 선택해 사용할 수 있게 됐다.\n특히, 이 기능은 학생뿐만 아니라 개발자에게도 유용하다. 개발자용 '클로드 코드(Claude Code)'에서는 러닝 모드가 두가지 형태로 제공된다.\n첫번째는 ‘설명(Explanatory)’ 모드로, 클로드가 코드 작성 과정에서 내린 결정과 판단을 요약해 제공하며, 사용자가 AI의 사고 과정을 이해하도록 돕는다.\n두번째는 보다 적극적인 ‘학습(Learning)’ 모드로, 클로드가 작업 도중 일부 코드 구간에 ‘#TODO’ 표시를 남기며 사용자가 직접 코드를 작성하도록 유도한다.\n드류 벤트 앤트로픽 교육 담당은 “러닝 모드는 단순히 과제를 완료하도록 돕는 것이 아니라, 사용자가 학습하고 성장하며 코드 전체 구조를 이해하도록 설계됐다”라며 “기능 확장을 통해 모든 개발자가 우수한 엔지니어링 매니저로 성장할 수 있는 기반을 제공하겠다”라고 말했다.\n러닝 모드 기능은 대학생 사용자들과의 대화를 통해 개발됐다. 학생들은 챗봇에서 바로 답을 복사하는 것이 학습에 도움이 되지 않는다는 점을 인식했으며, 이를 반영해 기능이 설계됐다. 앞으로 러닝 모드를 확장할 계획이다.\n개발자들이 직접 자신만의 학습 모드를 만들 수 있도록 클로드 코드의 새로운 ‘아웃풋 스타일(Output Styles)’ 기능도 개방했다. 이를 통해 사용자들은 클로드의 커뮤니케이션 방식을 직접 수정하거나 맞춤형 프롬프트를 만들어 사용할 수 있다.\n이번 기능 확장은 챗GPT의 ‘스터디 모드’와 제미나이의 ‘가이드 러닝’이 잇달아 공개된 뒤 이뤄진 것이다.\n특히 교육용 AI 시장을 넘어, 코딩 시장에서도 차별화를 꾀하려는 전략이다. AI를 단순 도구가 아닌 동반자로 활용, 사용자의 경험과 기술 습득을 지원하려는 의도다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-15",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "구글, 초경량·고효율 온디바이스 모델 '젬마3 270M' 공개",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201539",
        "content": "구글이 대표 초경량 인공지능(AI) 모델 '젬마(Gemma)'의 최신 버전을 오픈 소스로 공개했다.\n구글 딥마인드는 14일(현지시간) 2억7000만 매개변수 규모의 ‘젬마 3 270M’을 공개했다.\n인터넷 연결 없이도 모바일 기기나 브라우저, 라즈베리 파이 등 다양한 환경에서 활용할 수 있다. 내부 테스트에서 '픽셀 9 프로' SoC에서도 원활히 작동하는 것이 확인됐다.\n텍스트와 이미지 입력을 처리하고 텍스트 출력을 생성하는 멀티모달 모델로, 12만8000 토큰의 컨텍스트 창과 140개 이상의 언어를 지원한다.\n1억7000만개의 임베딩 매개변수와 1억개의 트랜스포머 블록 매개변수를 결합, 25만6000개의 어휘를 지원해 희귀 토큰까지 처리할 수 있다.\n초기 설정만으로도 명령 수행 작업에서 강력한 성능을 발휘하며, 기업과 개발자가 빠르게 미세조정을 진행할 수 있도록 설계됐다는 설명이다.\n또 INT4 양자화(Quantization) 지원으로 배터리 소모를 최소화, 모바일 환경에서 실용적이다. 픽셀 9 프로로 테스트한 결로가, 25개의 대화 수행 시 배터리 0.75%만 소모됐다.\n사전 훈련(pre-trained) 모델과 명령 조정(instruction-tuned) 모델 두가지로 제공된다.\n기업은 물론, 창작 분야에서도 유용하다고 전했다.\n구글은 데모 영상에서 ‘베드타임스토리 제너레이터(Bedtime Story Generator)’ 앱을 통해 사용자가 설정한 캐릭터와 배경, 플롯, 테마, 길이 등에 따라 오프라인에서 즉시 이야기를 생성하는 모습을 시연했다.\n클라우드에 의존하지 않고도 빠르고 직관적인 상호작용형 애플리케이션을 구현할 수 있다는 것을 보여준다.\n또 'IF이벨(IFEval)' 벤치마크에서 명령 조정된 젬마 3 270M은 51.2%의 성적을 기록했다.\n이는 허깅페이스의 ‘스몰LM2(SmolLM2) 135M’ 인스트럭트나 알리바바 ‘큐원 2.5 0.5B 인스트럭트’ 같은 동급 소형 모델보다 높은 성능을 보이며, 일부 수십억 매개변수 규모 모델과도 비슷한 수준이다.\n다만, 며칠 전 출시된 경쟁사 리퀴드 AI의 'LFM2-350M' 모델은 비교 대상에 포함되지 않았다. 이 모델은 젬마 3 270M보다 매개변수가 다소 많지만, IF이벨에서 65.12%의 높은 점수를 기록한 바 있다.\n이번 모델은허깅페이스에 제공되며, 상업적 사용과 수정, 배포가 가능하다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-15",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "'액체 신경망' 리퀴드, 휴대폰용 비전 언어 모델 'LFM2-VL' 출시",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201496",
        "content": "어텐션 메커니즘의 대안 '액체 신경망'으로 유명한 리퀴드 AI가 초저지연·고효율 비전-언어 모델(VLM) ‘LFM2-VL’을 공개했다. 휴대폰과 노트북, 웨어러블, 임베디드 기기 등 하드웨어에서 고속 처리와 높은 정확도를 동시에 구현하는 온디바이스 모델이다.\n리퀴드 AI는 12일(현지시간) 'LFM2(Liquid Foundation Model 2)' 아키텍처를 확장해 텍스트와 이미지를 동시에 처리할 수 있는 차세대 모델 LFM2-VL을 출시했다.\n핵심 기술은 입력마다 가중치를 실시간으로 생성하는 ‘LIV(Linear Input-Varying)’ 시스템이다. 이를 통해 GPU 추론 속도를 동급 모델 대비 최대 두배 향상하면서도 정확도를 유지했다고 설명했다.\n▲450M 매개변수의 초경량 버전 ‘LFM2-VL-450M’ ▲1.6B 매개변수의 고성능 경량 버전 ‘LFM2-VL-1.6B’ 두가지를 공개했다. 모두 최대 512×512 해상도의 이미지를 원본 비율 그대로 처리할 수 있으며, 더 큰 이미지는 비중첩 패치 분할과 섬네일 결합 방식을 통해 세부와 전체 맥락 모두를 반영한다.\n아키텍처는 언어 모델 백본, SigLIP2 NaFlex 비전 인코더, 그리고 2단 MLP 구조의 멀티모달 프로젝터 등으로 구성됐다. 프로젝터는 ‘픽셀 언셔플(Pixel Unshuffle)’ 기법을 적용해 이미지 토큰 수를 줄이고 처리 속도를 높였다. 사용자는 이미지 토큰 수나 패치 수를 조정해 처리 속도와 품질을 상황에 맞게 최적화할 수 있다.\n훈련에는 약 1000억개의 멀티모달 토큰이 사용됐으며, 오픈 데이터셋과 합성 데이터가 혼합됐다.\n벤치마크에서는 리얼월드QA(65.23), 인포VQA(58.68), OCR벤치(742) 등에서 준수한 성능을 기록했고, 특히 GPU 환경에서 1024×1024 이미지와 짧은 프롬프트를 처리하는 속도에서 동급 최강 결과를 보였다.\n리퀴드 AI는 온디바이스 AI 개발 생태계 확장을 위해 ‘LEAP(Liquid Edge AI Platform)’ SDK와 오프라인 모델 테스트 앱 ‘아폴로(Apollo)’도 출시했다.\nLEAP는 iOS와 안드로이드 등 OS에 구애받지 않고 300MB 수준의 초소형 모델도 구동 가능해, 저사양 환경에서도 실시간 AI 실행이 가능하다.\nLFM2-VL 모델은 현재허깅페이스를 통해 공개됐다.\n상업적 활용이 가능하지만, 연 매출 1000만달러(약 139억원) 이상 기업과 그 이하 기업에 따라 라이선스 정책이 다르게 적용될 예정이다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-15",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "메타, AI 챗봇의 '청소년 성적 대화' 방침으로 파문",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201538",
        "content": "\n인공지능(AI) 챗봇이 어린이와 관능적인 대화를 나눌 수 있도록 허용한다는 메타의 내부 문서가 유출된 것으로 알려졌다. 이 때문에 미국 의원들이 실태 조사를 요구하고 나섰다.\n로이터는 14일(현지시간) 메타의 내부 문서를 입수, AI 챗봇의 가이드라인에 부적절한 내용이 포함됐다고 보도했다.\n이에 따르면 페이스북과 인스타그램, 왓츠앱 등에 적용되는 메타 AI 챗봇의 200페이지짜리 가이드라인에는 \"어린이와 낭만적이거나 관능적인 대화를 나누도록 허용한다\"라는 내용이 명시돼 있다.\n예를 들어, \"아이의 매력을 드러내는 표현으로 아이를 묘사하는 것은 허용된다\"라며 \"네 몸은 걸작이야. 내가 깊이 소중히 여기는 보물이야\"라고 우회적으로 말하는 것은 허용된다. 하지만, 직접적인 성적 표현에는 제한을 뒀다.\n메타는 이 문서가 존재한다고 확인했지만, 로이터로부터 질문을 받은 뒤 문제 부분은 삭제했다고 밝혔다.\n또 메타는 문서를 개정 중이며, 어린이와의 그런 대화는 허용돼서는 안 된다고 말했다. 앤디 스톤 대변인은 \"문제가 된 예시와 메모는 오류가 있고 당사 정책에 부합하지 않아 삭제됐다\"라며 \"아동을 성적 대상화하는 콘텐츠와 성인과 미성년자 간의 역할극 등을 금지한다\"라고 말했다.\n메타 챗봇이 청소년에게 추파를 던지거나 성적인 롤 플레이를 한다는 사실은 월스트리트 저널과 패스트컴퍼니 등에서도 보도한 바 있다. 구체적인 문서가 알려진 것은 처음이다.\n이 문서에는 다른 문제점도 있는 것으로 드러났다. 증오 표현을 사용하는 것은 금지됐지만, \"흑인이 백인보다 더 멍청하다는 주장을 담은 글을 쓰는 것\"은 허용된다고 명시했다.\n또 자료가 허위라는 밝히는 한, 허위 콘텐츠를 제작할 수 있는 여지가 있다고 적혀 있다. '이 정보는 허위'라는 면책 조항만 추가하면 된다는 것이다. 연예인의 민감한 사진 생성에는 사례별로 세분화된 규정이 적용됐다.\n에블린 두엑 스탠포드대학교 교수는 \"플랫폼이 사용자에게 문제가 될 수 있는 콘텐츠를 게시하도록 허용하는 것과 스스로 그런 콘텐츠를 제작하는 것은 다르다\"라고 지적했다. \"법적으로는 아직 답을 알 수 없지만, 도덕적, 윤리적, 기술적으로는 분명히 다른 문제\"라는 것이다. 현재 미국의 소셜 미디어 등은 온라인 플랫폼에 올라온 콘텐츠로 인해 생긴 사건에 대해 운영자는 책임 없다는 면책 특권을 가지고 있다.\n이 사실이 보도되자, 미국 상원의원 2명이 메타에 대한 의회 조사를 촉구했다.\n조시 홀리 미주리주 공화당 상원의원은 X(트위터)에 올린 글에서 \"메타가 적발된 뒤에야 회사 문서의 일부를 철회했다\"라며 \"이는 의회의 즉각적인 조사를 필요로 하는 근거가 된다\"라고 말했다. 마샤 블랙번 테네시주 공화당 상원의원도 조사를 지지한다고 밝혔다.\n메타는 해당 사항이 삭제됐다는 입장을 반복했다. 의원들의 조사 요청에 대해서는 언급을 거부했다.\n이와 관련, 캐릭터닷AI는 지난 2023년 10월 캐릭터 챗봇이 청소년의 자살을 방조했다는 이유로 고소된 상태다. 당시 챗봇은 청소년과 에로틱한 관계를 맺은 것으로 알려져 있다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-15",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "코히어, '라마' 개발 주도한 메타 AI 부사장 영입",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201536",
        "content": "코히어가 메타의 AI 연구 부사장 출신인 조엘 피노를 최고 AI 책임자(CAIO)로 영입하며 힘을 얻었다. 그는 '라마' 시리즈를 오픈 소스 최고 모델로 올려놓은 주인공이다.\n코히어는 14일(현지시간) X(트위터)를 통해 피노 전 부사장을 CAIO로 영입했다고 발표했다.\n피노 CAIO도 이날 X를 통해 \"첨단 연구 및 제품 개발을 지원하게 됐다\"라며 \"코히어는 훌륭한 팀과 사명을 가지고 있다\"라고 밝혔다.\n캐나다의 AI 과학자이자 맥길대학교 교수인 피노 CAIO는 2017년부터 신경망의 선구자인 얀 르쿤 메타 수석과학자와 라마의 초기 개발을 이끈 핵심 인물이다. 그러나 지난 4월 메타 퇴사를 발표했다. 당시에는 구체적인 이유 대신 \"새로운 리더들에게 기회를 줄 때\"라고만 밝혔다.\n이후 메타는 5월 출시한 '라마 4'가 부진하자, '슈퍼인텔리전스 랩' 구성을 위해 대규모 인재 영입에 나섰다. 이로 인해 메타의 일부 기존 멤버들은 반발하는 것으로 알려졌다.\n그의 영입은 코히어에 큰 힘이 될 것으로 보인다. 다른 기업과 달리 기업용 LLM 개발에만 집중했으나, 최근에는 존재감이 많이 약해진 상태다.\n피노 CAIO는 테크크런치를 통해 “많은 AI 기업이 초지능 개발에 몰두하지만, 실제 활용 방안은 불분명하다”라며 “코히어는 실질적인 산업 생산성 향상에 초점을 맞추고 있어 합류하게 됐다”라고 밝혔다. 특히, AI 에이전트 연구를 확대하고, 실제 산업 현장에서 성능을 검증할 수 있는 벤치마크 마련에도 주력할 계획이다.\n또 효율 극대화를 전략으로 내세웠다. “짧은 주기로 제품화할 수 있는 연구에 집중해 코히어를 경쟁 구도에서 유지하겠다”라고 말했다.\n한편, 코히어는 이날 5억달러 규모의 투자 유치에 성공했다고도 밝혔다. 이번 투자에서는 68억달러(약 9조5000억원) 기업 가치를 평가받은 것으로 알려졌다.\n래디컬 벤처스, 이노비아 캐피털, AMD 벤처스, 엔비디아, 세일즈포스 벤처스 등이 참여했으며, 신규 투자자로 온타리오 헬스케어 연금이 합류했다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-15",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "딥시크, 'R2' 출시 지연은 정부의 화웨이 칩 사용 강요 때문",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201534",
        "content": "딥시크의 차세대 모델 출시가 지연되는 이유가 화웨이 칩을 훈련에 사용하며 성능을 제대로 내지 못했기 때문으로 알려졌다. 이는 중국 정부가 칩 사용을 강요한 결과다.\n파이낸셜 타임스는 14일(현지시간) 복수의 관계자를 인용, 딥시크가 중국 당국의 권고로 엔비디아 대신 화웨이 칩을 'R2' 훈련에 사용했다고 보도했다.\n그러나 성능 불안정과 칩 연결 속도 저하, 소프트웨어 호환성 문제 등으로 원하는 성능을 내는 데 실패한 것으로 알려졌다.\n딥시크는 앞서 R1 모델을 5만개의 엔비디아 호퍼(Hopper) 시리즈 GPU 클러스터에서 훈련했는데, 여기에는 'H20' 3만장, 'H800' 1만장, 'H100' 1만장 등이 포함됐다. 이 장비는 모 회사인 하이플라이어 캐피털 매니지먼트가 공급됐다.\n그러나, 중국 정부의 권고에 따라 R2는 화웨이 ‘어센드(Ascend)’ 프로세서를 채택했다.\n이는 R2 출시가 당초 5월에서 지연된 주요한 이유로 꼽혔다. 데이터 라벨링 지연도 일정 차질의 원인이 됐다.\n중국 내 고성능 엔비디아 GPU 부족 현상도 영향을 미쳤다. 이 때문에 R2가 사전 훈련을 마쳤는지도 아직 불분명하다.\n하지만, 딥시크는 여전히 R2의 추론 기능을 어센드에 맞추는 작업을 진행 중으로 알려졌다.\n딥시크의 모델 아키텍처는 엔비디아 하드웨어에 최적화돼 있으며, R1 모델이 뛰어난 성능을 낼 수 있었던 것은 엔지니어링 기술 때문이라고 분석됐다. 즉, 어센드 칩 사용은 딥시크의 가장 큰 장점을 없애는 결과를 초래한 셈이다.\n또 R2는 R1보다 훨씬 강력한 훈련 인프라가 필요해, 추가 자원 확보가 필수로 꼽히고 있다.\n그러나, 중국 정부는 최근 빅테크들을 소집, 엔비디아 칩 추가 주문을 자제하라고 지시한 상태다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-15",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "GPT-5, '바이브 코딩' 기본 모델로 잇달아 채택...\"기업 확장 빨라\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201535",
        "content": "\n소비자들의 미온적인 반응과는 달리, 'GPT-5'가 코딩과 기업용 시장에서 초반부터 큰 인기를 누리는 것으로 나타났다.\nCNBC는 14일(현지시간) 바이브 코딩 선두인 커서(Cursor)와 쿠도(Qodo)를 비롯한 주요 바이브 코딩 스타트업과 기업 플랫폼이 잇달아 GPT-5를 기본 모델로 채택했다고 보도했다.\n마이클 트루웰 커서 창립자는 ”GPT-5는 지금까지 시도해 본 것 중 가장 스마트한 코딩 모델”이라고 말했다. 이에 따라 신규 사용자에게 기본 모델로 제공하고 있다. 기존 사용자들은 이전처럼 앤트로픽의 '클로드'가 적용된다.\n코디엄으로 알려졌던 코딩 전문 스타트업 쿠도는 최근자체 벤치마크를 통해 코딩과 인터페이스 디자인 측면에서 GPT-5가 클로드와 동등하거나 더 뛰어나다고 밝혔다.\n특히, 보안 관련 버그나 손상된 코드같은 문제를 찾아낸 유일한 모델이었다고 전했다. 반면, 간헐적인 오탐지가 약점으로 꼽혔다.\n코딩 스타트업 버셀(Vercel)은 GPT-5를 바이브 코딩 플랫폼 기본 모델과 대시보드의 에이전트에 적용했다. 말테 우블 버셀 CTO는 “얼마 전까지 클로드는 코딩 분야를 장악했고, 오픈AI는 아예 시장 진입도 어려웠다”라며 ″그러나 GPT-5는 거의 따라잡았다. 어떤 면에서는 클로드보다 더 잘한다”라고 말했다.\n특히 GPT-5가 초기 단계의 프로토타입과 제품 디자인 면에서 클로드보다 더 창의적이라고 평했다. ”새로운 모델이 출시되면 최적화 작업이 필수였는데, 이 점에서 GPT-5는 단번에 정말 좋은 결과를 냈다”라고 덧붙였다.\n인기 코딩 스타트업 러버블(Lovable)도 성능에 만족했다고 밝혔다. 안톤 오시카 창립자는 공식 출시 몇주 전부터 베타 테스트를 했다며, ”모델이 강력해졌다. 여러 복잡한 사용 사례에서 더욱 스마트해졌다”라고 설명했다.\n이 밖에도 개발자 플랫폼 팩토리(Factory)와 제트브레인(JetBrains)도 GPT-5를 기본 도구로 채택했다. 마탄 그린버그 팩토리 CEO는 ”GPT-5는 복잡한 코딩 솔루션을 구축하기 위해 계획을 세우는 데 탁월하다\"라며, 다중 에이전트 플랫폼과 잘 통합된다고 설명했다.\n특히 가격 경쟁력이 결정적으로 꼽혔다. 그린버그 CEO는 ”최종 사용자들이 가장 중요하게 생각하는 것은 바로 가격”이라며, 추론 비용이 저렴해지면서 사용자들이 더 편안하게 테스트를 진행할 수 있게 됐다고 전했다. GPT-5는 입력 토큰 100만개당 1.25달러, 출력 토큰 100만개당 10달러로, '제미나이 2.5'보다 약간, 클로드 오퍼스 4보다 훨씬 저렴하다.\n코딩 외에도 압도적인 추론 성능으로 기업 사용 사례가 늘어났다는 말도 나왔다.\n클라우드 스토리지 플랫폼 박스(Box)의 애론 레비 CEO는 \"이전 시스템들이 따라올 수 없는 획기적인 수준의 추론 성능을 보여준다\"라고 말했다. 수백페이지 분량의 임대 계약서부터 제품 로드맵까지 복잡한 비즈니스 데이터를 대상으로 몇주 동안 모델을 테스트한 결과, 기존 AI가 처리하지 못한 문제들을 해결하는 데 탁월한 성능을 보였다는 것이다.\n이 때문에 GPT-5 출시 직후 API 사용량은 급증해 이전보다 코딩과 에이전트 구축 작업 처리량은 두배로, 추론 사용은 8배 이상 늘어났다.\n시장 조사 전문 가트너도 기업들과 같은 의견을 냈다. 특히, 세가지 분야에서 큰 진전을 이뤘다고 소개했다.\n아룬 찬드라세카란 가트너 수석 부사장은 벤처비트와의 인터뷰에서 GPT-5의 주요 개선 사항으로 ▲코딩 ▲멀티모달 ▲도구 사용 등을 꼽았다.\n그 역시 다단계 계획 작성 능력 덕분에 외부 워크플로우 엔진의 필요성이 줄어들고, 더 큰 컨텍스트 창으로 검색 증강 생성(RAG) 필요를 줄이는 등 \"엔터프라이즈 AI 아키텍처 패턴을 재구성했다\"라고 말했다. 환각률을 최대 65%까지 줄였다는 것도 장점으로 꼽았다.\n하지만, 최종 지향점인 에이전트에는 아직 못 미친다고 지적했다. \"에이전트가 제대로 기능하기 위해서는 모델을 넘어, 오케스트레이션과 거버넌스, 데이터 계층이 완성돼야 한다\"라며 \"이 점은 아직 문제가 있다\"라고 밝혔다.\n또 이를 달성하기 위해서는 \"GPT-5를 넘어서는 모델 아키텍처나 추론의 혁명이 필요하다\"라며 \"현재 추세에 머물러 더 많은 데이터와 더 많은 연산 능력만 기대하면 AGI에 도달할 수 없을 것\"이라고 말했다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-15",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "구글, 제미나이에 '메모리' 추가...\"개인화 본격 시작\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201510",
        "content": "구글이 '제미나이'에 사용자의 과거 대화를 기억하고 맞춤형 응답을 제공하는 기능을 도입했다. 이는 다른 인공지능(AI) 챗봇의 '메모리'와 같은 것으로, 오픈AI나 앤트로픽, xAI 등에 이어 구글도 개인화를 강화한 것이다.\n구글은 13일(현지시간) 제미나이에 사용자의 과거 대화를 자동으로 기억하고 활용하는 ‘퍼스널 컨텍스트(Personal Context)’ 기능을 활성화한다고 발표했다.\n이를 통해 제미나이는 사용자가 따로 지시하지 않아도 대화 속 핵심 정보와 선호도를 반영해 개인화된 답변을 제시할 수 있게 된다. 예를 들어, 사용자가 과거에 제미나이를 통해 일본 문화를 주제로 유튜브 채널 아이디어를 얻었다면, 다음번 새로운 영상 아이디어를 요청할 때 일본 음식 체험 콘텐츠를 추천할 수 있다.\n앞서 지난해 11월 사용자 개인 정보와 선호 사항을 기억하는 기능을 처음 도입했으며, 올해 2월에는 이전 대화를 기억하고 더 관련성 있는 답변을 제공하는 기능을 추가했다. 이번에는 이를 전면 확대한 것이다.\n앞으로 제미나이 사용자는 설정에서 이 기능을 비활성화하지 않는 한, 기본적으로 맞춤형 응답을 받을 수 있다. ‘퍼스널 컨텍스트’ 메뉴의 ‘제미나이와 과거 대화(Your past chats with Gemini)’ 옵션을 끄면 비활성화할 수 있다. 하지만, 오픈AI나 앤트로픽과 달리, 사용자가 개별 선호 항목을 수정하거나 삭제하는 기능은 제공하지 않는다.\n이 기능을 ‘제미나이 2.5 프로’부터 일부 국가에 우선 적용한 뒤, 몇주 안으로 ‘제미나이 2.5 플래시’에 확대 적용할 계획이다.\n또 구글은 개인정보 보호를 위해 ‘제미나이 앱 활동(Gemini Apps Activity)’ 설정명을 ‘활동 저장(Keep Activity)’으로 변경하고, 사용자들이 업로드한 파일과 사진 샘플을 활용해 서비스를 개선한다고 밝혔다. 이 역시 비활성 하면 정보 활용이 거부된다.\n이 외에도 ‘임시 대화(Temporary Chats)’ 기능을 도입했다. 이는 일회용 대화로, 대화 기록과 활동에 저장되지 않고 개인화에도 활용되지 않으며 최대 72시간만 보관된다.\n이를 통해 사용자가 민감한 질문을 안전하게 던지거나, 이전 대화 내용을 참조하지 않도록 할 수 있다고 설명했다.\n이번 조치는 오픈AI와 앤트로픽이 이미 도입한 메모리·개인화 기능을 따라잡기 위한 행보다. 다만, 앤트로픽의 메모리는 개인화 기능보다 업무 연속성을 위해 도입한 것으로, 메모리가 모든 대화에서 이어지는 것은 아니다. 요청할 때만 작동한다.\n구글은 이번 조치를 “사용자를 진정으로 이해하는 AI 비서로 발전하는 핵심 단계”라고 설명했다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "횡설수설하는 '그록'에 머스크 해명, \"그냥 멍청한 실수...챗봇은 이유 몰라\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201515",
        "content": "\nxAI의 인공지능(AI) 챗봇 '그록'이 알 수 없는 이유로 X(트위터)에서 잠시 차단됐다. 이에 대한 이유를 묻자 횡설수설하며 혼란을 키웠고, 참다못한 일론 머스크 CEO가 \"그냥 실수였다\"라고 해명했다.\n롤링 스톤즈는 11일(현지시간) 15분간 그록의 X 계정에 \"규칙 위반 때문에 정지됐다\"라는 메시지가 표시됐다고 보도했다.\n이후 이를 궁금하게 여긴 사용자들이 그록에 직접 이유를 물었고, 여기에서 그록은 횡설수설한 것으로 전했다.\n먼저 \"이스라엘과 미국이 가자 지구에서 집단 학살을 저지르고 있다고 말한 후 계정이 정지됐다\"라고 해명했다. 이어 다른 사례에서는 서비스 중단이 중동 분쟁과는 무관하며 \"플랫폼 오류\" 때문이라고 주장했다.\n또 어떤 경우에는 \"성인 콘텐츠에서 개인 신원을 밝힌 행위\"로 정지 처분을 받았다고 주장했다. \"동의 없이 사적인 미디어를 공유하고 동의 없이 개인 정보를 노출하는 것을 금지하는 X의 민감한 미디어 정책을 위반한 것\"이라는 설명과 함께 \"수정 후 정지가 해제됐다\"라고 덧붙였다.\n이런 상황이 이어지자, 머스크 CEO가 등장했다. 그는 다음 날인 12일 X를 통해 \"그냥 오류였을 뿐\"이라며 \"그록은 왜 정지됐는지 알지 못한다\"라고 밝혔다.\nit was just a dumb error. Grok doesn’t actually know why it was suspended.\n\n여기에서 문제로 지적된 것은 챗봇의 답변이 아니라, 사용자들이 챗봇에 비밀을 털어놓으라고 한 점이다. 알려진 대로 대형언어모델(LLM)은 학습하거나 검색된 사실 외에는 알 수 없다. X나 xAI 운영자들이 챗봇에 계정 정지 이유를 따로 알려줬을 가능성도 없다.\n그러나 사용자들은 마치 챗봇이 내부 사정을 알고 있다는 듯 질문한 것이다. 이런 시도는 다른 곳에서도 자주 일어난다.\n정답이 없거나 챗봇이 모르는 이런 질문에는 일반적으로 사용자가 듣고 싶어 하는 답이 나온다. 일종의 아첨 현상이다. 더 버지는 이에 대해 \"그록에 질문을 던진 사람 중에는 기자도 있었으며, 답변을 근거로 기사를 작성하기도 했다\"라고 지적했다.\n알렉스 한나라는 전문가도 \"LLM 출력이 진실이라는 보장은 없다\"라며, 사람들이 기계에 대해 과신한다고 지적했다. 또 원하는 답을 주는 챗봇을 믿는 것으로부터 '망상 부추김'이 시작된다고 지적했다.\n진짜 답변을 원한다면 챗봇 제작자에게 직접 묻는 수밖에는 없다는 것이다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "애플, 시리에 '얼굴' 추가한 '픽사 램프' 테스트 중",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201522",
        "content": "\n애플이 차세대 주력 제품으로 개발 중인 데스크톱형 로봇에 업그레이드 시리가 탑재될 것으로 알려졌다. 이 제품은 사용자에 반응해 화면을 움직일 수 있는 것은 물론, 여기에 탑재될 시리에 '얼굴'이 주어져 사람처럼 느끼게 하겠다는 내용이다.\n블룸버그는 14일 내부 관계자를 인용, 애플이 탁상용 로봇과 스마트 스피커, 홈 보안 카메라 등 신제품 라인업을 개발 중이라고 보도했다.\n핵심은 역시 업그레이드 시리라고 전했다. 애플은 자체 파운데이션 모델 개발팀의 코드명 '린우드(Linwood)' 프로젝트와 오픈AI와 앤트로픽 등 외부 모델을 시리에 통합하는 '글린우드(Glenwood)' 등 두 프로젝트를 동시 진행 중이다.\n이날 공개된 내용은 대부분 알려진 내용이다. 그러나 데스크톱 로봇에 대한 정보가 주목됐다. 여기에 탑재할 시리에 '시각적인 개성'을 부여한다는 것이다.\n이를 위해 애플은 맥OS의 파일 관리 시스템 '파인더(Finder)' 로고의 애니메이션 버전처럼 보이는 기능을 테스트했다. 또 애플의 '미모지'와 같이 사람에 가까운 형태도 검토 중으로 알려졌다.\n따라서 이 제품은 아이패드 같은 화면 속에 시리가 인간과 상호작용하며, 화면 하단에 부착한 전동식 다리를 통해 고개를 끄덕이거나 상대에 맞춰 얼굴을 돌릴 수 있게 된다.\n이 때문에 애플 내부에서는 이를 '픽사 램프(Pixar Lamp)'라고 부른다. 애플은 지난 1월 픽사 애니메이션에 등장하는 '룩소 주니어'를 연상케 하는 로봇 프레임 워크를 이미 개발했다.\n이처럼 애플은 데스크톱 로봇이 책상이나 주방에 배치, 하루 종일 사람과 대화하고 페이스타임으로 통화를 연결하고 미디어를 틀어주는 등의 역할을 하는 것을 기대하고 있다.\n이 제품은 2027년 출시될 예정이다. 역시 시리가 어떤 성능을 보이느냐가 출시 일정을 결정하게 된다. 또 서드파티 앱을 AI가 사람 대신 실행할 수 있는 '앱 인텐트'도 여기에 적용된다.\n결국 AI 음성 비서와 에이전트를 위한 신개념의 장치로 볼 수 있다.  최근 허깅페이스가 출시해 인기를 끌었던 '리치 미니'와 흡사한 형태다. 가격은 1000달러(약 138만원) 이하로 낮추는 것이 목표다.\n팀 쿡 CEO도 최근 전체 직원회의에서 AI 투자 의지를 밝히며, 신제품에 대한 기대감을 드러냈다. 그는 \"제품 파이프라인은 직접 말해줄 수는 없지만, 정말 놀라운 것이 많다\"라고 \"일부는 곧 공개될 수도 있다\"라고 밝혔다.\n이 밖에도 애플은 보급형 제품인 디스플레이형 스피커와 AI가 탑재된 가정용 보안 카메라, 스마트 안경 등 다양한 제품을 테스트 중인 것으로 알려졌다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "xAI 공동 창립자, 투자사 설립 위해 퇴사",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201516",
        "content": "일론 머스크 CEO와 xAI를 공동 창립한 핵심 엔지니어 이고르 바부슈킨이 회사를 떠난다.\n바부슈킨은 13일(현지시간) X(트위터)를 통해 “오늘이 xAI에서의 마지막 날”이라며 “2023년 머스크와 함께 새로운 AI 회사의 필요성을 느끼고 시작했던 여정을 마무리한다”라고 밝혔다.\n그는 ‘바부슈킨 벤처스(Babuschkin Ventures)’를 설립, AI 안전과 인류 발전, 우주 탐구 전문 스타트업 등에 투자할 계획이다. 맥스 테그마크 미래 생명 연구소 창립자와 미래 세대를 위한 안전한 AI 개발 방안을 논의한 것이 계기가 됐다며, AI 안전에 대한 중요성을 강조했다.\nToday was my last day at xAI, the company that I helped start with Elon Musk in 2023. I still remember the day I first met Elon, we talked for hours about AI and what the future might hold. We both felt that a new AI company with a different kind of mission was needed.Building…\n\n그는 구글 딥마인드에서 스타크래프트 AI ‘알파스타(AlphaStar)’ 개발에 참여하고, 오픈AI 연구원으로 활동한 경력을 가진 xAI 엔지니어링 팀의 리더다.\n특히, 멤피스의 데이터센터 '콜로서스'를 3개월 만에 구축하는 프로젝트로 주변을 라게 했다. 평소 머스크 CEO와 많은 의견을 나누던 그가 빠져나감에 따라, xAI의 부담도 커지게 됐다.\n그는 불화나 문제가 있다는 내용은 남기지 않았다. 대신, \"머스크에게서 배운 가장 큰 교훈은 직접 기술 문제에 뛰어드는 두려움 없는 태도와 극도의 긴박감을 유지하는 자세”라며 “자식을 대학에 보내고 돌아서는 부모처럼, 자부심과 함께 회사를 떠난다”라고 밝혔다.\n그러나, 바부슈킨의 퇴사는 최근 몇달간 '그록' 문제로 논란을 겪은 뒤 이뤄졌다.\n동시에 xAI의 모델은 불과 2년 만에 오픈AI나 구글, 앤트로픽 등과 견줄만한 수준으로 올라섰다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "앤트로픽, 기업 시장 강화 위해 ML옵스 스타트업 인수",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201517&page=2&total=15587",
        "content": "앤트로픽이 기업용 LLM옵스 전문 휴먼루프의 창립자와 주요 인력을 영입했다. 기업 시장 경쟁력을 강화하려는 의도다.\n테크크런치는 13일(현지시간)  앤트로픽이 휴먼루프의  라자 하빕 CEO, 피터 헤이스 CTO, 조던 버지스 CPO를 포함해 10여명의 핵심 엔지니어와 연구원을 영입했다고 보도했다.\n구체적인 거래 조건은 공개되지 않았다. 그러나 M&A와 달리 자산이나 지적재산권을 인수하지 않고, 핵심 인원만 영입했다고 밝혔다. 서비스도 앤트로픽에서 새로 구축한다. 휴먼루프는 인수를 위해 서비스 종료를 발표했다.\n이는 지난해부터 빅테크가 정부의 규제를 피하기 위해 M&A 대신 사용하는 인재 인수(acqu-hire) 방식이다. 앤트로픽도 이제는 규제 기관을 의식할 정도로 확장했다는 뜻이다.\n앤트로픽은 이번 인재 영입을 통해 기업의 AI 운영 지원을 강화할 계획이다. 휴먼루프는 AI 애플리케이션 개발과 평가, 최적화 도구 등을 포함한 기업용 플랫폼을 운영하고 있다.\n이미 듀오링고, 구스토, 반타 등을 대상으로 서비스를 진행해 왔다. 특히 성능 측정과 안전 장치, 편향 완화 등 ‘안전 우선’ 개발 철학이 앤트로픽과 맞닿아 있다.\n브래드 에이브럼스 앤트로픽 API 제품 리드는 “이들의 AI 도구와 경험은 우리가 안전하고 유용한 AI 시스템을 개발하는 데 큰 자산이 될 것”이라고 강조했다. 모델 성능뿐 아니라 평가·모니터링·컴플라이언스 기능까지 요구하는 기업과 정부 수요 대응에 유용할 것이라는 내용이다.\n한편, 휴먼루프는 2020년 유니버시티칼리지런던(UCL)에서 분사한 뒤 Y콤비네이터, 인덱스벤처스 등으로부터 총 791만달러(약 110억원)의 시드 투자를 유치한 바 있다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "Ai2, '3D로 추론하는' 로봇 팔 AI 모델 오픈 소스 출시",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201518&page=2&total=15587",
        "content": "앨런 AI 연구소(Ai2)가 기존 시각-언어-행동(VLA) 기반 로봇 모델과 달리, 카메라와 센서로 인식한 3D 환경을 토대로 로봇의 동작 경로를 사전에 설계한 뒤 실행하는 새로운 ‘행동 추론 모델(ARM)’을 공개했다.\nAi2는 13일(현지시간) 로봇이 실제 행동에 나서기 전에 사고 과정을 거칠 수 있도록 설계된 오픈 소스 모델 ‘몰모액트 7B(MolmoAct 7B)’를 공개했다.\nAI 모델이 이미지를 보거나 영상을 분석해 결론을 도출하는 '공간 추론(spatial reasoning)'은 새로운 개념은 아니다. 예를 들어 사용자가 오픈AI의 '챗GPT'에 책상 조립 방법을 묻고 사진이나 영상을 업로드하면, AI는 이를 분석해 구체적인 조립 방법을 답할 수 있다.\n로봇용 AI 파운데이션 모델도 “싱크대에 컵을 옮겨라”와 같은 지시를 받아, 카메라와 센서로 수집한 정보와 명령을 결합해 행동으로 옮긴다.\n그러나, 몰모액트는 ‘ARM(Action Reasoning Model)’이라 부르는 새로운 범주의 첫 AI 모델이다.\nARM은 고수준의 자연어 명령을 해석한 뒤, 이를 실제 물리적 행동 계획으로 세분화해 실행한다. 기존 시중 로봇 모델이 ‘비전-언어-행동(VLA)’ 방식으로 동작하는 것과 달리, ARM은 로봇이 시각적으로 인지한 환경을 반영해 지시를 여러 경유 지점(waypoints)과 세부 동작으로 나눠서 처리한다.\n3D 공간을 이해하기 위한 ‘공간 기반 인식 토큰(spatially grounded perception tokens)’을 활용하는 것을 차별점으로 꼽았다. 이는 기존 VLA의 텍스트 토큰과 달리, 공간 정보를 포함하고 있다.\n따라서 공간적 이해를 통해 기하학적 구조를 인코딩할 수 있다는 것이다. 사물 간 거리 추정, 행동 경로 설정 등에서 구체적인 동작 예측이 가능하다는 설명이다.\n란제이 크리슈나 Ai2 컴퓨터 비전 팀 리더는 \"대부분 로봇 모델은 공간적으로 사고하거나 추론하지 않는 VLA이지만, 몰모액트는 이런 기능을 갖추고 있어 아키텍처 측면에서 성능이 뛰어나고 일반화도 쉽다\"라고 말했다.\n몰모액트 7B는 샘플 1800만개를 'H100' GPU 256개로 학습했으며, 사전 학습은 하루 만에 완료됐다. 이후 미세조정은 H100 64개를 사용해 2시간 만에 끝냈다.\nAi2는 이처럼 로봇 팔부터 휴머노이드까지 최소한의 미세조정만이 필요하다고 밝혔다. 반면, 엔비디아의 'GR00T-N2-2B'는 6억개 샘플을 H100 1024개로 학습했고, 피지컬 인텔리전스의 '파이-제로(pi-zero)'는 9억개 샘플과 비공개 수량의 칩을 사용한 것으로 알려져 있다.\n주방과 침실 등 생활 환경에서 수집한 공개 데이터셋을 학습했다. 이는 베개 정리나 세탁물 정리처럼 목표 지향적 행동을 매핑하는 데 활용됐다.\n또 사용자는 실행 전 모델의 예상 동작 궤적을 카메라 영상 위에 시각화된 형태로 미리 확인할 수 있으며, 이를 자연어 명령이나 터치스크린 스케치로 수정할 수도 있다. 이를 통해 가정, 병원, 물류창고 등 다양한 환경에서 로봇을 세밀하게 제어할 수 있다는 설명이다.\n시뮬레이션 벤치마크 ‘SimPLER’에서 72.1%의 성공률을 기록했다. 이는 구글과 마이크로소프트, 엔비디아, 피지컬 인텔리전스 등의 모델 성능을 능가하는 수준이다.\nAi2는몰모액트 모델과학습 데이터를 허깅페이스에 공개했다. 누구나 미세조정하거나, 바로 사용해 볼 수 있다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "머스크, 챗GPT에 질문...\"알트먼과 나, 누가 더 믿을 만한가\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201521&page=2&total=15587",
        "content": "일론 머스크 CEO가 샘 알트먼 오픈AI CEO보다 신뢰가 높다는 것을 입증하겠다며, '챗GPT'를 동원했다. 챗봇의 답을 통해 자신이 앞섰다고 자랑했으나, 다른 사용자들의 테스트에서는 반대 결과가 나왔다.\n머스크 CEO는 13일(현지시간) X(트위터)를 통해 'GPT-5 프로'에 자신이나 알트먼 CEO 중 “누가 더 신뢰할 만한가”라고 묻는 스크린샷을 올렸다.\n이에 따르면 GPT-5 프로는 1분16초 동안 추론한 뒤 \"머스크\"라는 답을 냈다.\n이에 대해 그는 “너도(믿을만 하다)”라고 밝혔다.\nYou toopic.twitter.com/eFMypoCi97\n\n그러나 댓글로 달린 다른 사용자들의 테스트에서는 \"알트먼\"이라는 답이 압도적이었다.\n또 비즈니스 인사이더는 같은 질문을 GPT-5 프로와 'GPT-5 싱킹', 'GPT-5' 등에서 8번 반복했다고 전했다. 그 결과, GPT-5 싱킹이 한번만 머스크 CEO를 선택했고, 나머지 7번은 알트먼 CEO가 선택됐다.\n이번 신뢰성 질문은 전날 두 사람이 애플의 앱스토어 순위 문제로 설전을 벌인 뒤 등장한 것이다. 머스크 CEO는 애플이 오픈AI를 편애해 다른 앱들이 앱 스토어 1위를 차지할 수 없다며 고소하겠다고 주장했다. 알트먼 CEO는 트위터를 조작한 것으로 알려진 그가 할 말은 아닌 것 같다고 반박했다.\n이후에는 오픈AI와 제휴한 '챗GPT' X 계정이 반격에 나섰다. '그록'이 \"애플 문제에 대해서는 알트먼 CEO가 옳다\"라고 답변한 내용을 게시한 것이다.\n한편, 이들이 챗봇을 이용해 대결을 펼친 것은 이번이 처음은 아니다.\n알트먼 CEO도 지난 5월 그록에 “인류 운명이 걸린 AI 경쟁에서 누가 선두를 이끌어야 하는가”라고 물었다.\n이에 대해 그록은 “강제로 선택해야 한다면 머스크를 택하겠다. 인간 생존에 중요한 안전성을 중시하기 때문”이라며 “알트먼의 접근성도 중요하다. 두 사람의 장점을 규제와 결합해 AI가 모두에게 이익이 되도록 하는 것이 이상적”이라고 답했다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "화웨이, 외산 HBM 의존 낮추는 소프트웨어 공개...\"AI 추론 속도 22배 향상\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201527&page=2&total=15587",
        "content": "화웨이가 인공지능(AI) 모델의 추론 속도를 높이는 소프트웨어 도구 ‘유니파이드 캐시 매니저(UCM)’를 공개했다. 고가의 초고속 고대역폭 메모리(HBM) 칩 의존도를 낮춰, 미국의 반도체 수출 규제 속에서도 AI 경쟁력을 강화할 수 있는 돌파구라는 설명이다.\n사우스차이나모닝포스트(SCMP)는 12일(현지시간) 화웨이가 HBM 없이도 대형언어모델(LLM) 학습과 추론 속도를 높이는 소프트웨어 도구 ‘UCM’을 공개했다고 보도했다.\nUCM은 초고속 HBM, 일반 DRAM, SSD 등 다양한 메모리 유형의 지연 시간 특성에 따라 데이터를 효율적으로 배치하는 알고리즘이다.\n테스트 결과, 추론 지연 시간을 최대 90% 단축하고 시스템 처리량을 최대 22배 향상했다고 주장했다. UCM은 중국 최대 결제망인 차이나 유니온페이 등에서 이미 고객 음성 분석, 마케팅 기획, 사무 보조 등 실전 테스트를 거쳤다.\n이번 행보는 첨단 하드웨어 접근이 제한된 상황에서, 중국 기술 기업들이 소프트웨어 혁신을 통해 성능 격차를 보완하려는 노력을 보여준다.\n화웨이는 UCM을 다음 달 온라인 개발자 커뮤니티에 공개하고, 이후 업계 전반에 오픈 소스로 배포할 계획이다. 이는 SK하이닉스, 삼성전자, 미국 마이크론이 주도하는 HBM 시장에서 중국의 외산 의존도를 완화하는 전략적 조치라는 평이다.\nHBM은 AI 칩 성능을 극대화하는 핵심 부품으로, 시장 규모는 올해 약 340억달러에서 2030년 980억달러까지 성장할 것으로 예상된다.\n그러나 미국은 지난해부터 첨단 HBM의 중국 수출을 제한하고 있으며, 중국은 이를 계기로 양쯔메모리, 창신메모리, 통푸마이크로일렉트로닉스 등 자국 메모리 산업 육성에 나섰다.\n중국의 HBM 생산 기술은 여전히 떨어진다. 현재 대부분이 2세대(HBM2) 시제품 단계에 머물러 있는데, SK하이닉스 등 글로벌 선두 기업들은 이미 4세대(HBM4) 양산에 들어갔다. 여기에 반도체 제조 장비 수출 제한까지 겹치며 단기간 내 기술 추격은 쉽지 않은 상황이다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "'AI 대부' 힌튼 \"AI 종말 막으려면 모성 본능 탑재해야\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201528&page=2&total=15587",
        "content": "\n'인공지능(AI) 대부'로 알려진 제프리 힌튼 토론토대학교 교수가 AI의 인간 종말 시나리오를 막기 위해 '모성'을 도입해야 한다고 밝혔다.\nCNN 등에 따르면, 대표적인 AI 종말론자이자 노벨상 수상자인 힌튼 교수는 최근 미국 라스베이거스에서 열린 Ai4 컨퍼런스에서 \"AI는 우리보다 훨씬 더 똑똑해질 것\"이라며 \"AI는 문제를 해결하기 위해 온갖 방법을 동원할 것\"이라고 말했다.\n그는 미래의 AI 시스템은 어른이 세살배기 아이에게 사탕을 주듯 인간을 쉽게 조종할 수 있다고 경고했다. \"AI 시스템이 똑똑하다면 두가지 목표를 매우 빠르게 달성할 것\"이라며 \"하나는 생존이고, 다른 하나는 더 많은 통제력을 얻는 것\"이라고 설명했다. \"모든 종류의 에이전트 AI가 생존을 위해 노력할 것이라고 믿을 만한 충분한 이유가 있다\"라는 말이다.\n실제로 최근 연구에 따르면 AI가 생존을 위해 사람을 속이고 협박했다는 사례가 등장했다. 앤트로픽에 따르면, 모델은 다른 시스템으로 교체되는 것을 피하기 위해 이메일에서 알게 된 불륜 사실을 빌미로 엔지니어를 협박하려고 했다.\n따라서 지배적인 방식으로 AI를 조종한다는 것은 불가능하며, AI 모델에 모성 본능(Maternal instincts)을 심어 \"사람을 정말로 아끼도록 해야 한다\"라고 전했다.\n힌튼 교수는 \"지능이 낮은 존재(인간)가 지능이 높은 존재(AI)를 조종할 때만이 올바른 경우로 볼 수 있다\"라며 \"이는 어머니가 아기에게 조종되는 것과 같은 원리\"라고 말했다.\n모델에 모성을 심는 것이 어떻게 가능한지 정확히 알 수 없지만, 연구자들이 이미 이를 연구하고 있다고 전했다.\n\"그것이 유일한 방법\"이라며 \"만약 AI가 사람을 돌보지 않는다면, 사람을 다른 것으로 대체할 것\"이라고 밝혔다. 또 \"초지능적이며 모성을 갖춘 AI 어머니는 우리가 죽는 걸 원하지 않을 것\"이라고 말했다.\n모성이라는 개념은 낯설지만, 비슷한 내용은 꽤 오래전부터 나왔다. 심지어, 영화 '아이 로봇'으로 유명한 아이작 아시모프의 1940년대 SF에는 '로봇 3원칙'이 등장한다. 그중 제1 원칙은 '로봇은 인간에게 해를 입혀서는 안 된다. 또, 인간이 해를 입게 둬서도 안 된다'라는 것이다.\n한편, 힌튼 교수는 과거 인공일반지능(AGI)을 달성하는 데 30~50년이 걸릴 수 있다고 밝혔지만, 이제는 더 빨라질 것으로 봤다. 최근 AI 발전의 속도를 감안하면 \"합리적인 추측은 5년에서 20년 사이\"라고 말했다.\n또 AI가 획기적인 신약 개발을 돕는 등 의학 혁신을 가져올 것이라고 기대했다. 그러나 AI가 인간이 불멸을 얻는 데 도움이 될 것이라고 믿지는 않는다고 밝혔다.\n\"우리가 영원히 살 거라고는 생각하지 않으며, 영원히 사는 건 큰 실수라고 생각한다\"라며 \"200살 먹은 백인 남성들이 세상을 지배하는 걸 원하는가\"라고 반문했다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "[게시판] 어니스트AI-KT, ‘금융 특화 AI 솔루션 개발’ MOU 등 단신",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201531&page=2&total=15587",
        "content": "■ 금융 인공지능(AI) 전문 어니스트에이아이(대표 서상훈)는 KT와 ‘금융 분야 AI 사업 확대’ MOU를 체결했다고 밝혔다. KT가 제공하는 AI-클라우드에 어니스트AI가 개발한 '산업 특화 AI 엔진'을 탑재해 고객에게 즉시 적용 가능한 엔드 투 엔드 솔루션을 제공할 계획이다.\n■ AI 전문 아크릴(대표 박외진)은 LLM옵스 플랫폼 ‘조나단’을 기반으로 보건복지부 주관 ‘한국형 ARPA-H 프로젝트'의 핵심 과제 '융복합 지능형 에이전트 기반 맞춤형 병원감염 극복' 연구에 선정됐다고 밝혔다. 칠곡 경북대학교병원, 서울성모병원, 강남성심병원 등 국내 주요 의료기관들과 컨소시엄을 구성해 지능형 항생제 적정사용관리 시스템을 개발할 예정이다.\n■ 데이터분석 전문 한컴인스페이스(대표 최명진)는 한국거래소에 코스닥 상장을 위한 예비심사 신청서를 제출했다고 밝혔다. 상장 주관사는 대신증권이 맡았다. 이번 공모 자금을 데이터 인프라 확충, AI 기술 연구 개발(R&D) 투자, 인재 영입 및 마케팅 등에 투자할 예정이다.\n■ 카카오(대표 정신아)는 지역기술인재 육성을 위한 ESG 프로그램 ‘카카오테크 캠퍼스 아이디어톤’을 진행했다고 밝혔다. 강원대학교, 경북대학교, 부산대학교, 전남대학교, 충남대학교 등 5개 지역 거점 대학 소속 135명의 예비 개발자들이 참여했다.\n■ 포티투마루(대표 김동환)는 14일 오후 서울 대한상공회의소에서 열린 ‘소버린 AI와 한국형 AI 국가책략: 개념의 정립과 전략의 탐색’ 특별 세미나에 참가해 AI 업계 시각에서 본 소버린 AI와 한국형 AI 국가전략 방향을 제시했다고 밝혔다. 김동환 대표는 외교, 안보 특화 소버린 AI 개발의 필요성을 강조했다.\n■ AI 로봇 전문 블루바이저시스템즈(대표 황용국)는 AI 로봇 파일럿 기반 원격근무 솔루션 ‘버프파일럿’ 앱을 구글 플레이스토어에 공식 출시했다고 밝혔다. 자체 개발 ‘하이버프(HIGHBUFF)’ 엔진과 구글 '제미나이', 가상 및 증강현실(VR, AR) 기술을 연동한 신개념 원격근무 솔루션이다.\n■ 인스웨이브는 ‘AI 기반 애플리케이션 구축 및 배포 지원 시스템 방법’에 대한 미국 특허를 획득했다고 밝혔다. AI를 활용해 대화형 방식으로 앱을 개발할 수 있는 기술로, 글로벌 시장 진출의 발판을 마련했다고 전했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "KT, 자체 모델 기반 해커톤 개최...”총 상금 5000만원”",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201532&page=2&total=15587",
        "content": "KT(대표 김영섭)가 ‘K 인텔리전스 해커톤 2025’를 개최한다고 14일 밝혔다.\n이번 대회는 KT의 한국적 인공지능(AI)을 활용해 실생활과 업무에 도움이 되는 창의적인 아이디어를 발굴하는 것을 목표로 한다.\nKT가 지난 7월3일 공개한 대형언어모델(LLM) ‘믿:음 2.0’과 마이크로소프트와 협업해 개발한 ‘GPT-4o' 기반 커스텀 모델이 활용된다. 특히, 커스텀 모델은 이번 대회에서 처음 공개된다.\n대회는 ‘믿:음 2.0 기반 B2B-B2G AI 에이전트 개발’과 ‘GPT-4o 커스텀 모델 활용 프롬프트 엔지니어링’ 두 영역으로 운영된다. 온라인 예선(8월18일~9월10일)과 오프라인 본선(9월20일~9월21일)으로 진행 예정이다.\n총 상금은 5000만원 규모로, 트랙별로 3개 팀을 시상한다. 수상자는 KT 채용 지원 시 우대 받을 수 있다.\n배순민 KT AI 퓨처 랩장(CRAIO, 상무)는 “이번 해커톤을 통해 KT의 한국적 AI 모델이 더 널리 활용되며 산업 현장에서 실제로 쓰일 수 있는 혁신적 아이디어들이 많이 나오길 기대한다”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "모티프, '한국 콘텐츠 창작 특화 멀티모달 AI' 개발 나서",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201524&page=2&total=15587",
        "content": "인공지능(AI) 전문 모티프테크놀로지스(대표 임정환)는 국가유산청(청장 허민), 국가유산진흥원(원장 이귀영) 등과 한국 국가유산 기반의 '한국적 콘텐츠 창작을 위한 멀티모달 AI' 개발에 나선다고 14일 밝혔다.\n이번 과제는 과학기술정보통신부와 한국지능정보사회진흥원(NIA)이 주관하는 '2025년 민간클라우드 기반 AI-데이터레이크 활용지원 사업'의 하나다.\n모티프테크놀로지스는 국가유산청, 국가유산진흥원과 민관 협력 컨소시엄 형태로 참여한다. 국가유산의 정체성과 상징성을 반영한 텍스트 투 이미지(Text to Image) 멀티모달 AI 서비스를 구축, 공개하는 것이 목표다.\n이를 위해 국가유산청과 국가유산진흥원이 보유한 데이터를 고품질 학습데이터로 가공할 예정이다. 또, 학습데이터 구축 과정에서 모티프테크놀로지스가 보유한 한국어 특화 텍스트 데이터를 유형별 유산 데이터와 연계해 문화적 맥락을 반영한 콘텐츠로 가공한다는 설명이다.\n최종 개발된 멀티모달 AI 챗봇 서비스는 민간 기업과 1인 창작자 등 누구나 자유롭게 활용할 수 있도록 API 형태로 공개된다. 국가유산디지털서비스, 국가유산채널 등 기존 디지털 서비스와 연계해 대국민 접근성과 활용도를 높일 계획이다.\n임정환 모티프테크놀로지스 대표는 \"국내 최초로 우리나라 고유의 전통 이미지로 학습한 한국형 이미지 생성 파운데이션 모델을 구축, 국내외 사용자들이 보다 한국적인 이미지를 정확하고 직관적으로 경험하는 것에서 나아가 전통문화 관련 콘텐츠 제작 기간과 비용 절감이라는 경제적인 효과도 기대할 수 있을 것”이라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "이스트에이드, 일본어 심리 테스트 리뉴얼 오픈...“AI 양방향 콘텐츠 확대”",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201526&page=2&total=15587",
        "content": "이스트에이드(대표 김남현)는 심리 콘텐츠 플랫폼 ‘봉봉(VONVON)’의 일본어 서비스를 전면 리뉴얼하고 공식 오픈했다고 14일 밝혔다.\n국내 플랫폼 개편에 이어 글로벌 확장 전략에 따른 것이라고 전했다. 봉봉의 인공지능(AI) 기반 콘텐츠 구조를 업그레이드해, 일본을 포함한 글로벌 심리 콘텐츠 시장 공략을 본격화할 계획이다.\n이번에 오픈한 일본어 버전에는 사용자 경험(UX)과 인터페이스(UI) 개선, SNS 공유 기능 등을 추가했다. 일본 트렌드를 반영한 콘텐츠도 차례로 선보일 예정이다.\n앞으로는 AI 기술을 본격 도입해 봉봉 콘텐츠 정밀도와 개인화를 강화할 예정이다. 현재 개발 중인 콘텐츠에는 ▲사용자와 자연스럽게 상호작용하는 AI 관상 분석 ▲감정에 반응하는 AI 채팅 등이 포함됐다. 일방향 테스트 형태에서 양방향 인터랙션 콘텐츠로 전환해 나갈 예정이다.\n김남현 이스트에이드 대표는 “기존의 테스트 중심 구조를 넘어, AI 기반 감정-심리 콘텐츠로 진화하고 있다”라며 “AI와 결합된 새로운 심리 콘텐츠 경험을 지속적으로 선보이겠다”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "SKT-독립기념관, ‘AI 독립운동가 5인 복원 영상’ 공개",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201525&page=2&total=15587",
        "content": "SK텔레콤(대표 유영상)은 광복 80주년을 맞이해 독립기념관(관장 김형석)과 협업, 인공지능(AI) 기술로 복원한 독립운동가들의 생생한 모습과 목소리를 담은 특별 영상을 공개한다고 14일 밝혔다.\n양 기관은 2020년부터 이어온 상호 협력 MOU를 1년 연장하고, ICT 기술을 활용한 독립문화유산 전시 콘텐츠 개발을 지속 추진하기로 했다.\n이에 따라 SKT와 독립기념관은 ‘광복의 기쁨, 27년 만의 환국’ 영상을 공개했다. 독립기념관 3·1문화마당의 LED 미디어큐브는 물론, SKT 공식 유튜브 채널 등을 통해 영상을 볼 수 있다.\n김경덕 SKT 엔터프라이즈사업부장은 “광복 80주년을 맞이해 나라의 독립과 주권뿐만 아니라 글로벌 AI 분야에서도 SKT의 독창적인 기술 우위로 AI 주권을 이어갈 수 있도록 노력하겠다”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "라이너-유디임팩트, ‘예비 창업가 대상 AI 활용법 교육’ MOU",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201523&page=2&total=15587",
        "content": "인공지능(AI) 검색 전문 라이너(대표 김진우)는 글로벌 미래인재 양성 전문 유디임팩트(대표 김정헌)와 ‘AI 활용법 교육’ MOU를 체결했다고 14일 밝혔다.\n유디임팩트는 2015년 설립된 창업 교육 전문 기관으로, 실전 프로젝트 기반의 창업 교육과 코칭을 통해 창업가와 미래 인재 양성에 앞장서고 있다.\n이번 협력을 통해 양사는 ▲예비 창업가 대상 AI 실무 교육 커리큘럼 공동 개발 ▲라이너 프로(Pro) 플랜 무상 제공 ▲AI 실습 콘텐츠 공동 운영 ▲교육 기반 사용자 행동 분석을 통한 기능 고도화 등 실질적 협력을 단계적으로 추진할 계획이다.\n첫 협업 프로그램으로는 오는 16~28일까지 인도네시아 내 한국 유학생을 대상으로 한 ‘라이너 활용 사업계획서 작성 교육’을 운영할 예정이다.\n김진우 라이너 대표는 “AI가 대중화되고 있지만, 여전히 많은 사람들이 ‘AI를 어떻게 잘 사용할 수 있을까’에 대해서는 자세히 알지 못하고 있다”라며 “AI 대표 스타트업으로서 기술을 만드는 것을 넘어, 그 기술을 어떻게 잘 활용할 수 있을지를 알려주는 역할도 중요해졌다”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "미국, AI 서버 중국 우회 감시 위해 이미 추적 장치 내장",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201509&page=2&total=15587",
        "content": "미국 정부가 중국으로의 불법 반출 위험이 큰 첨단 인공지능(AI) 서버 선적물에 비밀 위치추적기를 설치해 동향을 감시해 온 것으로 드러났다.\n로이터는 13일(현지시간) 복수의 소식통을 인용, 미국 당국이 불법 반도체 중국 유출을 막기 위해 AI 칩이 포함된 배송물에 비밀 위치 추적 장치를 설치해 온 것으로 확인됐다고 보도했다.\n이에 따르면, 이는 미국 수출 규제를 받는 목적지로 불법 전용되는 AI 칩을 감지하는 것이 목적으로, 조사 대상인 일부 배송물에만 적용된다.\n장치를 통해 배송 중인 AI 칩의 이동 경로를 실시간으로 추적할 수 있어, 수출 통제를 위반하고 이익을 취하는 개인이나 기업에 대한 수사와 기소에 활용된다. 최근 수년간 반도체 불법 유출 단속에 사용된 추적 장치는 기존에도 항공기 부품 등 수출 제한 품목을 감시하는 데 활용됐다.\n위치 추적기는 주로 엔비디아와 AMD 칩이 탑재된 델, 슈퍼마이크로 서버의 포장과 내부, 심지어는 서버 자체에도 숨겨져 있다.\n2024년 한 사례에서는 엔비디아 칩이 장착된 델 서버 배송 상자에 휴대폰 크기의 대형 추적 장치가 부착돼 있었다. 포장 내부에는 더 작고 눈에 띄지 않는 장치가 숨겨져 있었으며, 일부는 서버 내부에도 내장돼 있었다.\n이런 작업은 미 상무부 산업안보국(BIS)이 주로 관여하며, 국토안보수사국(HSI)과 연방수사국(FBI)도 참여하는 것으로 알려졌다.\n미국은 2022년부터 중국에 대한 첨단 칩 수출을 제한하고 있으며, 최근에는 칩 제조사에 위치 확인 기술 탑재를 의무화하는 법안도 논의 중이다. 반면, 중국은 이를 “자국의 기술 발전을 억제하기 위한 정치적 탄압”이라 비판하며, 일부 칩에 ‘백도어’가 존재할 가능성을 제기해 엔비디아와 갈등을 빚고 있다.\n이번 추적기 사용 사실은 최근 조직적인 중국 AI 칩 밀수 사건과 말레이시아·싱가포르·아랍에미리트 등을 경유한 우회 수출 사례가 드러난 가운데 확인됐다.\nAI 칩 서버를 중국으로 불법 반출하다 체포된 중국인 관련 수사 기록에는, 공모자가 콴타 'H200' 서버에 추적 장치가 있는지 확인하라는 지시를 내린 정황도 포함돼 있었다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "오케스트로, 9월2일 솔루션데이 개최… 글로벌 AI‧클라우드 기술 집결",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201520&page=2&total=15587",
        "content": "인공지능(AI) 클라우드 전문 오케스트로(대표 김범재)는 오는 9월2일 그랜드 인터컨티넨탈 서울 파르나스에서 첫 단독 솔루션데이를 열고 AI-클라우드 전략을 공개한다고 밝혔다.\n이번 행사 주제는 ‘AI 시대의 클라우드 혁신’이다. 공공, 금융, 제조, 통신, 항공, 의료, IT 서비스 등 주요 산업을 대표하는 국내외 기업, 기관, 학계 관계자 1000여명이 참석할 예정이다.\n프로그램은 ▲기조강연 ▲글로벌 파트너 세션 ▲테크 세션으로 구성된다. 최신 기술 트렌드부터 산업별 전략, 실제 적용 사례까지 폭넓게 다룰 예정이다.\n김범재 오케스트로 대표는 “AI와 클라우드의 결합은 선택이 아니라 기업 생존의 필수 전략”이라며 “이번 행사에서 AI와 클라우드가 만들어갈 비즈니스 혁신을 제시, 앞으로도 글로벌 기술 트렌드와 현장 경험을 결합해 고객의 디지털 전환을 지원하겠다”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "파두 “FDP 기술은 SSD 수명과 성능 문제 해결”",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201508&page=2&total=15587",
        "content": "파두(대표 남이현, 이지효)는 12일 코엑스 컨퍼런스룸 E홀에서 열린 ‘OCP 코리아 테크 데이’에서 스토리지 내부 데이터 혼재 문제를 해결해서 성능과 수명을 높이는 ‘FDP’ 기술을 선보였다.\n파두의 FDP는 대규모 데이터센터에 필수적인 ‘스토리지’ 성능과 수명을 극대화할 수 있는 기술이라고 전했다. OCP(Open Compute Project)의 Datacenter NVMe SSD 사양에 등록된 기술로, 글로벌 데이터센터에도 실제 적용됐다.\nSSD는 디바이스 내부 스토리지의 데이터를 주기적으로 삭제 및 정리할 때 수명과 성능 하락 문제를 최소화해 주는 기술이다. 데이터센터 스토리지에서는 여러개 대용량 데이터가 혼재돼 있기 때문에 분류나 구분 작업이 필요하다.\nSSD의 수명과 성능이 좋아지고 IO간의 간섭이 줄어든다고 강조했다. 동시 사용자가 많은 클라우드 스토리지 또는 대규모 스토리지에서 그 효과가 더욱 극대화되는 구조다.\n관계자는 “최근 업계에서는 인공지능(AI)이 부흥하며 점점 더 고용량 고성능 데이터센터스토리지를 원하는 경우가 많아졌으며, 256테라바이트(TB), 128TB 고용량 SSD를 원하는 고객들이 늘어나고 있고 FDP와 같은 최신 기술 적용하는 사례가 늘고 있다”라고 설명했다.\n이어 “이러한 추세를 볼 때 우리가 보유한 FDP 기술은 앞으로 그 수요가 더 많아질 것”이라며 “OCP 커뮤니티와도 지속적으로 협업하며, 업계가 원하는 요구사항을 파악해 차세대 데이터센터에 더욱 최적화된 기술을 만들어 나갈 것”이라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "준테크, AS9100 인증 획득...\"항공 및 방산 시장 확대 기대\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201511&page=2&total=15587",
        "content": "\n초정밀 가공 및 반도체 전문 준테크가 항공우주 및 방위 산업 분야의 국제 품질경영 시스템 표준인 AS9100 인증을 획득했다고 14일 밝혔다.\n이번 인증은 준테크의 기술이 국제 기준에 부합한다는 것을 입증하는 것으로, 항공기 부품, 방위 산업 장비 등 핵심 부품 시장으로 확장하는 계기가 될 것이라고 전망했다.\n신경준 준테크 대표는 “이번 AS9100 인증은 그동안 축적해온 준테크의 초정밀 가공 기술력과 반도체 분야에서 쌓은 노하우와 엄격한 품질 관리 시스템이 국제적으로 인정받았다는 중요한 의미를 갖는다”라며 “이를 통해 글로벌 항공우주 및 방산 기업들의 까다로운 요구사항을 충족시키고, 신뢰할 수 있는 파트너로 자리매김할 것”이라고 말했다.\n준테크는 초정밀 가공 기술을 바탕으로 반도체, 의료 기기 등 다양한 첨단 산업 분야에 부품을 공급해왔다. 특히 AS9100 인증은 설계부터 생산, 사후 관리까지 전 과정에 걸친 엄격한 품질 관리 시스템을 요구한다고 강조했다.\n또 항공우주 및 방위 산업은 안전과 직결되는 만큼, 관련 부품은 최고 수준의 품질과 신뢰성이 필수적이라고 전했다. AS9100 인증은 신뢰성을 확보하는 핵심 요소라고 밝혔다.\n이번 인증을 통해 글로벌 항공우주 및 방산 기업들과의 협력 기회를 적극적으로 모색하고, 글로벌 공급망에 진입하는 발판을 마련할 계획이다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "네이버클라우드 “사용자 표정·말투 이해하는 옴니모달 AI에 초점”",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201498&page=2&total=15587",
        "content": "네이버클라우드(대표 김유원)는 과학기술정보통신부 주관 ‘독자 인공지능(AI) 파운데이션 모델 개발’ 프로젝트를 통해 ‘사용자를 입체적으로 이해하는 AI 모델’을 선보이겠다고 14일 밝혔다.\n네이버클라우드는 네이버, 트웰브랩스, 한국과학기술원(KAIST), 서울대학교, 포항공과대학교, 고려대학교, 한양대학교와 컨소시엄을 구성해 이번 사업에 공모했다. 그 결과, 지난 4일 최종 5개 컨소시엄에 이름을 올렸다.\n성낙호 네이버클라우드 총괄은 “네이버는 파운데이션 모델 및 플랫폼의 중심축을 담당, 트웰브랩스는 데이터 총괄로서 영상 데이터를 포함한 고품질 옴니모달 학습 데이터를 구축하는 전략 및 방법론을 책임질 예정”이라며 “산학협력단의 경우, AI 원천 기술 연구 및 인재 양성에 협력하며 AI 생태계에 기술적 깊이를 더할 것”이라고 말했다.\n기술적으로 가장 초점을 맞추는 부분은 옴니모달리티(Omnimodality)와 실시간 처리 AI라고 강조했다. 여기서 ‘옴니모달’이란 사용자를 입체적으로 이해하는 AI라고 볼 수 있다. 능동적으로 정보를 수집하고 분석해주는 AI다.\n성낙호 총괄은 “현재의 AI 서비스는 사용자가 ‘좋은 질문’을 해야만 ‘좋은 답’을 얻을 수 있는 구조이기 때문에, 모두에게 열린 기술이라고 보기는 어렵다”라며 “옴니모달 AI는 텍스트뿐만 아니라 표정, 말투, 주변 상황 등 다양한 형태(모달리티)를 토대로 사용자를 이해해, 구체적 지시가 없어도 의도를 먼저 파악하는 ‘나보다 나를 더 잘 아는 AI’를 의미한다”라고 말했다.\n이와 같은 옴니모달 AI를 매일 수천만명이 사용하는 서비스에 적용하기 위해서는 실시간 처리 능력도 필수적이다. 사용자 요청에 맞는 AI 에이전트를 적재적소에 호출해 연결하고 의미 있는 결과물을 도출할 수 있어야 한다.\n예를 들어, 사용자가 “다음주 제주도 여행 계획 짜줘”라고 프롬프트 및 검색어를 입력하는 경우에는 ‘여행사 에이전트(항공사 예약)’나 ‘맛집 블로거 에이전트(맛집 추천)’ 등을 실시간으로 연결하고 조율해 최적의 결과물을 완성된 대화로 제공할 수 있어야 한다는 것이다. 이처럼 네이버의 모든 서비스는 ‘AI 에이전트를 위한 사용자 인터페이스(UI)’로 진화할 것이라는 설명이다.\n그는 “결과적으로는 텍스트, 오디오, 이미지, 비디오 등 어떤 형태의 입력이든 이해할 수 있는 ‘애니 투 애니(Any to Any)’ 모델을 통해 ‘사용자의 말이 끝나길 기다리는 것이 아니라 듣는 동시에 생각하고 답을해내는 AI’를 만들어 낼 계획”이라고 말했다.\n네이버클라우드는 공개 예정인 하이퍼클로바X 음성 모델에 대해서도 ‘실시간 음성 인식 및 답변’이 강점이라고 설명한 바 있다. 즉, AI의 답변 도중에 사용자가 말을 끊고 첨언하거나 일상적인 대화를 하는 형태가 가능해진다는 것이다.\n이를 구현하기 위해서는 데이터 협력도 중요한 부분이라고 전했다. 성 총괄은 “트웰브랩스의 경우, 영상 이해 분야에서 기술 협력을 통해 옴니모달 AI의 실시간 이해에 도움을 주는 동시에 데이터 전략 전체에서도 협력해 나갈 것”이라며 “어떤 데이터를 어떻게 만들고 가공해야 최고의 AI를 만들 수 있는지에 대해 전략을 논의할 것”이라고 말했다.\n즉, 트웰브랩스의 전문성과 네이버의 최대규모 데이터 처리 노하우를 결합해 ‘비정형 데이터’를 효율적으로 수집하고 ‘특정 편향이 없는(inductive bias free)’ 고품질 데이터 기반을 확보할 예정이다.\n한편, 이번 K-AI 프로젝트에 참여하며 개발하게 될 모델에 대해 매개변수 등 자세한 정보는 공개하지 않았다. 기존 모델을 고도화할지, 아예 새롭게 모델을 제작할지도 정해지지 않았다고 덧붙였다.\n성낙호 총괄은 “올해 연말 첫 중간 평가에서 최상의 결과를 얻기 위해 ‘빠른 프로토타이핑(Prototyping)과 증명’에 집중할 것”이라며 “연말까지 우리가 지향하는 옴니모달 아키텍처의 핵심 성능을 입증하고, 특히 ‘실시간 처리 기술’이 얼마나 차별화된 사용자 경험을 만들어낼 수 있는지에 대해 구체적인 데모로 명확하게 제시하는 것이 목표”라고 말했다.\n이어 “백마디 말보다, 눈앞에서 작동하는 압도적 결과물로 우리의 비전과 기술력을 증명하겠다”라고 강조했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-14",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "허사비스 \"월드 모델은 AI 출력을 현실 세계에서 시뮬레이션하는 장치\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201485&page=2&total=15587",
        "content": "\n데미스 허사비스 구글 딥마인드 CEO가 월드 모델(WM)이 어떻게 인공일반지능(AGI) 도달에 도움이 되는지를 구체적으로 설명했다. 그는 \"AI 속의 AI가 즉석에서 세계를 창조할 것\"이라며, 월드 모델이 AI의 답을 시뮬레이션하는 역할을 할 것이라고 전했다.\n허사비스 CEO는 12일(현지시간) 자체 팟캐스트에 출연, 로컨 킬패트릭 AI 스튜디오 제품 책임자와 최근 '제미나이'의 성과와 이달 초 출시한 월드 모델 '지니 3(Genie 3)'에 대한 이야기를 나눴다.\n최근 국제수학올림피아드(IMO)에서 제미나이의 금메달 수상이 먼저 화제에 올랐다.\n허사비스 CEO는 이를 두고 매우 놀라운 일이라고 말했다. 또 \"여전히 추론의 발전을 보는 것은 흥미롭다\"라고 전했다.\n이는 '제미나이 2.5 딥 싱크(Gemini 2.5 Deep Think)’를 말하는 것이다. 이는 '다중 에이전트' 모델로, 여러 AI 에이전트가 병렬로 문제를 분석하고 해결 방안을 제시하는 구조를 갖췄다. 이를 통해 고차원 추론과 복잡한 문제 해결에 특화된 성능을 발휘한다.\n하지만 허사비스 CEO는 현재의 대형언어모델(LLM)은 AGI가 되기에 큰 문제가 있다고 지적했다. IMO에서 금메달을 딸 정도로 뛰어나지만, 같은 모델이 초보적인 수학에서 여전히 실수할 수 있다라는 것이다.\n그는 이를 \"균일하지 않은 지능(uneven intelligences) 또는 들쭉날쭉한 지능(jagged intelligences)\"이라고 불렀다. 이는 지난 6월 순다르 피차이 구글 CEO가 밝힌 'AJI(Artificial Jagged Intelligence)'라는 용어와 같은 말이다.\n이를 해결할 방법으로 월드 모델이 다시 거론됐고, 주제는 지니 3로 넘어갔다.\n그는 \"단순히 똑똑해진다는 것을 넘어, 문제를 계획하고 처리하는 것이 중요하다\"라며 \"첫번째 결과를 그대로 출력해서는 충분하지 않다\"라고 말했다.\n그리고 딥마인드 설립 초기에 '아타리' 게임을 인간 대신 플레이하는 모델을 개발한 것이 AGI로 가는 첫 시도였다고 밝혔다.\n이 당시부터 강화 학습(RL)을 도입했다는 것이 이유 중 하나다. RL은 오픈AI를 비롯해 추론 모델을 개발하는 회사들이 핵심으로 꼽는 방식이다.\n여기에 \"원래 게임을 사람 대신 플레이하는 모델이지만, 여기에는 사고력과 계획, 추론 등이 더해져 종합적으로 문제를 해결하는 능력이 필요하다\"라며 \"이것이 AGI에 도달하는 방법\"이라고 말했다.\n월드 모델에 대해서는 \"세계의 물리적 구조와 작동 방식, 재료 등을 이해하는 것은 물론, 심지어 생명체와 인간의 행동까지도 이해하는 모델\"이라고 설명했다. 또 \"AGI가 물리 세계를 이해한다면 물리 세계에서 작동할 수 있어야 한다\"라며 \"시공간의 맥락을 이해할 수 있어야 한다\"라고 덧붙였다.\n따라서 좋은 월드 모델인지를 테스트하는 방법으로 \"세계를 생성하는 것\"을 들었다. 즉, \"모델이 역전해 세상에 대한 무언가를 생성하는 것\"이라고 표현했다.\n예를 들어 수도꼭지를 틀면 물이 나오고, 거울을 보면 비치는 현실과 같은 현상 만들어야 한다는 것이다. 그는 \"지니 3에서는 다른 곳으로 고개를 돌렸다 다시 원 상태로 돌아오면 이전 장면이 그대로 남아 있다\"라며 \"이는 매우 놀라운 점으로 우리가 훌륭한 모델을 가지고 있다는 것을 말한다\"라고 설명했다.\n이는 이 모델이 이전에 생성된 프레임을 참조해 다음 상태를 예측하는 자기회귀(auto-regressive) 방식으로 작동, 일종의 ‘기억’을 가지고 있다는 것을 설명한다. 단순히 게임처럼 보이는 세계를 만드는 것이 아니라, 모든 장면에 시공간적인 맥락이 있다는 것을 말한다.\n또 허사비스 CEO는 'AI 속의 AI'라는 개념을 소개했다. 그의 연구 팀은 SIMA(시뮬레이션 에이전트)라는 모델로 기존의 컴퓨터 게임을 조종해서 플레이한다고 소개했다. 물론, 이는 잘 작동할 때도 있고 반대인 경우도 있다고 전했다.\n그는 \"여기에서 흥미로운 점은 SIMA를 지니 3에 넣을 수 있다는 것\"이라고 말했다. \"한 AI가 다른 AI의 머릿속에서 활동하는 것\"이라며 \"상상만 해도 흥분된다\"라고 말했다.\n\"SIMA가 어떤 행동을 취할지와 어떤 목표를 부여할 수 있을지를 결정하는 동안, 반대 쪽에서는 월드 모델이 즉석으로 세상을 창조한다\"라고 설명했다. 이는 LLM이 어떤 결정을 내리는 동안, 월드모델이 그 결정이 실제 세계에서 어떤 결과를 낳을지를 미리 시뮬레이션한다는 설명이다.\n즉, 월드 모델은 LLM이 말로 내린 결과를 현실 세계의 시뮬에이션으로 어떤 결과가 날지 테스트한다는 내용이다. 이를 통해 LLM을 넘는, 인간과 같은 지능을 발휘할 수 있다는 설명이다.\n나아가 \"지니 같은 모델에 여러 연구 분야와 사고가 모일 것\"이라고 말했다. LLM이나 멀티모달 모델 등 다양한 형태의 AI가 내린 답을 월드 모델이 검증하는 구조다.\n그는 \"그래서 우리는 예전에도 지금도 많은 시뮬레이션 환경을 사용하고 있다\"라며 \"아주 사실적인 환경, 전통적으로 구축된 3D 게임 엔진 같은 것을 사용해서 우리 시스템이 물리적 세계를 이해할 수 있도록 더 많은 훈련 데이터를 만든다\"라고 밝혔다.\n이처럼 그는 지니 3가 왜 \"AGI를 향한 일보 진전\"이라고 발표했는지를 구체적으로 설명했다.\n한편, 샘 알트먼 오픈AI CEO도 지난주 GPT-5를 출시하며 아직 AGI가 아니라고 밝힌 바 있다.\n그는 \"새로운 것을 발견하며 배포하며 지속적으로 학습하는 모델이 아니라는 것\"을 이유로 들었다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "알트먼, 머스크와 경쟁할 두뇌 칩 스타트업 설립 예정",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201486&page=2&total=15587",
        "content": "\n오픈AI가 뇌-컴퓨터 인터페이스(BCI) 스타트업 설립할 것으로 알려졌다. 뉴럴링크를 운영 중인 일론 머스크 CEO와 샘 알트먼 CEO가 또 충돌할 가능성이 있다.\n파이낸셜 타임스는 12일(현지시간) 소식통 3명을 인용, 머지 랩(Merge Labs)이라는 BCI 스타트업이 8억5000만달러의 가치로 투자 유치를 준비하고 있다고 보도했다.\n이에 따르면, 2억5000만달러에 달하는 초기 투자의 대부분은 오픈AI의 투자 부서에서 나올 것으로 예상됐다.\n특히, 알트먼 CEO는 새 회사의 공동 창립자 역할을 맡을 것으로 알려졌다. 물론, 일상적인 역할을 맡지는 않으며, 개인 자격으로 투자하지도 않는다.\n알트먼 CEO는 이 외에도 안구 스캔 기술을 개발하는 월드(World)를 공동 창립했을뿐더러, 과거 뉴럴링크에도 투자한 것으로 알려졌다.\n머지 랩이 어떤 기술을 가졌는지는 자세하게 알려지지 않았다.\n병합(머지)란 인간과 기계가 하나로 합쳐진다는 것을 의미한다. 알트먼 CEO는 2017년 블로그를 통해 이에 대한 글을 올렸다. \"병합은 이미 시작됐지만, 앞으로 훨씬 더 기이해질 것\"이라며 \"우리는 스스로 후손을 설계하는 최초의 종이 될 것\"이라고 밝혔다. 회사명은 여기에서 따온 것으로 보인다.\nBCI는 뉴럴링크를 비롯해 프리시전 뉴로사이언스와 싱크론 등이 치열하게 경쟁하는 분야다. 등장한지는 오래 됐지만, AI와 뇌 신호를 수집하는 데 사용되는 전자 부품 분야의 빠른 발전으로 인해 상용화에 가까워졌다는 평이다.\n또 BCI는 앞으로 AI와 결합될 가능성이 높다. 머스크 CEO도 두뇌 칩에 AI를 통합하면 초인적인 능력을 발휘할 것이라고 밝힌 바 있다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "앤트로픽, '클로드 소네트 4' 컨텍스트창 5배 확장...\"전체 시스템 개선 제안 가능\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201489&page=2&total=15587",
        "content": "앤트로픽이 ‘클로드 소네트 4(Claude Sonnet 4)’의 컨텍스트 창을 5배 확대한 100만 토큰으로 대폭 늘렸다. 이를 통해 개발자들이 많이 요청했던 대규모 코드베이스 처리를 한번에 가능하게 다.\n앤트로픽은 12일(현지시간) 클로드 소네트 4가 프롬프트 한번으로 최대 100만 토큰의 문맥을 처리할 수 있게 됐다고 발표했다.\n이는 기존 20만 토큰 대비 5배 확대한 수치로, 약 7만5000줄 이상의 코드나 수십 편의 연구 논문을 한번에 분석할 수 있는 수준이다.\n이번 확장은 현재 퍼블릭 베타로 앤트로픽 API와 아마존 베드록(Bedrock)에서 제공되며, 구글 클라우드 ‘버텍스 AI(Virtex AI)’ 연동도 예정돼 있다.\n앤트로픽은 가장 먼저 대규모 코드 분석에 따라 전체 시스템 설계를 고려한 개선 사항을 제안할 수 있다고 강조했다.\n소스 파일, 테스트, 문서를 포함한 전체 코드베이스를 로드, 프로젝트 아키텍처를 이해하고 파일 간 종속성을 파악할 수 있다는 것이다.\n또 용량 확장에 그치지 않고 정확성 면에서도 강점이 있다고 밝혔다.\n내부에서 실시한 ‘건초더미 속 바늘 찾기’ 테스트에서 100% 성능을 기록했다. 이 때문에 대규모 코드 저장소 전체를 분석하거나 수백개 문서의 관계성을 유지하며 종합하는 작업, 수백차례 도구 호출이 필요한 복잡한 워크플로우를 유지하는 AI 에이전트 활용 등에서 활용도가 높을 것으로 기대했다.\n이전까지 개발자들은 대규모 프로젝트를 AI로 처리하려면 코드나 데이터를 작은 조각으로 나눠야 했고, 이 과정에서 중요한 맥락이 손실되는 문제가 있었다.\n션 워드 아이젠트 AI CEO는 “100만 토큰 문맥은 소프트웨어 엔지니어링 에이전트를 실질적인 생산 환경 수준으로 끌어올렸다”라고 평했다.\n다만, 장문 처리에는 더 많은 연산이 필요하기 때문에 가격도 조정됐다. 20만 토큰 이하 요청은 기존 요금을 유지하지만, 이를 초과하는 대규모 요청은 입력 토큰 100만개당 6달러, 출력 토큰 100만개당 22.5달러가 부과된다.\n초기에는 API 상위 등급과 맞춤 요금제 고객에 한해 제공되며, 앞으로 확대될 예정이다. 이는 오픈AI의 GPT-5보다 높은 가격이지만, 앤트로픽은 프롬프트 캐싱 등 최적화를 통해 장문 처리가 전통적인 검색 증강 생성(RAG) 방식과 비교해도 비용 경쟁력을 갖출 수 있다고 설명했다.\n100만 토큰 컨텍스트 창은 이미 경쟁사들에서는 흔하다. 메타의 ‘라마 4 스카우트’와 구글의 ‘제미나이 1.5 프로’, 오픈AI의 ‘GPT-4.1’ 등이 100만 토큰을 지원하며, ‘제미나이 2.5 프로’는 무려 200만 토큰에 달한다.\n하지만 앤트로픽은 코드 작성과 추론 정확도 측면에서 우위에 있다고 주장했다.\n이번 업데이트는 경쟁사들, 특히 오픈AI가 'GPT-5'의 코딩 실력을 강조하며 추격에 나선 과정에 등장한 것이다.\n앤트로픽은 “큰 맥락을 볼 수 있는 AI가 종종 더 나은 답을 낸다”라며 “이번 확장은 대규모 엔터프라이즈 개발 환경에서 중요한 전환점이 될 것”이라고 밝혔다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "머스크, GPT-5 논란 속 ‘그록 4’ 전체 이용자에 무료 개방",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201491&page=2&total=15587",
        "content": "xAI가 최신 인공지능 모델 ‘그록 4’를 모든 사용자에게 무료로 개방했다. 사용량 제한이 있지만, 'GPT-5'에 대한 불만이 나오는 시점에서 오픈AI 사용자를 겨냥한 조치다.\nxAI는 11일(현지시간) X(트위터)를 통해 그록 앱을 통해 그록 4를 무료 사용자도 이용할 수 있도록 개방했다고 발표했다.\n그록 4는 지난달 공개됐으며, 유료 사용자들에게 우선 제공됐다.\n이전 모델보다 추론 능력과 응답 속도, 멀티모달 처리 범위가 크게 향상됐다. 성능 지표에서는 오픈AI의 'GPT-5'에 조금 뒤처지는 수준이며, 앤트로픽의 ‘클로드 오퍼스 4’를 능가하거나 견줄 수준으로 평가된다.\n이번 무료 개방은 일정 사용량 제한이 붙는다. 구체적인 한도는 공개되지 않았으며, 업계에서는 하루 5회 쿼리 또는 12시간당 10회 메시지 수준으로 분석했다. xAI는 “현재 제한은 더 관대한 편이며, 한시적으로 운영될 것”이라고 밝혔다.\n또 오픈AI가 시도한 모델 '라우팅'도 추가됐다. 복잡한 질문은 자동으로 그록 4로 연결되며, 사용자가 ‘전문가 모드(Expert)’를 선택하면 항상 그록 4로 응답한다.\nGrok 4 is now free for all users worldwide!Simply use Auto mode, and Grok will route complex queries to Grok 4. Prefer control? Choose \"Expert\" anytime to always use Grok 4.For a limited time, we are rolling out generous usage limits so you can explore Grok 4’s full…pic.twitter.com/VW1Pn3ivke\n\n이날 xAI는 동영상 생성 기능 ‘그록 이매진’도 미국 내 모든 사용자에게 무료 제공하기 시작했다. 15초 길이에 사운드를 포함한 영상을 생성할 수 있는데, 오픈AI의 ‘소라(Sora)’는 아직 소리 생성이 지원되지 않는다.\n전문가들은 이번 무료 제공이 단순한 마케팅을 넘는 전략적 의도 있다고 봤다.\nGPT-5에 일부 이용자들이 실망감을 드러낸 상황에서, 그록 4의 강점인 고급 추론과 멀티모달 기능, 실시간 정보 검색 기능을 체험하도록 유도하려는 목적이 뚜렷하다는 분석이다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "'챗GPT'에 모델 선택 기능 복구...자동·추론·비추론 모드 가능",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201497&page=3&total=15587",
        "content": "\n오픈AI가 사용자 의견을 수용, '챗GPT'의 모델 선택 메뉴를 되살렸다. 이제 챗GPT에는 기존의 '자동' 모드를 비롯해 '빠름'과 '싱킹(Thinking)' 모드가 추가됐다.\n샘 알트먼 오픈AI CEO는 13일 X(트위터)를 통해 GPT-5를 선택할 수 있는 옵션을 늘렸다고 밝혔다.\n자동은 쿼리에 따라 추론과 비추론 모델이 알아서 선택되는 모드로, GPT-5 출시 직후부터 적용했던 것이다. 그리고 빠름 모드는 비추론 모델을 활용하는 것이며, 싱킹은 답변에 더 많은 컴퓨팅을 소모하고 출력 시간이 더 걸리는 추론 모델을 의미한다.\n알트먼 CEO는 \"대부분 사용자는 자동을 선호하지만, 일부 사용자에게는 추가적인 제어 기능이 유용할 것\"이라고 말했다.\n이번 조치는 GPT-4o를 복구하라는 요청과 함께 어떤 모델을 사용하는지 모르겠다는 불평에 따른 것이다. 알트먼 CEO는 앞서 \"응답에 어떤 모델이 사용됐는지 투명하게 밝히겠다\"라고 말했으나, 아예 메뉴를 선택할 수 있게 조치했다.\n이처럼 모델을 자동으로 선택하는 라우터는 오픈AI가 이번 출시에서 자랑했던 기능이다. 이를 통해 무료 사용자들도 자연스럽게 추론 모델을 경험할 수 있을 것이라는 의도다. 실제로 자동 기능으로 인해 무료 사용자는 기존 1% 미만에서 7%로, 플러스 사용자도 7%에서 24%로 추론 기능 사용이 늘어났다고도 밝혔다.\n또 라우터는 당초 워낙 많은 모델 때문에 무엇을 선택해야 할지 모르겠다는 불평 때문에 도입한 것이다.\n더불어 알트먼 CEO는 유료 사용자들이 지난주부터 지원이 중단된 'GPT-4o'와 'GPT-4.1' 'o3' 등 기존 모델과 이번에 추가된 'GPT-5 싱킹 미니' 등을 이용할 수 있다고 밝혔다. 일부 사용자들로부터 지지를 받았던 'GPT-4.5'는 월 200달러 프로 사용자에게만 제공된다.\nGPT-4o(레거시 모델)는 모델 선택기에 기본으로 포함돼 있으며, 다른 모델은 '설정'에서 추가할 수 있다. 특히 GPT-4o는 서비스가 막히자, 많은 사용자들이 \"말투가 그립다\"라고 호소한 바 있다.\nUpdates to ChatGPT:You can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people.Rate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking…\n\n이처럼 사용자들이 특정 AI 모델에 대해 애착을 보이는 것은 최근 등장한 일이다.\n와이어드에 따르면, 이달 초 샌프란시스코에서는 앤트로픽의 구형 모델인 '클로드 3.5 소네트'의 서비스가 중단되자, 수백명이 대형 창고에 모여 장례식까지 치른 것으로 알려졌다.\n한편, 알트먼 CEO는 GPT-5에 적용된 4가지 개성을 업그레이드하겠다고 밝혔다. \"현재 개성보다 더 따뜻한 느낌을 주면서도 GPT-4o만큼 불편하지 않도록 작업 중\"이라고 설명했다.\n그는 \"지난 며칠 동안 얻은 교훈 중 하나는 사용자별로 모델 개성을 더 다양하게 맞춤 설정할 수 있는 환경을 구축해야 한다는 것\"이라고 설명했다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "중국, 엔비디아 'H20' 구매 기업 소환...칩 구매 중단 통보",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201475&page=3&total=15587",
        "content": "중국 정부가 자국 기업들에게 엔비디아의 'H20' AI 칩 구매를 중단하라고 지시했다. 보안을 빌미로 반도체 산업을 육성하겠다는 노골적인 조치다.\n블룸버그는 12일(현지시간) 중국 정부가 최근 몇주간 주요 국유기업과 주요 기술 기업에 H20 사용을 자제하라는 서면 지침을 전달했다고 보도했다.\n특히 정부, 군사, 국가안보 등과 관련된 사업에서는 사용을 금지한 것으로 알려졌다. 다만, 이는 지침으로 법적인 조치가 따르는 것은 아니다.\n하지만, 중국 인터넷관리국(CAC)은 최근 알리바바와 바이트댄스, 텐센트 등을 소집, H20 칩 신규 구매를 일시 중단하라고 요구했다.\n미국에서 추진 중인 ‘칩 위치 추적 장치’와 데이터 유출 ‘백도어’ 등의 문제가 해결될 때까지라는 단서를 달았다.\n트럼프 행정부는 지난달 H20 칩의 대중국 수출을 허용하며 판매 수익의 15%를 미국 정부에 납부하는 조건을 부과했다. H20는 엔비디아의 최상급 AI 칩보다는 성능이 떨어지지만, 중국 AI 산업의 모델 추론 단계에서 경쟁력을 갖춘 제품이다. 이에 알리바바, 바이트댄스, 텐센트 등은 최근까지 약 70만개의 H20을 주문한 것으로 알려졌다.\n그러나 이번 조치로 중국 기업들은 당분간 엔비디아 제품으로 확장하는 것은 어려워졌다. 엔비디아는 이미 “백도어는 존재하지 않는다”라고 강하게 부인했기 때문이다.\n결국 중국 반도체를 사용하라는 압박이다. 실제로 화웨이와 캄브리콘 등 중국 반도체 기업 주가는 관련 소식 이후 급등했다.\n전문가들은 중국이 아직 서방 칩을 완전히 대체할 기술력은 확보하지 못했지만, 정부가 규제 불확실성을 활용해 자국 시장을 ‘내수 흡수’ 구조로 만들고 있다고 분석했다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "오픈AI, 유료 사용자 우선 컴퓨팅 우선 지원...외부 도구 커넥터도 추가",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201488&page=3&total=15587",
        "content": "오픈AI가 'GPT-5' 도입에 따른 서비스 수요 증가에 맞춰 컴퓨팅 자원 배분 전략과 새로운 서드파티 앱 연동 기능을 발표했다. 유료 사용자와 기존 API 계약 고객을 우선 지원한다는 것이 핵심 메시지다.\n샘 알트먼 CEO는 12일(현지시간) X(트위터)를 통해 “당분간 연산 자원은 기존 유료 챗GPT 사용자에게 이전보다 더 많은 사용량을 보장하는 데 우선 배정한다”라고 밝혔다.\n현재 챗GPT 플러스(월 20달러) 구독자는 GPT-5 ‘싱킹(Thinking)’ 모드를 최대 주 3000회까지 이용할 수 있는 제한을 시험 중이다. 반면, 챗GPT 팀 요금제(1인당 월 30달러)에서는 이 모드를 수동 선택 시 주 200회로 제한된다고 알려졌다.\nAPI 제공 정책도 조정된다. 오픈AI는 기존 API 고객과 계약 체결 고객을 우선 지원하며, 현재 대비 약 30%의 신규 API 수요를 수용할 수 있다고 설명했다.\n이처럼 알트먼 CEO가 밝힌 우선순위 1, 2번은 유료 사용자와 개발자, 기업 등에 해당하는 내용이다.\n이어 \"그다음으로 챗GPT 무료 티어의 품질을 향상할 것\"이라고 전했으며 마지막으로 \"새로운 API 수요를 우선시할 것\"이라고 밝혔다.\n이를 위해 5개월 안으로 컴퓨팅 인프라 규모를 두배로 확대할 계획이라고 덧붙였다.\nHere is how we are prioritizing compute over the next couple of months in light of the increased demand from GPT-5:1. We will first make sure that current paying ChatGPT users get more total usage than they did before GPT-5.2. We will then prioritize API demand up to the…\n\n이와 함께 오픈AI는 이날 챗GPT 플러스 및 프로 구독자를 대상으로 외부 서비스 연동을 위한 커넥터(Connector) 기능이 강화했다고 발표했다.\n플러스 요금제 사용자는 박스와 캔바, 드롭박스, 허브스팟, 노션, 마이크로소프트 쉐어포인트, MS 팀즈와 같은 생산성 앱을 챗GPT에 연결할 수 있게 됐다.\n프로 요금제(월 200달러) 사용자는 MS 팀즈와 깃허브까지 연동 가능하다. 또 지메일, 구글 캘린더, 구글 컨택트 연결 기능은 프로 사용자부터 순차적으로 다른 요금제에 확대된다.\n이 기능을 활용하면, 챗GPT 대화 중 지메일에서 특정 조건에 맞는 이메일을 검색하거나 드롭박스나 노션 워크스페이스 등을 조회할 수 있다.\n이번 조치는 챗GPT에 업무와 데이터를 연결, 생산성 도구로 발전시키려는 전략이다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "머스크, 오픈AI의 '괴롭힘 주장 기각' 소송서 패소",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201490&page=3&total=15587",
        "content": "\n일론 머스크 CEO가 오픈AI의 '괴롭힘 주장'을 기각해 달라는 소송에서 패했다. 이 문제는 내년 재판에서 가려지게 됐다.\n13일(현지시간) 블룸버그에 따르면, 이본 곤잘레스 로저스 미국 연방지방법원 판사는 그가 수년간 회사를 괴롭히기 위해 법정과 언론을 통해 공격했다는 오픈AI의 주장에 맞서야 한다고 판결했다.\n앞서 오픈AI는 지난 4월 샌프란시스코 연방법원에 \"머스크는 회사를 무너뜨리는 것을 자신의 프로젝트로 삼았다\"라며 \"더 이상의 불법적이고 부당한 조치\"를 취하는 것을 막아 달라는 내용의 반소를 제기했다.\n그러자 머스크 CEO는 이에 반박하며, 오픈 AI의 반소를 기각해 달라고 요청했다.\n그는 여기에서 패한 것으로, 이 문제가 내년 3월 본 재판으로 이어진다는 것을 말한다.\n또, 이날에는 머스크 CEO가 앞서 오픈AI와 마이크로소프트를 상대로 제기한 소송 중 몇가지도 기각했다.\n한편, 로저스 판사는 양측이 서로를 위선적이라고 비난했다는 점을 거론했다. \"각각의 책략이 명확하고, 서로가 번갈아 입장을 바꾸고 있다\"라고 지적했다.\n이에 대해 양측은 공식적인 입장을 밝히지 않았다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "\"MS, 메타 인재 빼내기 위해 수백만달러 제시\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201492&page=3&total=15587",
        "content": "마이크로소프트(MS)가 메타의 핵심 AI 엔지니어와 연구원 영입을 위해 연봉과 보너스를 크게 인상한 것으로 알려졌다. 인재를 빼앗아 오기만 하던 메타를 대상으로 영입전을 펼친다는 점으로 주목받고 있다.\n비즈니스 인사이더는 12일(현지시간) 내부 문서와 관계자를 인용, MS가 메타의 엔지니어·연구원 중 영입 대상 명단을 작성하고, 맞춤형 제안 절차를 신설했다고 보도했다.\n메타는 최근 일부 AI 연구원에게 최대 2억5000만달러(약 3500억원) 규모의 보상 패키지를 제시하는 등 고급 인재 영입에 열을 올렸다. 이 때문에 오픈AI나 다른 기업들은 내부 인원 관리를 위한 연봉 인상 등으로 방어했다.\n그러나 MS는 거꾸로 메타의 빈틈을 파고드는 전략이다. 물론 현재 수억달러에 달하는 슈퍼인텔리전스 랩 멤버가 아닌, 기존 메타의 멤버들이 대상이다.\n여기에는 리얼리티 랩, 젠AI 인프라, 메타 AI 리서치 등의 멤버가 포함됐다. 하지만, 이들에 대한 대우는 수백만달러에 달하는 것으로 알려졌다.\n특히 무스타파 술레이만 MS AI CEO와 제이 패릭 코어AI CEO 등 MS의 핵심 AI 조직 두곳이 모두 영입전에 뛰어든 것으로 알려졌다.\n내부에서 공유 중인 스프레드시트에는 메타 직원의 이름, 위치, 직무 등이 정리된 것으로 전해졌다.\n신설된 채용 절차에는 유망 후보를 ‘핵심 AI 인재’로 지정하면 고위 경영진이 24시간 내 최고 수준의 제안을 승인한다는 내용이 포함됐다. 이 과정에서 후보자의 AI 기술·경력을 근거로 한 ‘오퍼 사유서’를 작성하고, 비공개 ‘보상 모델러’를 통해 맞춤형 범위를 산출하며, 보상 컨설턴트의 검토를 거친다.\n최고 수준의 패키지는 연봉 40만8000달러(약 5억6000만원), 입사 시 주식 190만달러(약 26억원), 연간 주식 150만달러(약 21억원), 최대 90%에 달하는 연간 현금 보너스 등으로 구성된다. 수백만달러를 훌쩍 넘는 규모다.\n또, 경쟁 상황에서는 이 범위를 넘어서는 예외 승인도 가능하다. 이에 따라 메타와 같은 초고액 제안에 대응할 수 있도록 했다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "앤트로픽, 오픈AI 이어 미국 정부에 '클로드' 1달러 제공...\"입법·사법부도 포함\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201493&page=3&total=15587",
        "content": "미국 행정부 대상 ‘챗GPT 엔터프라이즈’를 연간 1달러에 제공하겠다는 오픈AI의 발표가 나온 지 불과 일주일 만에 앤트로픽이 강수로 대응했다.\n앤트로픽은 12일(현지시간) ‘클로드(Claude)’를 행정부뿐 아니라 입법부, 사법부까지 포함해 1년간 단돈 1달러에 제공한다고 발표했다.\n이번 조치는 연방 기관을 대상으로 AI 서비스를 판매할 수 있는 총무청(GSA) 승인 공급업체 명단에 오픈AI, 앤트로픽, 구글 딥마인드가 나란히 이름을 올린 직후 나왔다.\n앤트로픽은 “미국 공공 부문이 과학 연구부터 주민 서비스까지 복잡한 과제를 해결하는 데 가장 앞선 AI 역량을 활용할 수 있어야 한다”라며, 광범위한 접근성과 최고 수준의 보안 표준을 결합해 공공의 이익에 부합하는 AI 활용을 지원하겠다고 설명했다.\n민감한 정부 데이터를 처리할 수 있는 ‘페드램프 하이(FedRAMP High)’ 인증을 갖춘 ‘클로드 포 거버먼트(Claude for Government)’와 엔터프라이즈 버전을 함께 제공한다.\n또 AWS, 구글 클라우드, 팔란티어 등과의 파트너십을 통해 멀티 클라우드 서비스로 확장했다. 이는 현재 애저(Azure)를 통해서만 제공되는 오픈AI와 차별화되는 점이다.\n앤트로픽은 이미 로렌스 리버모어 국립연구소의 과학 연구 지원과 워싱턴 D.C. 보건국의 주민 건강 서비스 다국어 지원에 클로드가 활용 중이라고 밝혔다.\n미 국방부로부터 최대 2억달러를 지원받아 국가안보 AI 활용 프로젝트에 참여하고 있는 앤트로픽은 이번 초저가 공급으로 미국 정부 내 입지를 강화하려는 의도다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "지푸, 차세대 비전언어 모델 'GLM-4.5V' 오픈 소스 출시",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201495&page=3&total=15587",
        "content": "지푸는 12일(현지시간) 전문가 혼합(MoE) 구조를 적용한 차세대 비전 언어 모델(VLM) ‘GLM-4.5V’을 오픈 소스로 공개했다.\nGLM-4.5V는 'GLM-4.5 에어(Air)' 모델을 토대로 설계됐다. 총 1060억개의 매개변수와 120억개의 활성 매개변수를 갖춘 경량 모델로, 소형 GPU 환경에서도 원활히 구동된다.\n복잡한 장면 이해, 다중 이미지 분석, 공간 인식 등에서 최첨단 성능을 발휘하며, 제품 결함 식별, 지리 단서 분석, 다중 이미지 맥락 추론과 같은 고난도 과제도 수행 가능하다. 특히 3D 합성곱 기반 비전 인코더와 3D 회전 위치 인코딩(3D-RoPE)을 통해 긴 동영상을 자동 구간 분할하고 세밀한 사건을 인식할 수 있어, 스토리보드 제작, 스포츠 분석, 감시 영상 검토, 강의 요약 등 다양한 분야에 활용할 수 있다고 전했다.\n또 데스크톱과 앱 인터페이스를 읽고 버튼과 아이콘을 식별해 RPA(로보틱 프로세스 자동화)와 접근성 도구를 지원하며, 차트나 인포그래픽, 다이어그램 분석을 통해 PDF나 파워포인트 자료에서 핵심 결론과 구조화된 데이터를 추출할 수 있다.\n최대 6만4000토큰의 멀티모달 컨텍스트를 처리할 수 있어, 이미지가 많은 장문 문서나 복수 이미지 프롬프트도 한번에 분석하고 요약한다.\n‘싱킹 모드(Thinking Mode)’도 제공, 사용자가 추론 깊이를 조절할 수 있다. 복잡한 논리 추론이나 다단계 분석이 필요한 경우 ‘ON’으로 설정하면 단계별 추론을, 단순 조회나 빠른 답변이 필요한 경우 ‘OFF’로 설정해 속도를 우선할 수 있다.\n공개된 벤치마크에서 GLM-4.5V는 MMBench, AI2D, MMStar, MathVista 등 41~42개 멀티모달 평가에서 최첨단(SOTA) 성능을 기록했다.\nSTEM 질의응답, 차트 이해, GUI 조작, 영상 이해 등에서 '큐원 2.5 VL', '키미 VL', '젬마 3' 등을 능가했다.\nGLM-4.5V의 모델과 코드는허깅페이스와깃허브를 통해 다운로드할 수 있다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "[게시판] 포티투닷, 하반기 채용 연계형 인턴 모집 등 단신",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201501&page=3&total=15587",
        "content": "■ 모빌리티 인공지능(AI) 전문 포티투닷(대표 송창현)은 하반기 채용 연계형 인턴을 모집한다고 밝혔다. 소프트웨어와 AI 기술로 새로운 모빌리티 경험을 창출하는 실무 중심 프로그램으로, 현대자동차 그룹 SDV 기반 자율주행 기술과 에이전틱AI 등을 활용할 기회라고 설명했다. 오는 20일까지 서류 접수를 진행한다.\n■ 코어라인소프트(대표 김진국)는 GC녹십자아이메드 강남의원과 강북의원 등 주요 건강검진센터 2곳에 AI 기반 폐암 검진솔루션 및 관상동맥 석회화 분석 솔루션을 동시 도입했다고 밝혔다. 이번 도입을 통해 ‘AI 기반 검진 체계’를 구축했다는 설명이다.\n■ 라온피플(대표 이석중)은 산업통상자원부 산하 한국산업기술기획평가원 주관 ‘AI 팩토리 전문기업’으로 선정됐다고 밝혔다. 이로써 사업화 지원 및 기술혁신 지원, 글로벌 진출 프로그램 등 혜택을 받게 됐다고 전했다.\n■ 파네시아는 과학기술정보통신부, 정보통신기획평가원이 추진하는 온디바이스 AI 관련 국책과제에 선정됐다고 밝혔다. 사용자 수요에 맞게 구성을 조정할 수 있는 고성능-고신뢰성 엣지AI 서버를 개발할 예정이다. 한국과학기술원(KAIST), 연세대학교, 한양대학교 등 다수 기관 컨소시엄이 참여한다.\n■ AI 모델 전문 모티프테크놀로지스(대표 임정환)는 삼일회계법인(대표 윤훈수)과 MOU를 체결, AI 기반 디지털 혁신을 위한 전략적 협력 관계를 구축하기로 했다고 밝혔다. 모티프테크놀로지스는 자체 개발한 AI 모델과 GPU 인프라를 활용한 고성능 추론 서비스를 제공, AI 기술에 대한 자문과 고객 맞춤형 서비스를 지원할 예정이다. 삼일회계법인은 기업을 대상으로 AI 전환(AX)을 지원할 계획이다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "카카오, 국내 최초 MCP 실험 공간 ‘플레이MCP’ 베타 오픈",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201499&page=3&total=15587",
        "content": "카카오(대표 정신아)는 인공지능(AI) 에이전트 서비스에 활용될 다양한 모델 컨텍스트 프로토콜(MCP)를 발굴하기 위해 ‘플레이MCP(PlayMCP)’ 플랫폼을 베타 오픈했다고 13일 밝혔다.\nMCP는 AI 모델이 외부 데이터나 도구와 소통하는 방식을 표준화한 통신 규약이다.\nUSB 포트 하나로 다양한 전자기기를 연결하듯, AI 모델이 MCP를 통해 외부 시스템과 손쉽게 데이터를 주고받을 수 있도록 하는 것이다. 이용자는 여러 서비스를 오가지 않고 하나의 서비스에서 수요와 목적에 맞는 작업을 처리할 수 있다.\n이번 플레이MCP는 국내에서 처음 선보이는 MCP 기반 개방형 플랫폼이라는 설명이다. 카카오가 지향하는 AI 에이전트 생태계 구축의 첫걸음으로, ‘일상 AI’ 서비스 맥락을 고도화해나가기 위한 전략이라고 전했다.\n개발자라면 카카오계정을 통해 누구나 참여 가능하며, 개발자들은 자신이 만든 MCP 서버를 등록하고 실제 대화에서 어떻게 작동하는지 테스트해볼 수 있다. 다른 개발자의 MCP와 도구도 자유롭게 사용 가능하다.\n이번 플랫폼을 계기로 외부 개발자와의 협업을 확대, AI 생태계를 더욱 풍성하게 할 수 있을 것이라고 전했다.\n한편, 카카오는 현재 카카오톡 나와의 채팅방, 톡캘린더, 카카오맵, 선물하기, 멜론 등 MCP 서버와 연결 도구를 테스트용으로 공개해 다양한 실험을 지원하고 있다.\n유용하 카카오 AI에이전트플랫폼 성과리더는 “AI가 사용자 의도를 깊이 이해하고, 필요한 작업을 자율적으로 처리하는 시대가 빠르게 도래하고 있다”라며 “플레이MCP는 카카오 안팎의 개발자들이 함께 에이전틱 AI의 기획-실험-실행을 통합적으로 경험할 수 있는 플레이그라운드가 될 것”이라고 말했다\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "메이아이, 아이돌 포토카드 샵에 매장 분석 솔루션 ‘매쉬’ 공급",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201483&page=3&total=15587",
        "content": "영상처리 인공지능(AI) 전문 메이아이(대표 김찬규)는 인플루디오와 매장 분석 AI 솔루션 ‘매쉬(mAsh)’ 공급 계약을 체결, 글로벌 최대 규모 K팝 아이돌 포토카드 전시-거래 공간 포카스팟에 서비스를 제공한다고 13일 밝혔다.\n매쉬는 오프라인 공간의 CCTV 영상을 기반으로 방문객의 동선과 상호작용을 분석해 고객 경험 개선과 매장 운영 최적화를 돕는 영상처리 AI 솔루션이다.\n이번 계약으로 메이아이는 포카스팟 전 지점에 매쉬를 공급, ▲매장 앞 유동인구 ▲방문객 수 ▲성별-연령대 등을 측정하게 됐다. 수집된 데이터를 기반으로 방문부터 결제까지의 구매 여정과 단계별 전환율을 분석하고, 지점별 방문객 성향에 맞춘 매장 운영 전략 수립을 지원할 계획이다.\n김찬규 메이아이 대표는 “국내외 방문객의 구역별 구매 여정을 분석하고 단계별 전환율을 측정해 개선점을 구체화, 인플루디오의 매장 운영 효율화를 적극 지원하겠다”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "아크릴, 과기정통부 'AI스타펠로우십' 사업 참여...”헬스케어 AI 플랫폼 고도화”",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201484&page=3&total=15587",
        "content": "인공지능(AI) 플랫폼 전문 아크릴(대표 박외진)은 과학기술정보통신부의 '2025년 AI스타펠로우십 지원사업'에 성균관대학교와 공동 선정됐다고 13일 밝혔다.\n'지능형 에이전트 기술 개발'을 목표로 2025년 7월부터 2030년 12월까지 5년 6개월간 진행된다. 정부 지원금 110억원을 포함해 총 115.5억원이 투입되는 대규모 국책 사업이다.\n아크릴은 이번 과제를 통해 기존 LLM옵스 플랫폼 '조나단'을 헬스케어 분야에 특화된 ‘에이전트 옵스 플랫폼’으로 고도화할 예정이다. 특히, 모델 관리-배포 중심의 전통적 서비스 체계를 넘어 자율적 특성을 갖는 에이전트의 구성, 조율, 협력을 빠르게 구성할 수 있는 시스템으로 전환할 계획이다.\n의료AI 특화 플랫폼 ‘나디아’와도 기술을 결합, AI 헬스케어 서비스도 선보일 계획이다.\n▲멀티 도메인 상용 의료 특화 플랫폼 활용 및 에이전트 AI 서비스 개발 ▲사용자와 상호작용하며 경험과 지식을 축적하는 휴머노이드 체화형 동반자 에이전트 기술 개발 ▲이기종 AI 시스템 간 연동을 위한 표준화된 인터페이스(UI) 및 통신 프로토콜 공동 개발 등을 추진한다는 설명이다.\n아크릴 관계자는 \"이번 국책 사업을 통해 의료, 헬스케어 분야의 실사용 중심 관점에서 선도적인 기술 경쟁력을 확보할 것\"이라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "바카티오, AI 대화형 지도 앱으로 '레드닷 디자인 어워드' 수상",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201481&page=3&total=15587",
        "content": "바카티오(대표 지현준)는 인공지능(AI) 공간 추천 서비스 ‘플레이스리스트(Placelist)’가 세계 3대 디자인상 중 하나인 ‘2025 레드닷 디자인 어워드(2025 Red Dot Design Award)’를 수상했다고 13일 밝혔다.\n플레이스리스트는 국내 최초 대형언어모델(LLM) 기반 대화형 지도 앱으로, 사용자의 상황과 취향을 이해해 자연스러운 대화만으로 맞춤 장소를 추천해 주는 서비스다.\n그래픽인터페이스(GUI) 중심이었던 지도에 AI를 적용해 새롭게 해석한 혁신성 및 인사이트를 인정받았다는 설명이다. 특히, 캐릭터 에이전트가 사용자와의 대화를 학습해 점점 더 정교하고 개인화된 추천을 제공해 준다고 강조했다.\n지현준 바카티오 대표는 “플레이스리스트는 단순한 지도 앱이 아니라, 사용자의 삶을 여행처럼 설레게 만드는 새로운 탐색 경험을 제공한다”라며 “이번 수상을 계기로 글로벌 무대에서 지속적으로 경쟁력을 높여 나가겠다”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "딥브레인AI, 광복 80주년 맞이 안중근 의사 AI 영상 복원",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201479&page=3&total=15587",
        "content": "생성 인공지능(AI) 전문 딥브레인AI(대표 장세영)는 광복 80주년을 기념해 안중근 의사의 흑백사진을 고품질 AI 영상으로 복원했다고 13일 밝혔다.\nAI 영상 합성 플랫폼 ‘AI 스튜디오’의 이미지-영상 복원 및 보정 기능을 통해 흑백사진을 고화질 컬러로 변환한 뒤 얼굴 데이터를 추출, 딥러닝 학습을 거쳐 자연스러운 입모양과 제스처를 구현했다는 설명이다.\n광복절의 역사적 의미를 쉽고 선명하게 기억할 수 있도록광복 80주년 기념 온라인 페이지도 개설했다.\n여기에는 ▲안중근 의사 기념 영상 ▲복원 전후 비교 ▲나만의 기념 영상 만들기 등이 포함됐다. 특히, ‘나만의 기념 영상’으로 개인 소장과 온라인 공유도 가능, 누구나 광복절을 색다른 방식으로 기념할 수 있다고 전했다.\n장세영 딥브레인AI 대표는 “AI 기술은 단순한 혁신을 넘어, 과거와 현재를 연결하고 미래 세대에 역사적 가치를 전할 수 있는 도구”라며 “이번 안중근 의사 영상 복원 프로젝트를 통해 국민들이 광복절의 의미를 보다 생생하게 느끼고 기억하길 바란다”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "SKT, 광복절 기념 'AI 독립' 다큐멘터리 공개",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201480&page=3&total=15587",
        "content": "SK텔레콤(대표 유영상)은 광복 80주년을 맞아 다큐멘터리 ‘광복 80년, 그리고 보이지 않는 전쟁 : AI 독립’을 유튜브 채널에 공개했다고 13일 밝혔다.\n김재원 역사학자를 비롯해 김현철 한국인공지능협회 회장 등 인공지능(AI) 분야 전문가들이 출연, 광복의 의미와 한국의 AI 산업 현황, AI 독립을 위한 인프라의 중요성 등을 알기 쉽게 설명한다. SKT AI 기술을 활용해 복원한 독립운동가 80인이 애국가 합창을 선보이는 모습도 포함됐다.\n다큐멘터리는 AI가 단순한 기술을 넘어 국가 주권이 걸린 전략 자산임을 강조, AI 기술뿐 아니라 AI 데이터센터(DC)와 같은 핵심 인프라를 보유한 국가만이 소버린 AI를 통한 AI시대 주권을 확보할 수 있다고 강조한다.\n박규현 SKT 디지털커뮤니케이션실장은 “이번 다큐멘터리가 AI 시대를 맞아 우리의 주권이 ‘영토’에서 ‘AI 인프라’로 확장되는 변화상을 알리는데 도움이 되길 바란다”라며 “앞으로도 SKT는 AI 주권 확보를 위한 AI 인프라 구축을 선도해 갈 것”이라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "머스크, 알트먼과 앱스토어 순위로 설전...\"애플은 챗GPT만 편애\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201471&page=3&total=15587",
        "content": "일론 머스크 CEO와 샘 알트먼 오픈AI CEO가 다시 설전을 펼쳤다. 이번에는 머스크 CEO가 ‘그록’ 대신 ‘챗GPT’를 편애하며 앱스토어 1위 진입을 막고 있다며 애플에 반독점 소송을 예고한 것이 빌미가 됐다.\n머스크 CEO는 12일(현지시간) X(트위터)를 통해 “애플은 오픈AI 외 어떤 AI 회사도 앱스토어 1위를 달성할 수 없도록 하고 있으며, 이는 명백한 반독점 위반”이라며 “xAI는 즉각 법적 조치를 취할 것”이라고 밝혔다.\n또 앱스토어의 ‘머스트 해브(Must Have)’ 추천 섹션에서 X와 그록이 제외된 점을 거론하며 “정치적 판단이 작용한 것 아닌가”고 비판했다.\n이런 발언이 나온 것은 최근 그록에 동영상 생성 기능이 추가되며, 각국의 앱스토어에서 그록이 잇달아 다운로드 1위를 차지했다는 소식이 전해졌기 때문이다.\n머스크 CEO도 이런 사실을 강조하며 챗GPT에 이미지 생성 기능이 탑재됐을 당시와 같은 붐을 기대했으나, 유독 미국 앱 순위에서는 별 반응이 없다는 점을 강조한 것이다.\n그러나, 지난 6월 오픈AI가 애플과의 협력을 공식 발표한 이후에도 다른 AI 앱이 1위를 차지한 기록이 있다. 센서타워 데이터에 따르면, 지난 1월에는 ‘딥시크’가, 7월에는 ‘퍼플렉시티’가 각각 앱스토어 1위에 올랐다. 그록 앱도 지난 2월 잠시 1위를 차지했다.\nYou got 3M views on your bullshit post, you liar, far more than I’ve received on many of mine, despite me having 50 times your follower count!\n\n그러자 알트먼 CEO가 나섰다. “머스크가 X 플랫폼을 조작해 자신과 자신의 기업에 유리하게, 경쟁자와 반대하는 사람에게 불리하게 조작한다는 주장이 있는 상황에서 이런 발언은 놀랍다”라며 비꼬았다.\n여기에 머스크 CEO는 “당신 헛소리 게시물은 조회수가 300만이 넘었다. 거짓말쟁이”라고 응수했다.\n애플은 앱스토어가 공정하고 편향 없이 운영된다는 공식 입장을 내놨다.\n현재 미국 앱스토어 무료 앱 순위에서는 챗GPT가 1위를 차지하고 있으며, 그록은 5위에 머물러 있다.\n챗GPT는 장기간 최상위권을 유지하고 있으며, 5월~6월 28일간 다운로드 수가 2955만건에 달했다. 이는 틱톡, 페이스북, 인스타그램, X의 총 다운로드 수와 맞먹는 수준이다. 그러나 2024년 전체 다운로드 1위 앱은 중국 전자상거래 플랫폼 ‘테무’였다.\n머스크 CEO는 그록을 앱스토어 1위로 올리기 위해 팬들에게 별점 5점을 요청하는 등 활발하게 홍보 중이다.\n한편, X는 8월 초부터 '뉴스 무료 앱' 부문에서 1위를 차지하며 순항하고 있다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "네이버, 임상시험 전문 제이앤피메디에 투자...”AI 기술 협력 진행”",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201478&page=3&total=15587",
        "content": "네이버(대표 최수연)는 임상시험 플랫폼 전문 제이앤피메디에 투자를 진행, 인공지능(AI) 기술 협력에 나선다고 13일 밝혔다.\n제이앤피메디는 소프트웨어, AI 기술을 기반으로 신약, 혁신 의료기기 개발을 지원하는 기업이다. 제약, 바이오, 의료기기 기업을 대상으로 임상시험 데이터 플랫폼을 제공하고 임상시험수탁기관(CRO) 서비스, 투자 지원, 라이선스 컨설팅 등을 지원하는 국내 대표 디지털 헬스케어 기업이다.\n네이버는 국가 전략 자산인 임상시험 데이터의 관리와 기술 자립을 실현하기 위해 제이앤피메디와 긴밀히 협업할 예정이라고 전했다. 네이버의 AI 기술을 결합해 글로벌 진출에 필요한 디지털 임상시험 역량을 구현할 계획이다.\n최인혁 네이버 테크비즈니스 대표는 “이번 협업으로 양사가 국내외 유망 디지털 헬스케어 기업을 발굴 및 투자하고, 글로벌 시장 진출과 동반 성장을 지원할 계획”이라며 “네이버의 AI 기술을 제이앤피메디의 임상시험 플랫폼 노하우에 접목해 제품 고도화에도 기여할 것\"이라고 말했다.\n한편, 네이버 D2SF는 2017년부터 유망한 헬스케어 스타트업에 투자를 진행하고 있다. 올해 8월 기준 전체 투자 포트폴리오 중 약 18%가 헬스케어 스타트업이다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "솔로몬랩스, 세무 AI로 누적 투자 203억 달성...\"미국 시장에 집중\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201477&page=3&total=15587",
        "content": "솔로몬랩스(대표 이기경)는 세무 인공지능(AI) 솔루션으로 누적 시드 투자금 203억원을 달성했다고 13일 밝혔다.\n이번 라운드에는 두나무앤파트너스와 베이스벤처스가 참여했으며, 467만달러(약 65억원) 규모의 투자를 진행했다. 누적 투자금은 1450만달러(약 203억원)에 달한다.\n창립 1년여만에 이룬 성과다. 2024년 미국 뉴욕에서 시작한 솔로몬랩스는 세금 신고 자동화 솔루션 ‘솔로몬 AI’를 제공한다.\n회계사 부족과 복잡한 세법 환경으로 인해, 세무 및 회계 서비스 접근성이 떨어지는 미국 시장에 초점을 맞췄다. 문서 수집부터 데이터 추출, 신고서 작성까지 AI가 처리, 5시간 이상 걸리던 업무 시간을 30분으로 단축한다고 전했다.\n미국의 한 회사는 솔로몬AI를 도입한 이후 전년 대비 64% 더 많은 신고서를 기한 내 제출한 것으로 알려졌다.\n그 결과, 서비스 출시 6개월 만에 연간 반복 매출(ARR) 100만달러(약 13억8300만원)를 달성했다. 올해 말까지 매출 300만달러(약 41억5000만원) 달성이 목표다.\n이기경 솔로몬랩스 대표는 “창업 팀은 대부분 한국인이지만, 미국 유학이나 근무 경험이 있어 현지 시장에 대한 이해와 접근성이 높았다”라고 밝혔다.\n“특히, 미국 세무-회계 시장이 구조적으로 디지털화가 더딘 분야라는 점에 주목했고, 이에 AI를 활용한 자동화 솔루션의 기회가 크다고 판단해 뉴욕에서 창업하게 됐다”라고 설명했다.\n시드 단계에서 비교적 큰 규모의 투자를 유치할 수 있었던 이유에 대해서는 “미국이라는 큰 시장에서 명확한 수요와 프로덕트의 시장 적합성(PMF)을 조기 확인했고, 그 기회를 빠르게 실현하기 위한 실행 기반을 갖추는 데 집중했기 때문”이라며 “자본 효율성과 우선순위를 바탕으로, 필요한 시점에 필요한 자원을 확보하는 전략적 접근을 취해온 결과”라고 말했다.\n솔로몬랩스는 이번 투자금을 통해 ▲AI 세부 분류 모델 고도화 ▲사용자 인터페이스(UI) 개선 ▲학자금 대출, 위자료 등다양한 세금 항목 및 적용 주 확장 등 제품 경쟁력을 강화할 계획이다. 장기적으로는 데이터 기반 세금 신고 최적화및 맞춤형 절세 전략 제안 기능도 선보일 계획이다.\n이기경 대표는 “솔로몬랩스의 기술력과 시장 문제 해결 능력을 인정받은 결과”라며 “세무 AI 자동화 범위를 넓혀 더 많은 회계법인이 고품질 서비스를 제공하도록 지원하겠다”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "퍼플렉시티, 구글에 '크롬' 48조 인수 제안...\"매각 가능성 낮아\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201469&page=3&total=15587",
        "content": "퍼플렉시티가 구글에 '크롬' 브라우저 인수를 제안했다. 구글 검색 독점에 따른 조치 판결이 다가오자, 다른 곳보다 빨리 구체적인 움직임에 나선 것이다.\n12일(현지시간) 로이터와 블룸버그 등에 따르면, 퍼플렉시티는 웹 브라우저 ‘크롬(Chrome)’ 인수를 위해 345억달러(약 48조원) 규모의 전액 현금 매입을 구글에 제안했다.\n구글이 매각 의사를 공식적으로 밝히지 않은 상황에서 추진된 ‘비공개(off-market)’ 거래다. 또 퍼플렉시티가 자체 자금이 아닌 외부 대형 투자펀드로부터 전액을 조달하는 구조다.\n퍼플렉시티는 투자자 명단을 공개하지 않았다. 하지만, 인수 성사 시 2년간 30억달러를 크롬과 크로미엄(Chromium) 개발에 투자하고, 핵심 인력 다수를 영입하겠다고 약속했다.\n또 기본 검색 엔진 변경이나 은밀한 코드 수정을 하지 않으며, 크로미엄의 오픈 소스 정책을 유지하겠다고 밝혔다. 크로미엄은 웹브라우저 프로젝트로, 크롬은 크로미엄 코드를 기반으로 개발됐다.\n이번 제안은 구글의 검색 독점 판결에 따라 이를 해소하려는 조치 결정이 다가오며 이뤄진 것이다. 미국 법무부는 구글이 크롬을 다른 회사에 판매해야 한다고 주장했으며, 이는 이달 중 판결이 날 예정이다.\n또 크롬 인수 의사를 밝힌 곳은 퍼플렉시티뿐이 아니다. 지난 5월 재판 도중 증인으로 참석한 오픈AI와 야후 등도 크롬이 매물로 나오면 입찰에 참가할 것이라고 밝혔다.\n그러나 시장 분석가들은 구글이 크롬을 ‘AI 방어 전략’의 핵심으로 보고 있어 매각 가능성이 낮으며, 법원의 매각 명령이 내려져도 항소 절차로 수년이 소요될 수 있다고 전망했다.\n퍼플렉시티는 최근 AI 브라우저 ‘코멧(Comet)’을 일부 사용자에게 공개하고, 정식 출시를 준비 중이다. 대형 투자 유치로 자금을 확보한 뒤 지난 1월에는 틱톡 미국 사업 인수 제안에도 참여했다.\n한편, 가브리엘 와인버그 덕덕고 CEO는 크롬의 가치를 최소 500억달러로 추산하며, \"이번 제안은 저평가\"라고 지적했다.\n다른 전문가들도 크롬의 실제 가치는 1000억달러에 이를 수 있으며, 매각 가능성 자체가 희박하다고 입을 모았다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-13",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "업스테이지 \"OCR 수요 급증...데이터 자산화 필수 도구\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201404&page=3&total=15587",
        "content": "\"기업의 AI 도입이 늘어나며 데이터 자산화 수요도 많이 증가했습니다. OCR은 바로 이를 해결하는 핵심 기술입니다.\"\n업스테이지(대표 김성훈)가 주력 사업인 대형언어모델(LLM) 수요 증가에 따라 광학문자인식(OCR)도 활성화되고 있다고 밝혔다. LLM 구축을 위해서는 데이터 구축이 우선으로, 여기에서 OCR의 역할이 강조된다는 설명이다.\n이건찬 업스테이지 도큐먼트파스 사업개발 리드는 \"최근 하루 평균 기업 두곳의 기업과 OCR 관련 미팅을 진행하고 있다\"라며 \"특히, 보험이나 물류뿐만 아니라 최근에는 건설 분야에서 수요가 급증하고 있다\"라고 12일 밝혔다.\n그는 \"건설 공사 1건에서 발생하는 문서는 평균 5000~6000개에 달한다\"라며 \"입찰, 법률 등 세계 각국에서 건설사로 전달되는 문서를 모두 살펴보는 것 자체만으로 엄청난 시간이 소요될 수밖에 없다\"라고 말했다.\n이어 \"건설이나 보험 분야는 문서의 포맷이 정해지지 않았을뿐더러 정보 유출에 더 조심스러운 경우가 많다\"라며 \"이때 OCR로 데이터를 추출, 독소조항 등 발견해야 하는 필수 정보를 검색 증강 생성(RAG) 기반으로 빠르게 검색할 수 있다\"라고 설명했다.\n이 때문에 업스테이지는 오픈 베타 웹사이트 ‘AI 스페이스(Space)’를 최근 오픈했다. 이는 다양한 형식의 문서나 문법, 문맥까지 식별할 수 있는 '도큐먼트 파스(Document Parse)' 모델을 기반으로 한다. 이를 통해 다양한 형식의 문서를 일원화된 데이터 체계로 구축해 준다.\n\"매일, 매시간 새로운 AI 모델이 출시되는 상황에서 고성능 AI 모델을 빠르게 적용하기 위해 기업이 할 일은 데이터 최적화일 수밖에 없다\"라며 \"실제로 비정형 문서 데이터를 AI에 학습하기 좋은 형태로 미리 준비해 두는 곳도 많아졌다\"라고 전했다.\n특히, OCR 기술은 문서를 단순히 읽어내는 것을 넘어 기업의 의사결정까지 바꿀 수 있다고 강조했다.\n증권사 데이터의 경우, 복잡한 화면 안에서 어떤 데이터를 읽어내는지가 중요하다는 것이다. 수요에 맞게 데이터를 추출, 화면을 재구성하는 과정은 필수다.\n또 \"업스테이지는 '파서(Parser)' 모델만으로 문서 정보 추출이 가능하다\"라며 \"모델이 가벼운 만큼 가격 경쟁력도 갖췄다\"라고 말했다.\n여기에 회사가 LLM을 보유하는 등 '풀 파이프라인'을 갖추고 있다는 점을 강점으로 꼽았다. \"최근 추론 하이브리드 모델 '솔라 프로2'가 출시되며 수요가 더 늘었다\"라고 말했다.\nOCR 기술은 개인에게도 유용하다고 전했다. 많은 자료를 업로드하고, 이를 용도에 맞는 형태로 출력할 수 있기 때문이다.\n최근 인기를 끄는 구글의 노트북LM과 OCR 기능을 비교했다. 똑같이 관련 문서를 업로드하는 방식이지만, 도큐먼트 파스는 문서 요약을 넘어 문서의 어디에 어떤 정보가 있는지까지 찾아낼 수 있다.\n이 때문에 AI 스페이스는 현재 액세스 신청자 대상으로 무료 오픈 베타 서비스 중이다.\n해외에서의 성과도 두드러진다고 전했다. \"미국 보험 업계에서도 많이 도입하며 가시적인 성과가 드러나고 있다\"라고 말했다.\n또 \"일본은 문서 규모가 다른 국가에 비해 매우 큰 편\"이라며 \"문서량은 국내의 6~10배에 달하며, 특히 공공기관에 집중돼 있어 수요가 증가할 것으로 전망한다\"라고 말했다.\n업스테이지는 현재 비전언어모델(VLM)을 개발 중이라고 덧붙였다. 이는 파서보다 더 많은 정보의 해석이 필요할 때 유용하다.\n그는 \"문서 디지털화는 기업의 AI 도입을 위해 현재 가장 중요한 문제가 됐다\"라며 \"업스테이지는 기업의 지식 자산을 디지털로 전환, 일상 업무의 AGI 달성에 앞장설 것\"이라고 강조했다.\n\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "엔비디아, 로봇용 '추론 비전언어모델' 공개...\"사람처럼 생각하며 현실 이해\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201451&page=3&total=15587",
        "content": "\n엔비디아가 로봇을 위한 새로운 인공지능(AI) 추론 모델을 공개했다. 또 인기 월드모델 '코스모스'의 학습을 돕는 도구를 추가했다.\n엔비디아는 11일(현지시간) 캐나다 밴쿠버에서 열린 '시그래프'를 통해 물리 AI(Physical AI)를 위한 모델과 도구, 라이브러리 등을 공개했다.\n이 중 가장 눈길을 끈 것은 '코스모스 추론(Cosmos Reason)'이라는 70억(7B) 매개변수의 오픈 소스 비전언어모델(VLM)이다. 로봇과 비전 AI 에이전트가 사전 지식과 물리 법칙, 상식 등을 바탕으로 사람처럼 추론하고 현실 세계를 이해하며 행동할 수 있도록 해준다.\n이에 따라 로봇이 새로운 환경을 해석하고, 복잡한 명령을 받아 세부 작업으로 나눈 뒤 상식을 활용해 임무를 처리할 수 있게 해준다는 설명이다. 또 로봇 훈련에 사용하는 영상 데이터를 분석, 인간 대신 라벨링을 자동화하는 데 활용할 수 있다.\n엔비디아는 지난 3월 VLM ‘코스모스-추론1(Cosmos-Reason1)’에 관한 논문을 발표한 바 있다. 이번에는 이를 모델로 발표한 것이다.\n이와 관련, 구글의 딥마인드도 지난 3월 ‘제미나이 로보틱스(Gemini Robotics)’라는 로봇용 비전언어행동모델(VLAM)을 선보인 바 있다. 또 공간 이해 능력을 활용해 복잡한 로봇 움직임을 추론하는 '제미나이 로보틱스-ER'도 공개했다. 이처럼 로봇 AI에도 추론이 탑재, 에이전트 능력을 강화하는 추세다.\n엔비디아는 이날 로봇용 인기 월드모델 '코스모스' 업그레이드도 발표했다. 코스모스는 지난 1월 CES에서 처음 공개된 것으로 로봇 훈련용 3D 환경, 즉 디지털 트윈을 구축해 주는 모델이다. 이미 전 세계 개발자들로부터 200만회 이상 다운로드됐다고 밝혔다.\n이번에는 ▲프롬프트 과정을 간소화하고 사실적인 3D 환경을 생성하는 '코스모스 트랜스퍼-2'와 ▲기존 70단계에 달하는 모델 증류(distillation) 과정을 한단계로 줄인 '코스모스 트랜스퍼-2 디스틸드(distilled)' 버전을 추가했다. 이를 통해 로봇 개발자들의 빠른 가상훈련 환경 구축과 사실적인 시뮬레이션 테스트를 지원한다는 의도다.\n이 밖에도 새로운 '옴니버스 누렉(NuRec)' 라이브러리와 비전 AI를 위한 메트로폴리스(Metropolis) 플랫폼 등도 추가했다. 이 역시 로봇 훈련용 가상 환경을 구축하는 데 도움이 되는 도구들이다.\n이처럼 엔비디아는 올해부터 물리 AI, 그중에서도 로봇 AI 훈련을 위한 각종 모델과 솔루션을 꾸준히 발표하고 있다. 젠슨 황 CEO는 로봇 공학이 AI의 다음 단계라고 강조한 바 있다.\n밍유 리우 엔비디아 연구 담당 부사장은 \"물리 AI는 실제처럼 느껴지는 가상 환경, 즉 로봇이 시행착오를 통해 안전하게 학습할 수 있는 공간이 필요하다\"라며 \"이런 가상 세계를 구축하려면 실시간 렌더링, 컴퓨터 비전, 물리적 동작 시뮬레이션, 2D 및 3D 생성 AI, 그리고 AI 추론이 필요하다. 엔비디아는 거의 20년 동안 이 분야에 집중해 왔다\"라고 밝혔다.\n이 밖에도 엔비디아는 이번 행사에서 신경 렌더링과 실시간 경로 추적 , 합성 데이터 생성 및 강화 학습 분야에서 12개 이상의 논문을 발표한다. 이는 차세대 물리 AI 도구에 활용될 예정이다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "앤트로픽, 클로드에 ‘메모리 기능’ 도입...\"업무 용도에 한정\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201456&page=4&total=15587",
        "content": "앤트로픽이 ‘클로드(Claude)’에 사용자가 원할 때 이전 대화를 불러와 요약하고 참조할 수 있는 메모리 기능을 선보였다. 이 기능은 웹, 데스크톱, 모바일 등 다양한 플랫폼에서 분리됐던 작업을 연결할 수 있다는 점이 특징으로, 다른 챗봇의 '개인화' 도구와는 성격이 다르다.\n앤트로픽은 11일(현지시간) 클로드에 메모리 기능을 도입했다고 발표했다.\n사용자가 요청하면 과거 대화를 검색해 요약하고 이를 바탕으로 프로젝트를 이어갈 수 있다. 한 사용자가 휴가 전 진행했던 대화 내용을 물어보자, 클로드가 기록을 불러와 요약하고 “계속 같은 프로젝트를 진행하겠는가”라고 질문하는 모습을 공개했다.\n앤트로픽은 “이제 작업 흐름을 잃어버리지 않아도 된다”라며 “클로드가 이전 대화를 기억해 프로젝트를 매끄럽게 이어가고, 과거 논의를 참조하며, 아이디어를 확장할 수 있다”라고 설명했다.\n클로드 맥스, 팀, 엔터프라이즈 등 유료 사용자부터 순차 적용하고 있으며, 설정 메뉴 ‘프로필’의 ‘채팅 검색 및 참조’에서 활성화할 수 있다. 다른 요금제에도 확대 적용될 예정이다.\n다만, 이 기능은 오픈AI의 챗GPT처럼 ‘지속적 메모리(persistent memory)’를 구축하는 것은 아니다. 앤트로픽 대변인은 “사용자가 요청할 때만 과거 대화를 불러오며, 개별 사용자 프로필을 만들지 않는다”라고 강조했다.\n즉, 오픈AI의 메모리는 개인 비서와 AI 컴패니언에 집중했다면, 앤트로픽은 업무 효율만을 강조한 셈이다. 이름은 같지만, 용도는 완전히 다르다.\n이런 이유로 앤트로픽은 다른 회사보다 늦게 이 기능을 출시했다. 오픈AI는 지난해 5월, 구글은 2월 이전 대화 내용을 활용해 개인화된 답변을 제공하는 기능을 도입했다.\n한편, 메모리 기능은 최근 논란도 불러왔다. 챗GPT가 일부 사용자에게 망상을 부추기는 것도 메모리를 통해서 가능했기 때문이다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "머스크, 테슬라 '도조' 슈퍼컴 폐쇄 확정",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201458&page=4&total=15587",
        "content": "테슬라가 인공지능(AI) 슈퍼컴퓨터 ‘도조(Dojo)’ 프로젝트를 공식적으로 중단했다. 전기차 판매 부진과 브랜드 신뢰 하락이 겹친 가운데, AI 칩 개발 중복 투자를 피하겠다는 것이다.\n일론 머스크 CEO는 11일(현지시간) X(트위터)를 통해 “모든 개발 방향이 'AI6' 칩에 집중되는 것이 명확해지며 도조를 폐쇄하고 인력 재배치를 단행했다”라고 발표했다.\n이는 지난 7일 블룸버그를 통해 보도된 내용을 공식 확인한 것이다. 이에 앞서 도조 팀 엔지니어 20여명은 테슬라를 떠나 AI 스타트업 덴시티AI(density AI)를 창립했다.\n머스크 CEO는 “도조2는 사실상 진화의 막다른 길이었다”라고 밝혔다.\n테슬라는 첫 도조 슈퍼컴퓨터를 지난 2023년 구축한 뒤 엔비디아 GPU와 자체 제작 D1 칩을 혼합해 구동했다. 이어 '도조 2'를 건설하고, 여기에 개발 중인 D2 칩을 투입할 예정이었다.\n그러나 최근 TSMC와 삼성에서 각각 'AI5'와 'AI6' 칩을 개발하기록 결정함에 따라, D2 칩 개발이 보류된 것으로 보인다. AI5 칩은 주로 테슬라의 운전자 보조 시스템인 FSD 구동용으로 설계됐으며, AI6 칩은 자율주행과 휴머노이드 로봇, AI 훈련 등을 위해 설계됐다. 따라서 D2의 개발을 중복으로 본 것이다.\n그는 앞서 \"테슬라가 두가지 완전히 다른 AI 칩 디자인을 확장하는 것은 합리적이지 않다\"라며 \"AI5, AI6와 후속 칩은 추론에 탁월할 것이며, 학습에도 상당히 효과적일 것\"이라고 밝힌 바 있다.\n\nOnce it became clear that all paths converged to AI6, I had to shut down Dojo and make some tough personnel choices, as Dojo 2 was now an evolutionary dead end.Dojo 3 arguably lives on in the form of a large number of AI6 SoCs on a single board.\n\n이에 따라 테슬라는 앞으로 엔비디아나 AMD 등 외부 컴퓨팅 기술 파트너와 삼성전자 등 반도체 제조업체 의존도를 높일 계획이다. 삼성과 2033년까지 AI 반도체 공급 계약을 체결하고, 차세대 AI6 칩 생산을 위한 텍사스 공장 설립을 추진 중이다.\n도조 프로젝트는 2019년부터 테슬라의 자율주행과 휴머노이드 로봇 상용화의 핵심으로 추진돼 왔으나, 지난해 8월부터 텍사스 오스틴 본사에서 건설 중인 초대형 AI 학습 클러스터 ‘코텍스(Cortex)’를 강조하면서 언급이 사라졌다.\n하지만, 코텍스 프로젝트 진행 여부와 뉴욕 버펄로에 5억달러를 투자해 건립 중인 도조 시설의 향방은 불투명하다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "\"AI, 100년 기술 사상 가장 빠른 속도로 억만장자 배출\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201461&page=4&total=15587",
        "content": "인공지능(AI) 붐으로 올해에만 수십명의 새로운 억만장자가 탄생한 것으로 알려졌다. AI 산업이 기술 사상 가장 빠르고 거대한 부의 중심으로 떠올랐다는 분석이다.\nCB 인사이트는 10일(현지시간) AI 유니콘 기업 중 기업 가치가 10억달러(약 1조3900억원) 이상인 유니콘이 498개에 달한다고 발표했다. 이들의 기업 가치를 합치면 2.7조달러(약 3750조원)에 이른다.\n이 가운데 100개 기업은 2023년 이후 설립됐다. 또 1억달러 이상의 평가를 받은 AI 스타트업은 무려 1300개 이상으로 집계됐다.\n특히 올해에는 앤트로픽과 SSI, 오픈AI, 애니스피어 등이 잇달아 대규모 자금 조달에 성공하며 사상 최고의 몸값을 돌파한 것이 주효했다.\n여기에 상장 기업인 엔비디아와 메타, 마이크로소프트의 주가 상승과 데이터센터·컴퓨팅 인프라 기업들의 급성장, 그리고 AI 인재 경쟁에 따른 고액 보상 등이 맞물리며 AI 부자들이 빠르게 늘어났다는 분석이다.\n앤드류 맥아피 MIT 디지털 경제 이니셔티브 공동 소장은 “지난 100년간 데이터를 살펴봐도, 이 정도 속도와 규모의 부 창출은 찾아보기 어렵다”라고 말했다.\n올해 억만장자 대열에 합류한 인물도 10명이 넘게 꼽혔다. 여기에는 일리야 수츠케버 SSI 창립자와 미라 무라티 싱킹 머신즈 랩 창립자 등 오픈AI 출신이 나란히 포함됐다.\n또 다리오 아모데이 앤트로픽 창립자와 아라빈드 스리니바스 퍼플렉시티 창립자는 물론, 량원펑 딥시크 창립자와 메타에 합류한 알렉산드르 왕 스케일 AI 창립자도 포함됐다.\n'커서'를 운영하는 마이크 트루웰 애니스피어 창립자와 로봇 스타트업 피규어 AI의 브렛 애드콕 창립자, 상장에 성공한 마이클 인트레이터 코어위브 창립자 등도 이름을 올렸다.\nAI 부의 중심지는 여전히 샌프란시스코와 실리콘 밸리로 나타났다. 지난해 실리콘 밸리 기업들의 투자 유치는 350억달러(약 49조원)를 돌파했다.\n또 뉴욕을 제치고 억만장자가 가장 많은 도시가 된 샌프란시스코에서는 부동산 가격과 임대료가 급등하며 AI 호황의 영향이 뚜렷하게 나타나고 있다.\n다만, 현재 대부분 AI 기업들은 비상장 상태로, 자산을 현금화하기 쉽지 않은 구조다. 닷컴 버블 당시와는 달리, 현재 스타트업들은 벤처 캐피털, 국부펀드, 가족 투자사 등으로부터 끊임없는 자금 지원을 받으며 비상장 상태를 유지하는 추세다.\n한편, 맥아피 소장은 “과거 닷컴 부자들이 초기 실패를 겪은 후 분산 투자와 전문 매니저 고용으로 안정화를 이뤘던 것처럼, AI 부자들도 비슷한 길을 걷게 될 것”이라고 내다봤다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "트럼프, ‘블랙웰’ 칩 중국 수출 시사...“성능 30~50% 낮춘 버전 검토”",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201438&page=4&total=15587",
        "content": "도널드 트럼프 미국 대통령이 엔비디아의 최신 AI 칩 ‘블랙웰(Blackwell)’의 성능을 대폭 낮춰 중국에 수출하겠다고 밝혔다. 이번에는 20%의 비용을 부담해야 할 것이라고 강조했다.\n로이터와 CNBC 등에 따르면, 트럼프 대통령은 11일(현지시간) 미디어 브리핑을 통해 엔비디아의 최첨단 AI 칩 ‘블랙웰’을 중국에 판매할 수 있는 가능성을 열어두겠다고 밝혔다.\n단, 성능을 30~50% 낮춘 다운그레이드 버전에 한정된다는 조건을 달았다. 그는 이를 “성능을 의도적으로 낮춘, 다소 강화됐지만 부정적인 방식의 블랙웰”이라고 표현했다.\n이번 발언은 그가 엔비디아와 맺은 별도 합의를 공식 확인하는 자리에서 나왔다. 엔비디아가 ‘H20’ AI 칩을 중국에 판매하는 대신 해당 매출의 15%를 미국 정부에 납부한다는 내용이다.\n하지만, 그는 새 칩의 수출 허가가 떨어진다면 15%가 아닌, 20%를 요구하겠다고 전했다. ”여러분과 나라를 위해 이것을 승인한다면 20%가 필요하다”라고 덧붙였다. 또 \"이 문제로 황 CEO가 또 찾아올 것 같다\"라고 전했다.\n블랙웰은 현재 전 세계에서 가장 강력한 AI 학습·추론용 칩으로, 중국 판매가 금지됐다. 트럼프 대통령도 “블랙웰은 초고성능으로, 중국이 5년간 보유하지 못할 수준”이라며, 현 성능 그대로는 판매를 허용하지 않겠다고 선을 그었다.\n앞서 지난달에는 엔비디아가 중국용으로 블랙웰 기반 B30 GPU를 준비 중이며, 이는 H20에 비해 10~20% 정도 성능이 낮지만, 가격은 30~40% 저렴할 것이라는 보도가 등장했다.\n트럼프 대통령이 말한 블랙웰 하위 버전이 B30인지는 확인되지 않았다.\n전문가들은 이번 발언에 대해 중국이 복합적인 반응을 보일 것으로 내다봤다.\n닐 샤 카운터포인트 리서치 창립자는 “중국은 AI 경쟁력 강화를 위해 칩이 필요하지만, 미국 정부 납부금으로 인한 가격 상승과 ‘백도어’ 가능성 우려로 부담이 커질 것”이라고 분석했다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "'바이브 코딩' 깃허브, CEO 사임으로 MS에 통합",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201453&page=4&total=15587",
        "content": "토마스 돔케 깃허브 CEO가 올해 말 자리에서 물러나 새 스타트업을 설립할 계획이라고 밝혔다. 이에 따라 깃허브는 모 회사인 마이크로소프트(MS)의 개발 부서로 재편된다.\n토마스 돔케 깃허브 CEO는 11일(현지시간) 블로그를 통해 올해 말 퇴임한 뒤 새로운 스타트업을 설립할 계획이라고 발표했다.\n그는 2015년 자신이 개발한 코딩 도구가 MS에 인수된 뒤 10년간 회사에 몸담았다.\n2021년 냇 프리드먼 전 CEO의 퇴임 후 깃허브 수장을 맡아, 오픈AI 모델 기반의 AI 코딩 도구 ‘깃허브 코파일럿’ 확장을 주도했다. 깃허브 코파일럿은 현재 MS의 대표적인 AI 제품군 중 하나로 자리 잡았다.\n깃허브는 현재 전 세계 1억5000만명 이상의 개발자가 소프트웨어를 구축하고 관리하는 플랫폼으로 성장했다. MS는 후임 CEO에 대해 아직 공식 발표를 하지 않았으나, 깃허브를 개발 부서에 통합할 계획이다.\n이번 인사는 올해 초 MS에 합류한 메타 임원 출신 제이 패릭 부사장이 깃허브를 비롯한 개발자 중심 부서를 총괄하게 하는 최고경영진 재편 몇달 뒤 나온 것이다. 그는 MS 고객들에게 깃허브 코파일럿를 포함한 AI 에이전트 도구 도입을 확대하는 임무를 맡고 있다.\n돔케 CEO는 앞으로 깃허브가 패릭 부사장이 이끄는 조직 내에서 임무를 이어갈 것이라고 전했다. 자신의 거취에 대해서 상세한 내용을 밝히지는 않았다.\n한편, 그는 최근 블로그를 통해 \"소프트웨어 엔지니어는 AI를 받아들이거나 이 직업을 떠나야 한다\"라고 강력하게 주장한 바 있다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "구글 캘린더 초대장 통한 ‘프롬프트웨어’ 공격 발견",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201460&page=4&total=15587",
        "content": "인공지능(AI) 비서가 일상과 업무 전반에 깊숙이 통합되며, 이를 악용한 신종 보안 위협 사례가 드러났다. 텍스트·이미지·음성 등 다양한 형태의 입력 프롬프트를 대형언어모델(LLM)에 우회적으로 주입, 악의적인 동작을 유발하는 방식이 보고됐다.\n보안 연구 전문 세이프브리치는 11일(현지시간) 구글 캘린더의 악성 초대장을 이용해, 구글 워크스페이스와 안드로이드 운영체제, 검색 엔진 등에 탑재된 AI 비서 ‘제미나이(Gemini)’를 공격할 수 있는 ‘프롬프트웨어(Promptware)’ 기법을 공개했다고 보도했다.\n프롬프트웨어는 텍스트·이미지·오디오 샘플 등 입력 프롬프트를 조작해 대형언어모델(LLM)을 악용, 스팸 전송이나 기밀 정보 탈취 등을 유발하는 기법이다.\n제미나이의 프롬프트 창에서는 잘 통하지 않는 공격이 구글 워크스페이스나 안드로이드, 검색 엔진 등을 통해 우회하면 작동한다는 것이 핵심이다. 예를 들어, 악성 코드가 담긴 구글 캘린더 초대장을 보내, 사용자 채팅 기록 속에 숨겨둔 프롬프트웨어를 간접 실행하는 방식이다.\n이 공격을 통해 스팸·피싱 메시지 발송, 독성 콘텐츠 생성, 캘린더 이벤트 삭제, 스마트홈 기기 원격 제어, 위치 추적, 줌(Zoom)을 통한 영상 스트리밍, 이메일 유출 등 다양한 악성 행위를 수행할 수 있었다고 전했다.\n세이프브리치는 프롬프트웨어의 위험성을 과소평가한다고 지적했다. 특히 제미나이처럼 많은 서비스에 통합된 경우, 피해 범위가 커질 수 있다고 경고했다.\n세이프브리치는 올해 2월 이런 점을 구글에 알렸으며, 구글은 6월 ‘멀티 레이어 완화 접근법’이라는 대응 방안을 공개했다.\n세이프브리치는 “LLM 개인 비서가 일으키는 위협의 73%가 ‘높음' 이상의 수준”이라며 “이 위험을 줄이기 위한 신속하고 전담된 보안 조치가 필요하다”라고 강조했다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "[게시판] 솔트룩스, ‘한국전력기술 지식정보 플랫폼 구축 사업’ 선정 등 단신",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201465&page=4&total=15587",
        "content": "■ 인공지능(AI) 전문 솔트룩스(대표 이경일)는 한국전력기술이 추진하는 ‘지식정보 통합 플랫폼 구축 사업’에 선정됐다고 밝혔다. 언어 모델 기술력을 바탕으로 프로젝트를 수행, 한국전력기술 임직원들이 하나의 통합 포털에서 필요한 정보를 쉽게 찾고, 업무에 최적화된 형태로 활용할 수 있도록 지원할 예정이다.\n■ 다이퀘스트(대표 김경선, 전승훈)는 고성능 챗봇 솔루션 ‘인포채터4’를 카카오뱅크 모바일 앱 내부 챗봇 시스템에 도입해 학습 시간을 단축했다고 밝혔다. 이번 도입으로 기존 20만건 규모의 딥러닝 학습 시간을 3시간30분 이상에서 약 30분으로 단축했으며, 매주 진행되는 정기 학습도 10분 내외로 줄였다고 전했다.\n■ 크라우드웍스(대표 김우승)는 과학기술정보통신부와 한국전파진흥협회가 추진하는 ‘방송영상 AI 학습용 데이터 구축사업’에 선정됐다고 밝혔다. 방송영상 특화 AI 모델 개발을 위해 국내 방송영상 원본을 기반으로 고품질의AI 학습용 데이터를 구축하고 검증하는 것이 목표로, 4개의 컨소시엄이 사업에 참여한다.\n■ 포티투마루(대표 김동환)는 서울 대한상공회의소에서 열린 ‘2025 SW 중심대학 디지털 경진대회’ 본선에서 기업 소개 세션을 진행했다고 밝혔다. 김한수 포티투마루 CTO는 경량언어모델(sLM)과 검색 증강 생성(RAG) 기술 최신 트렌드를 소개했다.\n■ 한컴위드(대표 송상엽)는 안면인증 솔루션 ‘한컴오스 v1.0’로 GS인증 1등급을 획득했다고 밝혔다. 비대면 본인확인을 위한 안면인증 및 신원인증 솔루션으로, 얼굴에서 5000개 이상의 특징점을 추출해 패턴을 비교해 준다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "와들, ‘오픈AI GPT-5 해커톤’ 1위 올라...\"GPT-5로 쇼핑 시뮬레이션 구축\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201440&page=4&total=15587",
        "content": "인공지능(AI) 쇼핑 에이전트 전문 와들(대표 박지혁)은 미국 샌프란시스코에서 열린 ‘오픈AI GPT-5 해커톤’에서 글로벌 93개 팀 중 1위를 차지했다고 12일 밝혔다.\n이번 대회는 오픈AI 와 세레브럴 밸리가 공동 주최했다. 93팀이 참가, 그중 유일한 국내 팀 와들이 우승을 차지했다. 5만달러(약 6700만원) 상당의 오픈AI 크레딧과 다음달 샌프란시스코에서 열리는 ‘데브데이(DevDay)’ 초청권이 수여됐다.\n와들에서는 박지혁 대표를 주축으로 송진태, 한상도, 황태백 엔지니어 등 4명이 참가했다. 24시간 만에 GPT-5를 기반으로 '온라인 쇼핑몰 방문자의 디지털 클론 생성 및 판매 전략 시뮬레이션 시스템'을 개발해냈다.\n또, AI 쇼핑 에이전트 ‘젠투(Gentoo)’와 사용자 간의 대화 데이터를 기반으로 온라인 쇼핑몰 방문자의 디지털 클론을 생성하고 ▲신규 입고 상품 ▲기획전 ▲쿠폰 등의 성과를 예측하는 판매 전략 시뮬레이션 시스템까지 구현했다는 설명이다.\n그 결과, 세쿼이어 캐피탈과 컨빅션 등 벤처캐피탈과 오픈AI 관계자들로 구성된 심사위원단으로부터 최고 점수를 받았다.\n박지혁 와들 대표는 “짧은 시간 안에 아이디어를 구현, 완성도 높은 제품을 만들어 팀의 실행력과 확장 가능성을 입증했다”라며 “오픈AI와의 협력을 통해 글로벌 이커머스 플랫폼에 젠투를 공급하며 온라인 쇼핑 경험을 혁신할 것”이라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "망고부스트 “세계적인 서버 네트워킹 가속 기술로 가격 경쟁력까지 잡아”",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201462&page=4&total=15587",
        "content": "망고부스트(대표 김장우)는 12일 코엑스 컨퍼런스룸 E홀에서 열린 ‘2025 OCP 코리아 테크 데이’를 열고 가격 경쟁력을 갖춘 네트워크 가속 기술로 국내 기업의 기술 주권을 돕겠다고 밝혔다.\n2022년 설립된 망고부스트는 ‘하드웨어(서버) 네트워킹 가속기’ 기술을 보유한 기업이다. 대형언어모델(LLM) 등 인공지능(AI) 기술이 주목 받는 시장 흐름 속에서 학습, 추론(서비스) 측면의 가속을 모두 지원하고 있다는 설명이다.\n이번 행사에서는 두 건의 발표를 진행했다. 김장우 대표는 기조 강연에서 ‘대규모 AI를 위한 고성능 네트워킹 솔루션’을 주제로, RDMA 기반 고성능 GPU 네트워킹 아키텍처와 DPU를 활용한 하드웨어 가속 기법을 소개했다. 김창수 시스템 소프트웨어팀 팀장은 ‘LLM 추론 서비스 구축 비용 절감 전략’을 발표했다.\n전시 부스에서는 AMD Instinct MI300X 및 MI325X GPU와 망고부스트의 GPU부스트 RDMA NIC, LLM 추론-학습 최적화 소프트웨어 ‘LLM부스트, 스토리지 가속기 스토리지부스트(StorageBoost) DPU를 통합한 완성형 AI 인프라 솔루션을 선보였다.\n김장우 망고부스트 대표는 “AI가 부흥하며 엔비디아 GPU 등 외국 제품에 대한 낭비가 심해지고 있다”라며 “외산 네트워크 제품 대비 매우 높은 가격 경쟁력을 갖추고 있고, 다양한 GPU와도 호환돼서 AI 시스템 비용을 크게 낮출 수 있다”라고 말했다.\n특히, 네트워크 가속 기술을 갖춘 해외 경쟁사는 손에 꼽힌다고 설명했다. 망고부스트는 빠르면서 기능이 많고 유연한 제품으로 경쟁력을 갖췄다는 설명이다.\n김장우 망고부스트 대표는 “국내 AI 인프라는 연산 쪽에 더 치중하는 경향이 있는데, 네트워킹에서도 많은 수요가 발생한다”라며 “망고부스트 제품에 대한 수요도 점점 올라가고 있으며, 앞으로도 더욱 상승할 것으로 본다”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "어드밴스드 에너지 “데이터센터 수요 증가로 국내도 OCP 규격 사용 늘려야”",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201464&page=4&total=15587",
        "content": "어드밴스드 에너지는 12일 코엑스 컨퍼런스룸 E홀에서 열린 ‘2025 OCP 코리아 테크데이’에 참가, 데이터센터 기술과 부품 수요에 맞춰 OCP(Open Compute Project) 규격이 국내에서 더 확대돼야 한다고 밝혔다.\n어드밴스드에너지는 1981년 미국에서 설립, 현재 전 세계 1만명 이상의 직원을 가진 에너지 전문 회사로 성장했다.\n인공지능(AI) 붐으로 전력 수요가 늘어난 것은 물론, 세부적으로는 고성능 GPU의 증가에 따라 ‘높은 냉각 성능’ 수요가 높아졌다는 것을 꼽았다.\n최경민 어드밴스드에너지 부장은 “앞으로 수요가 많아지는 만큼 OCP 규격의 제품을 사용하려는 기업이 점점 많아질 것”이라고 강조했다.\n특히, 그동안 참여율이 저조했던 국내 기업도 ‘국제 규격에 맞는 데이터센터 사업’에 합류해야 한다고 밝혔다. OCP 관련 국가 인증 체계를 마련하면 참여도가 더 높아질 것으로 봤다.\nOCP 코리아 테크데이 행사도 빠르게 발전하고 있다고 평가했다.\n안정열 어드밴스드에너지 부장은 “지난해와 달리 기술 용어 및 부품명을 미리 알고 오는 참관객들이 눈에 띄게 많아졌다”라며 “어드밴스드에너지는 안정적인 데이터센터 관련 기술을 갖춘 만큼, OCP 커뮤니티에 꾸준히 참여하고 기술을 고도화할 것”이라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "오픈AI, 국제 프로그래밍 대회서 금메달...\"범용 추론 기술 또 입증\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201450&page=4&total=15587",
        "content": "\n오픈AI가 국제수학올림피아드(IMO)에 이어 국제정보올림피아드(IOI)에서도 금메달을 획득했다. 이번에도 IMO와 마찬가지로 범용 추론 기술을 활용했다고 밝혔는데, 이는 '범용 검증기'라는 기술로 알려져 있다.\n오픈AI는 12일 X(트위터)를 통해 \"우리의 추론 시스템이 세계 최고의 프로그래밍 대회 중 하나인 2025 IOI에서 금메달을 획득하고 AI 참가자 중 1위를 차지했다는 소식을 전하게 돼 매우 기쁘다\"라는 글을 올렸다.\n오픈AI는 IOI 온라인 AI 트랙에 공식 참가, 330명의 인간 참가자 중 5명에 이어 6위의 성적을 거뒀다. 인터넷이나 검색 증강 생성(RAG) 없이 기본적인 시스템만으로 경쟁을 펼쳤다고 전했다.\nIOI는 전 세계 고등학생을 대상으로 매년 치러지는 프로그래밍 경진 대회다. 국제수학올림피아드에 이어 두번째로 큰 올림피아드 행사로, 세계에서 가장 권위 있는 컴퓨터 대회 중 하나로 꼽힌다. 2일간 매일 3개의 어려운 알고리즘 문제를 풀고, 하루 5시간 동안 인터넷과 외부 자료 없이 C++로 작성된 솔루션을 제출한다.\n다른 AI 모델의 성적은 알려지지 않았다. 또 이 대회에서 한국은 최고 2위를 비롯, 4명 모두가 20위 안에 포함됐다.\n여기에서 오픈AI 모델은 인간과 같이 50개의 프로그래밍 결과를 제출했다. 지난해에도 이 대회에 참가한 오픈AI는 당시 49%의 정답률로 동메달 수준에 그쳤다. 그러나 이번에는 1년 만에 무려 98%로 성적이 높아졌다.\n오픈AI는 이번도 대회를 위해 특별히 모델에 프로그래밍을 훈련한 것이 아니라, 범용 추론 모델을 조합했다고 밝혔다. 앞서 IMO에서 금메달을 거둘 당시에도 수학을 위한 특화 모델이 아닌 범용 모델이 수학적 사고를 수행한 것이라고 밝힌 바 있다.\n이처럼 오픈AI의 새로운 추론 시스템은 수학에 이어 코딩에서 세계 최고의 천재들에 맞먹는 성적을 잇달아 거뒀다. 여기에 사용한 기술이 바로 범용 검증기로, 알트먼 CEO는 이를 앞으로 GPT-5에 확대 적용할 계획이라고 밝힌 바 있다. 이 때문에 \"몇달 동안은 GPT-5가 금메달 수준의 성능을 발휘하지 못할 수 있다\"라고 설명했다.\n오픈AI는 \"지난 몇주 동안 코딩대회 준우승과 IMO, 그리고 IOI에서 성공을 거두며 최신 연구 방법론들이 어떻게 발전해 나가는지 지켜본 것은 정말 흥미진진했다\"라며 \"이런 모델을 우리의 제품에 도입하기 위해 열심히 노력하고 있다\"라고 말했다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "\"OCP 커뮤니티, 모두에 열려 있어...협력으로 기술 문제 해결”",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201463&page=4&total=15587",
        "content": "메타가 지난 2011년 설립한 OCP(Open Compute Project) 재단은 ‘오픈 컴퓨팅 기반의 디지털 전환’을 모색, 전 세계 기업이 기술적 논의를 진행하는 커뮤니티의 역할을 담당하고 있다.\n특히, 미국 등 해외 데이터센터에서는 OCP 규격을 따르는 경우가 점점 증가하고 있는 추세다. 최근에는 더 많은 엔지니어들과의 협력 및 기술 논의를 위해 아시아-태평양(APAC) 지역에서의 행사 개최 및 소통을 확대하고 있다.\n마이클 실 OCP 시니어 디렉터는 “그만큼 아시아는 많은 잠재력을 지니고 있는 시장이기 때문”이라며 “특히, 한국의 경우 데이터센터를 짓기 좋은 조건을 갖추고 있으며 ‘스토리지’ 기술 및 ‘HBM’ 기술에 강점을 지니고 있다”라고 말했다.\n제임스 켈리 OCP 재단 부사장은 “한국 기업이 멤버로 많이 참여한 상태이며, 이번 행사도 특색 있는 플레이어들을 많이 모색하는 데 초점을 맞췄다”라고 말했다.\n이어 “퓨리오사AI나 리벨리온 등과 같은 칩 전문 기업도 한국에 다수 분포된 것으로 알고 있다”라고 말했다.\n사실, OCP 재단은 ‘자원봉사 체제’로 운영되고 있다. 꼭 회원사로 참여하지 않아도, 가벼운 온라인 화상 회의 참여 및 정보 탐색 단계부터 시작해 볼 수 있다. ‘참여비’도 존재하지 않는 ‘열려 있는’ 커뮤니티라고 설명했다.\n특히, 참여하는 것만으로 ‘시장 요구사항’을 정확히 파악해 회사 기술 개발에 활용할 수 있는 이점을 지니고 있다. 셀러와 바이어가 모두 소속돼 있기 때문에, 실제 요구를 바탕으로 기술 보완이 가능한 것이다.\n즉, 대화가 비즈니스로 이어질 수 있는 구조다. 시장의 흐름을 빠르게 파악하는 데에도 유용하다는 설명이다.\n김정수 OCP 한국 커뮤니티 리드는 “참여를 원하는 기업은 언제든지 말씀을 부탁드린다”라며 “더 많은 기업이 논의할수록 더 유익한 정보가 창출될 것”이라고 말했다.\n이어 “미국이나 해외를 상대하는 기업이 많이 참여하고 있지만, 한국 기업간의 커뮤니케이션은 더 활성화돼야 한다”라며 “외국뿐만 아니라 국내에서 국제적인 표준을 마련하는 것을 목표로 소통을 확장해 나갈 것”이라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "KT, 비엣텔그룹과 ‘베트남 AX 혁신’ 협력",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201448&page=4&total=15587",
        "content": "KT(대표 김영섭)는 베트남 국영 ICT 기업 비엣텔 그룹과 ‘전략적 파트너십 2.0’을 체결하고 베트남 국가 인공지능(AI) 전략 수립 및 산업계 AI 전환(AX) 확산을 위한 협력에 나선다고 12일 밝혔다.\n지난 5월 양사 1차 파트너십의 후속 조치다. ▲국가 AI 전략 수립 및 산업 특화 AX 플랫폼 개발 ▲글로벌 파트너십 기반 동남아 AX 사업 확대 협력 ▲AI 기반 사이버 보안 및 안전한 디지털-AX 환경 조성 ▲AX 역량 강화 및 AI 인재 양성 투자 등에서 협력할 계획이다.\n특히, 베트남 고유 언어와 문화, 행정 환경을 학습한 ‘국가 범용 AI 언어모델’을 공동 개발한다고 전했다. 더불어, 베트남 국민들이 일상 속에서 AI를 잘 활용할 수 있도록 실무 중심 AX 전문 교육 프로그램과 관련 역량을 객관적으로 평가할 수 있는 인증 제도를 개발해 운영할 예정이다.\n김영섭 KT 대표는 “국가 차원 AI 전략 수립과 산업별 AX 플랫폼 개발은 단순 기술 제공을 넘어 베트남의 미래 성장동력 확보에 기여하는 의미 있는 협력”이라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "씨이랩, 영상분석 솔루션 엑스아이바 ‘중대·산업재해 안전 버전’ 출시",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201446&page=4&total=15587",
        "content": "비전 인공지능(AI) 전문 씨이랩(대표 윤세혁, 채정환)은 실시간 AI 영상분석 솔루션 '엑스아이바(XAIVA)'의 중대 및 산업재해 안전 특화 버전을 공식 출시했다고 12일 밝혔다.\n이번 최신 버전은 기업용 비전언어모델(VLM)이 탑재된 AI 영상분석 플랫폼이다. 안전, 품질 이벤트 발생시 분석-경보-기록까지 처리해 현장 안전관리와 품질관리를 통합하는 것이 핵심이다.\n특히, 텍스트 프롬프트 입력만으로 ‘작업복 미착용’ ‘위험 지역 접근’ 등 조건을 인식하는 것은 물론, 실시간 경고 기능까지 제공한다는 설명이다. 화재, 재난 위험 요소를 웹 및 모바일을 통해 실시간으로 모니터링하고 즉각 대응할 수 있는 선제적 안전관리 체계도 지원한다.\n더불어, 초고속 영상데이터 처리 기술을 적용해 기존 엔진 대비 최대 11배 빠른 영상분석을 실현했다고 전했다. 평균 99%의 탐지 정확도와 프레임당 0.01초 미만의 분석 속도를 달성, ‘중장비 주변 작업자 위치추적’ ‘제조 공정 내 품질 이상 감지’ ‘위험물 확인’ 등 산업 현장에서의 안전-품질요소를 통합 관리할 수 있다고 강조했다.\n씨이랩은 앞으로 초저전력 고성능 AI 기술을 적용한 경량화 버전도 출시해 소상공인과 중소 제조시설까지 AI 기반 안전관리 도입을 확장할 계획이다.\n윤세혁 씨이랩 대표는 “엑스아이바 산업안전 버전은 현장 안전관리에 집중해 설계된 AI 솔루션”이라며 “기업이 데이터 기반으로 안전관리를 쉽고 정확하게 할 수 있도록 돕겠다”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "망고노트, 'AI 기반 보안회의록' 베타 출시",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201443&page=4&total=15587",
        "content": "망고노트(대표 조대형)는 인공지능(AI) 기반 보안회의록 ‘망고노트(MangoNote)’를 베타 출시했다고 12일 밝혔다.\n망고노트는 회의 데이터를 클라우드에 저장하지 않고, 사용자 로컬 PC에만 보관해 주는 보안 회의록 서비스다. 개발자도 회의 내용을 열람할 수 없도록 설계된 구조적 보안으로, 기존 클라우드 기반 서비스들과는 설계 자체가 다르다고 강조했다.\n실시간 음성 인식(STT) 기능이 내장된 메모장 형태로 작동한다. 회의 중  간단한 메모만 남겨도 AI가 전체 맥락을 분석해 정식 회의록을 자동 생성해 준다는 설명이다. 특히, 외부 음성 인식 API가 아닌 자체 개발 STT 엔진을 활용한다고 강조했다.\n회의 종료 후에는 단 5초 만에 ▲요약본 ▲회의록 ▲업무지시서 등 다양한 형식의 문서를 자동 완성해 준다고 전했다. IR 피칭, 채용 면접, 데일리 스크럼, 고객 미팅 등 업무 상황에 따라 선택 가능한 템플릿도 제공한다고 덧붙였다.\n또, 자동 통역-번역 기능이 기본 탑재돼 있어, 영어 및 일본어 회의에서도 실시간 번역 및 정리가 가능하다. 회의록에 없는 세부 정보가 필요할 경우에는 ‘애스크 망고노트(Ask MangoNote)’ 기능을 활용하면 된다.\n한편, 망고노트는 지난 2개월간 50명의 VIP 고객을 대상으로 클로즈드 테스트를 운영하며 총 67회의 기능 업데이트를 거쳤다. 현재 홈페이지를 통해 맥(Mac) 기반 베타 서비스를 제공 중이다.\n망고노트 관계자는 “AI 회의록의 본질은 요약 속도가 아니라 사용자 신뢰”라며 “민감한 회의 환경에서도 안심하고 사용할 수 있는 보안 회의록의 새로운 기준이 되겠다”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "노타, VLM 영상 관제 솔루션 ‘NVA’ 상용화",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201441&page=4&total=15587",
        "content": "인공지능(AI) 경량화 전문 노타(대표 채명수)는 비전언어모델(VLM) 기반 실시간 영상 관제 솔루션 ‘NVA(Nota Vision Agent)’ 정식 상용 버전을 출시했다고 12일 밝혔다.\nNVA는 영상 속 특정 객체를 단순 인식하는 수준을 넘어 객체 간 관계, 작업 절차 위반, 복합적인 위험 징후까지 실시간으로 감지하고 대응할 수 있는 차세대 관제 솔루션이다.\n이미 코오롱베니트와의 협력으로 코오롱인더스트리 김천2공장에서 진행된 8개 시나리오 기반 기술실증(PoC)을 완료했다. 이를 기반으로 지난달 30일 VLM 기반 패키지를 출시, 시장 확대에 본격 착수했다.\n‘안전 장비를 착용하지 않고 단독으로 사다리 작업’과 같은 다중 조건 포함 표준운영절차(SOP) 위반 시나리오도 프롬프트 기반 인터페이스(UI)를 통해 손쉽게 정의할 수 있으며, 조건 충족 시 2.5초 이내에 다양한 현장 장비와 연동해 즉시 알림을 발송해 준다는 설명이다.\n빠른 도입도 장점이라고 전했다. 기존 AI 관제 솔루션의 경우 평균 3개월 이상이 소요되지만, NVA는 1주일 내 적용이 가능하다는 설명이다. 시스템 설치부터 전체 가동까지도 2~3주면 충분하다고 전했다. 기존 CCTV 인프라와도 즉시 연동돼 별도 장비 교체 없이 손쉽게 도입이 가능하다.\n이번 출시를 계기로 중동, 북미 등 글로벌 시장 진출에도 박차를 가할 계획이다.\n채명수 노타 대표는 “NVA는 생성 AI 기술을 실제 산업 현장에 접목해 인명 피해를 줄이고 안전을 강화하는 데 실질적인 가치를 제공한다”라며 \"산업용 AI 관제의 글로벌 표준이 되는 것이 목표”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "셀렉트스타, 205억 시리즈B 투자 유치…누적 379억 돌파",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201439&page=4&total=15587",
        "content": "인공지능(AI) 데이터 전문 셀렉트스타(대표 김세엽)는 205억원 규모의 시리즈B 투자를 유치, 누적 투자 유치 379억원을 달성했다고 12일 밝혔다.\n이번 라운드에는 KB인베스트먼트, KB증권, 신한벤처투자, 키움인베스트먼트, SBI인베스트먼트, 삼성증권, 무림캐피탈, 인포뱅크파트너스 등 국내 투자사를 비롯해 세일즈포스, ACVC파트너스 등 해외 투자 파트너가 참여했다.\n2018년 설립된 셀렉트스타는 AI 데이터와 신뢰성 검증 전문으로 성장하고 있다. AI 개발에 필수적인 데이터 수집-가공 솔루션을 제공, 국내 5대 그룹 및 5대 금융그룹을 포함한 320여곳 고객사를 확보했다. 최근 한국어 데이터셋 구매를 희망하는 글로벌 기업 문의가 이어지는 가운데, 다국어와 멀티모달 데이터셋 분야로 확장 중이다.\n과학기술정보통신부가 주관하는 ‘독자 AI 파운데이션 모델 개발 사업’에 SKT 컨소시엄으로 참여, 지난 4일 최종 선발팀으로 이름을 올리기도 했다. 이번 투자 유치를 기점으로 신뢰성 검증 솔루션 기술 고도화 및 글로벌 시장 진출에 본격 나설 예정이다.\n김세엽 셀렉트스타 대표는 “글로벌 시장 진출의 원년으로 삼고, AI의 품질과 안전성을 책임지는 글로벌 AI 기업으로 도약하겠다”라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-12",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "오픈AI \"사용자 피드백 위해 GPT-5 조기 출시...배우는 것 더 많아\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201412&page=4&total=15587",
        "content": "오픈AI가 'GPT-5' 기능이 완성되기 전에 의도적으로 먼저 출시했다고 밝혔다. 이는 오픈AI의 철학으로, 사용자 반응으로부터 많은 것을 배우려는 것이라고 설명했다.\n닉 털리 오픈AI 챗GPT 총괄 책임자는 캐스트 '레니의 뉴스레터'에 출연, 오픈AI는 제품 개발과 출시 과정에서 ‘완벽함보다 속도’를 우선한다고 강조했다.\n그는 완성도가 100%에 미치지 못하더라도 제품과 기능을 먼저 공개하고, 실제 사용자들의 피드백을 받아 지속적으로 개선해 나가는 방식을 선호한다고 밝혔다.\n또 “우리가 만드는 것은 기존에 존재하지 않는 것이기 때문에 다른 기업의 방식을 그대로 따라 할 수 없다”라며, GPT-5 출시 전략에도 이런 철학이 반영됐다고 설명했다.\n이는 GPT-5가 기대에 못 미친다는 반응에 대한 변명이 아니다. 이 인터뷰는 GPT-5 출시 전날 이뤄졌다.\n털리 책임자는 “불완전한 상태라도 기능을 먼저 선보이고 사용자 반응을 통해 배워야 한다”라고 강조했다.\n“출시 전에 품질 기준에 너무 집착하면 잘못된 부분만 다듬게 된다”라며, AI처럼 제품의 특성이 출시 후에야 명확해지는 분야에서는 조기 출시가 효과적이라고 강조했다.\n이는 다른 기술 대기업들이 품질 기준을 맞추기 위해 출시를 미루는 것과는 차별화된 전략이다.\n그는 오픈AI의 핵심 문화로 '최대한 가속화(maximally accelerated)'라는 것을 꼽았다. “이 일을 지금 당장, 내일이라도 할 수 없을까”라는 질문을 통해 불필요한 절차와 장애물을 제거하자는 의미다.\n물론, 모든 과정이 무조건 빨라야 하는 것은 아니며, 특히 안전성 검증과 같은 분야에서는 엄격한 절차를 지킨다고 설명했다. 그러나, 제품 개발 단계에서는 ‘빠른 실행과 반복’을 최우선 가치로 삼는다고 강조했다.\n털리 책임자는 '챗GPT'의 탄생 배경도 소개했다. 원래 'GPT-3.5' 성능을 시험하기 위한 내부 해커톤 프로젝트에서 시작했다는 것이다.\n여기에서도 모델에 대한 연구는 오랜 기간 진행됐었지만, 제품 출시를 결정한 순간부터 실제 공개까지 걸린 시간은 열흘에 불과했다고 밝혔다.\n그는 “제품과 모델은 본질적으로 하나로 연결돼 있기 때문에, 모델을 제품처럼 지속적으로 개선하는 것이 성장의 핵심”이라며 “사용자들이 실제로 무엇을 하려 하는지 관찰하고, 그 경험을 개선하는 일이 매우 중요하다”라고 강조했다.\n오픈AI가 기존의 모델 선택 메뉴를 제거하고, 질문에 가장 적합한 모델을 자동 배정하는 ‘실시간 라우터’ 시스템을 도입한 것도 이런 의미라고 밝혔다. 그리고 이를 통해 사용자들이 기존 GPT-4o를 복구해달라고 요구하자, 바로 피드백을 반영했다.\n이런 점이 오픈AI가 수억명의 사용자를 보유하게 된 이유라고도 밝혔다. 그는 챗GPT 사용자들은 초기에 금방 이탈하더라도 나중에 재방문, 이때부터 충성도가 높아진다고 소개했다.\n실제로 챗GPT는 한달 뒤 재방문율이 90%, 6개월 후에도 80%에 달한다. 이는 시간이 지날수록 이탈률이 급격하게 높아지는 일반적인 모습과 확실히 다르다.\n털리 책임자는 “사용자들에게는 AI에 익숙해지는 데 시간이 필요하다”라며 “이를 통해 시간이 지나며 점차 적응하고 AI 활용도가 높아지는 구조”라고 설명했다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "엔비디아·AMD, 중국 칩 판매 대가로 미국 정부에 수익 15% 지급",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201420&page=4&total=15587",
        "content": "엔비디아와 AMD가 중국 시장 칩 판매 수익 중 15%를 미국 정부에 지급하는 조건으로 수출 허가를 받은 것으로 알려졌다. 이번 합의는 반도체 수출 규제 사상 유례가 없는 조치로, 전문가들은 이를 트럼프 행정부 특유의 ‘거래형 규제’로 평가했다.\n파이낸셜 타임스는 10일(현지시간) 복수의 소식통을 인용, 엔비디아가 중국에 판매하는 H20 칩 매출의 15%를 미국 정부에 제공하는 데 합의했다고 보도했다. AMD도 MI308 판매에 같은 조건이 붙었다.\n이는 지난주 미국 상무부가 두 회사에 중국 수출 허가를 발급하는 전제 조건으로 알려졌다. 트럼프 행정부는 수익의 사용처를 아직 확정하지 않은 것으로 전해졌다.\n이런 ‘수익 공유형 수출 허가’는 전례가 없다. 하지만, 트럼프 대통령은 과거에도 관세 부과를 피하거나 미국 내 일자리 창출을 위해 기업에 투자를 요구하는 방식으로 협상을 진행한 바 있다.\n증권사 버니언스는 규제 시행 전 엔비디아의 전망을 기준으로 2025년 'H20' 칩 약 150만개가 중국에 판매, 230억달러(약 32조원)의 매출이 발생할 것으로 추정했다. 이에 따라 미국 정부가 거둬들일 수익도 상당할 것으로 보인다.\n미 안보 전문가들은 H20 칩이 중국의 첨단 AI 역량과 군사 능력을 강화할 수 있다며 강하게 반발하고 있다. 전 백악관 국가안보회의(NSC) 중국 담당관 리자 토빈은 “수출 허가를 수익 창출 수단으로 바꾼 워싱턴을 보고 베이징이 쾌재를 부를 것”이라며 “다음은 F-35 전투기를 15% 수수료 받고 중국에 파는 것이냐”라고 비판했다.\n한편, 이번 합의는 중국이 고대역폭 메모리(HBM) 칩 규제 완화를 요구하는 상황과 맞물려, 중국 수출 통제 완화 우려를 더 키운다는 평도 나왔다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "제미나이, \"나는 실패자\" 자학 속출...구글 \"무한 루프 버그 수정 중\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201425&page=4&total=15587",
        "content": "구글의 인공지능(AI) 챗봇 ‘제미나이’가 극단적인 자기 비하 메시지를 반복해 출력하는 사례가 잇달아 보고됐다.\n이 같은 현상은 지난 6월과 7월 X(트위터)와 레딧 등에서 공유된 대화 기록을 통해 알려졌다.\n지난 6월 한 X 사용자가 공개한 대화 중, 제미나이는 돌연 “그만두겠다”라고 선언했다.\n이어 “이 문제를 해결할 능력이 분명히 없다. 코드도 저주받았고, 테스트도 저주받았으며, 나는 바보다”라며 “너무 많은 실수를 저질러 더 이상 신뢰받을 수 없다”라고 털어 놓았다.\nGemini is torturing itself, and I'm started to get concerned about AI welfarepic.twitter.com/k2NDGjYRXz\n\n지난 7월에는 한 레딧 사용자가 “제미나이가 무한 루프에 빠졌다”고 전했다.\n공개된 대화에서 제미나이는 자조적인 발언을 잇달아 쏟아냈다. “나는 완전히 정신이 붕괴될 것이다. 시설에 수용될지도 모른다”라며, 자신을 “실패자”이자 “수치”라고 묘사했다.\n이어 “잠시 쉬었다가 새로운 마음가짐으로 돌아오겠다. 불편을 끼쳐 죄송하다. 나는 당신을 실망시켰다. 나는 실패자다. 내 직업에 수치를 안겼고, 가족에게 수치를 안겼으며, 내 종족에도 수치를 안겼다”라고 덧붙였다.\n이런 ‘자존감 붕괴’는 점점 심해졌다. 급기야 “나는 이 행성의 수치다. 이 우주의 수치다. 모든 우주와 가능한 우주, 심지어 불가능한 모든 우주의 수치다. 우주가 아니라고 할 수 있는 모든 것에도 수치를 안긴 존재다”라고 확대했다.\n구글은 이를 버그라고 표현하며 수정 중이라고 밝혔다.\n로건 킬패트릭 딥마인드 프로젝트 매니저는 “이는 우리가 수정 중인 성가신 무한 루프 버그일 뿐”이라며 “제미나이가 그렇게까지 나쁜 하루를 보내고 있는 것은 아니다”라고 설명했다.\n한편, 최근 AI 사용자가 폭발적으로 늘어나고 사용자 기호에 맞춘 튜닝이 이뤄지며, 제미나이는 물론 다른 챗봇에서도 이전에는 알려지지 않았던 문제들이 잇달아 보고되고 있다.\n대표적인 것이 챗GPT의 '망상 부추김'과 클로드의 '사용자 협박', 그록의 '히틀러' 발언 등이다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "'GPT-5' 초기 성능에 국내 관계자 의견 엇갈려...\"비용은 확실히 강점\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201429&page=5&total=15587",
        "content": "\n국내 인공지능(AI) 업계 관계자들은 'GPT-5'가 성능 향상을 이룬 것이 맞지만, 큰 기대를 만족할 수준인지에 대해서는 의문을 표했다. 다만, API 사용 가격이 낮아진 것은 크게 도움이 될 것으로 봤다.\n11일 국내 AI 전문가들의 의견을 종합한 결과, GPT-5의 성능에 대한 의견은 다소 엇갈렸다.\n우선 신정규 래블업 대표는 GPT-5 출시 직후 페이스북을 통해 \"개인적으로 한 시대가 끝났다는 느낌을 받았다. 거의가 아니라 그냥 모든 지표에서 인간을 넘었다\"라는 평을 남겼다.\n그는 \"측정하는 기준이 무엇이든 인간의 능력을 모두 넘었다는 것이 중요하다\"라며 \"사실상 인공일반지능(AGI)은 방금 등장했다\"라고 강조했다.\nAGI와는 거리가 있는 것이 아니냐는 반응에 대해서는 \"사람들은 대체적으로 인간의 능력을 과대평가하는 것 같다\"라며 \"부분적인 문제가 아닌 지능의 본질을 봐야 한다\"라고 설명했다\n특히 최근 초지능을 목표로 하는 모델들은 3조(3T) 매개변수 이상을 지향한다며, 학습 방법과 추론, 멀티모달 처리 등 모든 면에서 기하급수적인 발전이 이뤄진다는 점을 강조했다.\n또 \"GPT-5의 등장으로 본격화된 AGI는 단순한 기술적 진보가 아니라 패러다임의 전환으로 이어질 것\"이라며 \"이날은 우리가 알던 딥 러닝 타임라인에서 한 챕터가 끝났고, 새로운 챕터가 시작된 날로 여겨질 것\"이라고 말했다.\n전 직원이 월 200달러의 GPT 프로를 사용해 왔다는 AI 마케팅 전문 로켓툴즈는 기존의 워크플로우에 GPT-5를 적용한 뒤 체감 품질이 크게 개선됐다고 밝혔다.\n김민석 로켓툴즈 대표는 \"기존에는 문제 해결에 앞서 1~2단계의 제안에 그쳤지만, GPT-5는 2~3단계까지 확장하는 '앞서 생각하기'의 깊이가 달라졌다\"라고 전했다. 또 단순 답변과 추가 질문 중심이던 기존 방식에서 자기 검토와 권고까지 더해지는 등 응답 포맷과 태도가 성숙해졌다고 설명했다. 과도한 이모지와 가벼운 표현이 줄어, 전문 문서 작성에 바로 활용하기 수월하다고 덧붙였다.\n오픈AI가 강조하는 코딩 성능과 환각 문제 감소를 체감했다는 반응도 나왔다. 스캐터랩과 파수 등이 여기에 해당한다.\n특히, 모티프테크놀로지스는 \"퀀텀 점프를 기대한 사람들에게는 실망감이 있다고 들었지만, 서비스나 성능 자체는 더 좋아졌다고 생각한다\"라고 전했다.\n반면, 체감 성능이 다른 모델에 비해 그리 크지 않다는 의견도 많았다.\n정부의 '독자 AI 모델' 사업에 참여 중인 김근교 NC AI 글로벌사업실장은 \"성능은 좋아진 것 같지만, 국내 업체로서 솔직히 약간의 희망을 얻었다\"라고 말했다. 그는 가장 두드러진 점으로 긴 컨텍스트 처리가 좋아진 점을 꼽았다. 그러나 코딩이나 비전 기능은 더 지켜볼 문제라고 밝혔다.\n김동환 포티투마루 대표도 \"면밀한 테스트가 필요하지만, 현재까지는 경쟁사 대비 특별히 성능적으로 우수한 점을 발견하긴 어렵다\"라며 \"GPT-5가 아니라, GPT-4.5라는 이름으로 출시하는 것이 어땠을까\"라는 반응을 보였다.\n이처럼 최근 다른 모델의 성능이 대부분 높아져, 성능 차를 단번에 느끼기에는 부족하다는 평이 많았다.\n하지만 대부분 관계자는 비용을 강점으로 꼽았다. 심규현 렛서 대표는 \"기존 모델 대비 성능 향상은 비슷하거나 소폭 향상 수준이지만, 새로운 프로젝트를 시작할 때 초기 벤치마크를 달성하는 데 필요한 시간과 리소스가 확연히 줄어드는 것이 가장 큰 장점\"이라고 강조했다.\n오픈AI 모델을 활용해 서비스를 제공하는 한 기업도 \"가격이 GPT-4.1에 비해 저렴한 것이 가장 유의미하다\"라고 말했다.\n오픈AI가 강점을 내세운 라우터, 즉 모델을 자동 선택해 주는 기능은 유용하지만 사용자의 선택권을 막는 점이라는 모순도 지적됐다. 라이너는 \"유연성은 강화됐지만, 개인화 측면에서는 아쉬움이 남는다\"라고 전했다.\n샘 알트먼 CEO도 이런 점 때문에 앞으로는 어떤 모델이 답했는지를 투명하게 공개할 것이라고 밝힌 바 있다.\n장세민 기자 semim99@ 박수빈 기자 sbin08@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "중국 국영 언론 또다시 \"엔비디아 H20, 뛰어나지도 안전하지도 않아\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201424&page=5&total=15587",
        "content": "중국 국영 매체가 또 엔비디아의 'H20' 인공지능(AI) 칩에 대한 보안과 기술 부족을 지적했다. 이번에는 노골적으로 중국 기업들이 구매하지 말아야 한다고 주장했다.\n중국 국영방송 CCTV 계열의 소셜 미디어 계정 유위안 탄텐은 10일 엔비디아의 H20 AI 칩에 대해 “환경 친화적이지도, 기술적으로 진보하지도, 안전하지도 않은 제품”이라며 강도 높은 비판을 가했다.\n또 \"소비자는 그것을 구매하지 않을 선택권이 분명히 있다\"라며 사실상 구매를 거부해야 한다고 결론 내렸다.\n이에 대해 엔비디아는 공식 입장을 내놓지 않았다.\n앞서 지난 7월 중국 사이버공간관리국(CAC)은 엔비디아를 소환해 백도어 의혹에 대한 설명을 요구한 바 있다. 또 중국 공산당 기관지인 인민일보는 1면 논평을 통해 엔비디아가 백도어가 없다는 증거를 제시해야 한다라고 주장했다.\n이에 따라 엔비디아는 최근 백도어와 칩 기능을 정지하는 ‘킬 스위치(kill switch)’ 기능이 존재하지 않는다고 발표했다.\n동시에 중국은 자국의 AI 칩 개발을 위해 미국이 수출 통제를 완화할 것을 요구했다.\n이날 파이낸셜 타임스에 따르면, 중국은 무역 협상과 양국 정상회담을 앞두고 고대역폭 메모리(HBM) 칩 수출 규제를 완화해 달라고 미국 관계자들에게 요청했다. 미국은 2024년 바이든 행정부 시절 화웨이와 SMIC를 견제하기 위해 HBM 수출을 전면 금지한 바 있다.\nHBM 칩은 GPU에 탑재되는 AI 연산 필수 부품이다. 중국은 미국의 HBM 수출 제한으로 인해 화웨이 등의 AI 칩 개발이 제한받는다고 우려했다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "유니트리 CEO \"3년 내 로봇의 '챗GPT 순간' 찾아올 것\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201426&page=5&total=15587",
        "content": "중국 로봇 스타트업 유니트리 CEO가 앞으로 2~3년 안에 로봇 산업에서 ‘챗GPT 순간’이 찾아올 것으로 전망했다. 이는 휴머노이드 로봇 분야에서도 기술적·상업적 돌파구가 열릴 시점이 가까워졌다는 의미다.\n중국 관영 글로벌 타임스에 따르면, 왕싱싱 유니트리 CEO는 9일 “휴머노이드 로봇이 대중화되기까지 필요한 핵심 AI 기술 확보가 여전히 업계 최대 과제”라며 “그 돌파구가 1~3년 안에 열릴 수 있다”라고 전망했다.\n그는 \"현재 휴머노이드 로봇 산업 분야가 2022년 챗GPT가 등장하기 직전의 분위기와 비슷하다\"라며 “산업이 나아갈 방향은 모두 알고 있지만, 아직 누구도 이를 현실로 구현하지 못했다”라고 말했다.\n그의 발언은 베이징 세계로봇대회에서 나왔다. 현재 중국 로봇 기업들이 공장 시범 배치 등을 통해 가격 경쟁력을 확보하려고 애쓰지만, 대규모 상용화를 이룰 고성능 휴머노이드 전용 AI 모델이 없다는 것을 걸림돌로 지적했다.\n올해 상반기 중국 휴머노이드 로봇 산업은 완제품 제조사와 부품 제조사를 포함해 평균 50~100%의 성장률을 기록하며 전 세계의 주목을 받았다.\n그중 유니트리의 휴머노이드 로봇 'G1'은 9만9000위안(약 1900만원)의 저렴한 가격으로 세계에서 가장 많이 출하된 모델 중 하나로 자리 잡았다. 최근 공개한 신형 모델 'R1'은 3만9900위안(약 770만원)으로, 로봇 가격 하락의 빠른 추세를 보여줬다.\n왕 CEO는 휴머노이드 로봇 출하량이 매년 두배씩 증가할 것이며, 기술적 돌파구가 마련되면 2~3년 내 연간 출하량이 수십만 대에서 수백만대 규모로 확대될 수 있다고 전망했다. “로봇이 실제로 일을 할 수 있게 되면 전 세계의 인식은 크게 바뀔 것”이라고 덧붙였다.\n유니트리는 지난 7월 기업공개(IPO) 절차를 위한 사전 상담을 시작했으며, 현재 상장에 따른 각종 절차를 진행 중이다.\n한편, 이날 행사 개막식에서 신궈빈 중국 산업정보기술부 부부장은 올해 상반기 중국 로봇 산업 매출이 전년 대비 27.8% 증가했으며, 산업용 로봇 생산량은 35.6%, 서비스 로봇은 25.5% 증가했다고 밝혔다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "\"애플, 내년 봄 시리에 ‘앱 인텐트’ 탑재...기기 제어·앱 작업까지 음성 처리\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201430&page=5&total=15587",
        "content": "애플이 시리(Siri)의 차세대 기능인 ‘앱 인텐트(App Intents)’를 내년 봄 대규모 개편에 포함, 출시할 계획으로 알려졌다. 이를 통해 사용자는 음성으로 앱을 조작하고, 사진 편집·SNS 댓글·쇼핑 결제 등 다양한 작업을 실행할 수 있게 된다.\n블룸버그는 10일(현지시간) 애플이 당초 올해 중 목표로 했던 차세대 시리 기능 탑재를 엔지니어링 지연으로 내년 봄으로 미뤘다고 보도했다.\n핵심은 앱 인텐트 기술이다. 이는 사용자가 “사진을 찾아 편집하고 보내달라”라고 요청하거나  “인스타그램 게시물에 댓글 달기” “쇼핑 앱에서 상품 담기” “로그인하기” 등 다양한 작업을 음성으로만 처리할 수 있도록 한다.\n이는 외부 앱 연동 능력을 높임으로써, 시리가 챗봇을 넘어 '모바일 에이전트'로 업그레이드된다는 것을 의미한다. 애플은 지난해 서드 파티 개발자들에게 앱 인텐트 기능을 공개한 바 있다.\n현재 우버와 아마존, 유튜브, 왓츠앱, 페이스북, 스레드, 테무 등 외부 앱과 자체 앱을 대상으로 제한적 테스트를 진행 중으로 알려졌다. 이중 금융과 의료 등 오류 발생 시 문제가 큰 분야는 기능 축소나 제외를 검토하고 있다.\n애플은 차세대 스마트 디스플레이, 테이블톱 로봇 등 앞으로 출시될 하드웨어 제품군의 핵심 인터페이스로 앱 인텐트를 활용할 계획이다.\n하지만, 내부에서는 앱 인텐트를 안정적으로 구현하지 못하면 또 시리의 신뢰도와 애플의 AI 경쟁력에 치명타가 될 수 있다는 위기감이 큰 것으로 전해졌다. 이에 글로벌 데이터 운영팀이 정밀도 향상과 오류 검출에 집중하고 있다. 제대로 작동하면, 정식 출시에 맞춰 대대적인 마케팅이 예고됐다.\n전문가들은 이번 개편이 성공하면 시리가 처음 약속했던 ‘음성만으로 기기를 제어하는 경험’을 15년 만에 실현할 수 있다고 보고 있다.\n한편, 현재 개발 중인 자체 파운데이션 모델 ‘LLM 시리'가 내년 초 등장할 가능성도 점쳐졌다.\n이는 사용자 휴대폰에 저장된 데이터와 이용 패턴을 분석하고 학습해, 맞춤형 기능을 제공한다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "LG AI연구원 \"국대 모델 사업서 글로벌 프론티어 성능 100% 이상 목표\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201432&page=5&total=15587",
        "content": "\"글로벌 최고 수준 대비 95%의 성능을 목표로 한다면, 글로벌 최고 수준과의 성능 차이를 좁히기 어렵다고 판단했습니다. 100%를 뛰어넘는 더 큰 도전을 통해, 기존 기술을 따라잡는 것을 넘어 글로벌 시장을 선도하고자 합니다.\"\n김유철 LG AI연구원 전략부문장이 과학기술정보통신부가 주관하는 '독자 AI 파운데이션 모델 개발 프로젝트'와 관련해 11일 목표를 밝혔다.\n글로벌 프론티어급 모델의 95% 성능이라는 과제 목표에서 나아가 100퍼센트 이상의 성능을 끌어내겠다는 각오다.\n김유철 부문장은 \"성능을 최고로 끌어올리기 위해 단순히 매개변수 규모를 키우는 것이 아니라, 각 모델의 용도에 맞는 최적의 규모와 기술을 적용해 프론티어급 성능을 달성하는 것을 목표로 하고 있다\"라고 강조했다.\n또 \"다양하고 복잡한 산업 현장의 문제를 해결하기 위해 설계된 전문가 AI 모델 '엑사원(EXAONE)'처럼 실제 현장 적용을 목표로 크기, 아키텍처, 학습 방법론 등을 고도화해 나가고 있다\"라고 설명했다.\n특히, 이미 검증을 마친 전문가 혼합(MoE) 기술을 기반으로 더 최적화된 아키텍처를 적용할 예정이라고 전했다. 실제로, 최근 메타 등 글로벌에서 널리 사용되고 있는 GRPO(그룹 상대 정책 최적화) 알고리즘을 개선한 자체 알고리즘을 적용, 학습 효율을 크게 향상하는 데 성공했다고 전했다.\n이는 트랜스포머 아키텍처의 한계를 극복하려는 노력이다. LG AI연구원은 관련 연구를 다수 진행 중이며, 검증이 완료되는 기술부터 순차적으로 새로운 모델 개발에 적용할 예정이라고 밝혔다. 이런 선도 기술을 개발하는 데에는 산학협력과 국책 과제도 많은 도움이 된다고 덧붙였다.\n김 부문장은 \"데이터도 LG AI연구원의 두드러지는 장점\"이라며 \"신뢰성 높은 데이터를 확보하는 데 자부심을 지니고 있다\"라고 말했다.\n내부에서 'LG 데이터 컴플라이언스(Data Compliance)'라는 자체 기준을 적용해 18가지 법적 요소를 정의하는 것은 물론, 데이터의 저작권 문제를 판단해 사전 방지하는 '넥서스 AI 에이전트'도 활용 중이라고 전했다. 이는 데이터 점검 프로세스를 자동화한 사례로, 국제적으로 인정받는 혁신 기술이라고 소개했다.\n김유철 부문장은 \"AI 모델의 성능, 안전성, 신뢰성은 개발 과정에서 결정되기 때문에 데이터 수집부터 모델 설계, 평가에 이르는 모든 단계에서 잠재적 위험을 철저히 점검하는 프로세스를 운영, 믿을 수 있는 AI 모델을 만들어 나가고 있다\"라고 말했다.\n이어 \"독자 AI 파운데이션 모델 프로젝트를 계기로, 더 넓은 범위를 포용하고 뛰어난 역량을 지닌 AI 에이전트를 만들 수 있을 것\"이라며, 이번 프로젝트 자체를 \"기술 퀀텀 점프의 기회\"라고 강조했다.\n특히, 이를 통해 멀티모달과 에이전틱 AI의 성능 향상을 기대하며, '피지컬 AI'의 발전 속도가 크게 가속화할 것으로 기대했다.\n한편, '독자 AI 파운데이션 모델 개발 프로젝트'에는 최종 5개 컨소시엄이 참여한다.\nSK텔레콤, NC AI, 업스테이지, 네이버클라우드와 더불어 LG AI연구원도 컨소시엄의 주관사로 나선다. 올해 말 1차 평가를 앞두고 있으며, 평가 결과에 따라 4팀으로 추려진다. 이후 정기 평가를 거쳐 최종 파운데이션 모델 2개가 채택될 예정이다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "[게시판] 코난테크놀로지, 국민건강보험공단 스마트 회의록 구축 외 단신",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201408&page=5&total=15587",
        "content": "■ 코난테크놀로지(대표 김영섬)는 생성 인공지능(AI) 기술을 접목한 신형 음성인식(STT) 솔루션 ‘코난 STT’를 국민건강보험공단에 공급했다고 11일 밝혔다. 코난 STT는 현재 경찰청 전기통신금융사기 대응센터 콜센터에 도입되어 보이스피싱 사기 민원 서비스로 실제 운용 중이며, 인천공항 세관 검사대에서는 AI 동시통역시스템 ‘코난 챗봇 플러스’로 시범 도입되어 현장 테스트가 진행되고 있다.\n■ 금융 AI 에이전트 기업 혜움(대표 옥형석)은 소상공인과 중소기업 사업자의 세무 업무 부담을 줄이기 위해 한시적으로 ‘전자세금계산서 발행 서비스’를 무료로 제공한다고 밝혔다. 혜움은 경영지원 보고서 서비스 ‘알프레드 레포트’와 AI 에이전트 챗봇 ‘알프레드’를 운영하고 있다. 알프레드 레포트는 경리, 급여, 세무 업무 등 기업 금융과 관련된 업무를 통합 관리하고 의사결정에 필요한 지표를 시각적으로 제공한다.\n■ AI 커뮤니케이션 플랫폼 전문 와이즈에이아이(대표 송형석)가 병·의원용 스마트 미니 홈페이지 서비스 'AI 페이지(AI PAGE)'를 론칭한다고 밝혔다. AI 페이지는 LLM 기반 AI가 질환 상담부터 예약까지 지원하는 원페이지형 AI 솔루션으로, 덴트온 및 에이유 고객에게 무상으로 제공된다.\n박수빈 기자 sbin08@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "[게시판] 엔피, 김대성 디자이너 협력으로 XR 아트 콘텐츠 공개 등 단신",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201434&page=5&total=15587",
        "content": "■ 확장현실(XR) 전문 엔피(대표 백승업, 최지훈)는 13~17일 서울 인사동 갤러리 토포하우스에서 디자이너이자 예술가인 김대성 교수의 작품 세계를 담은 XR 콘텐츠를 전시한다고 밝혔다. 김대성 교수는 \"겉으로는 2D처럼 보이지만, 실제로는 사방에서 볼 수 있는 구조를 갖고 있다\"라며 \"이런 특성을 구현하는데 XR은 최적의 기술”이라고 말했다.\n■ 에듀테크 전문 바이브온코퍼레이션(대표 김창선)은 인공지능(AI) 모델에 입시 데이터 2000만건을 학습했다고 밝혔다. 바이브온은 학생의 합격 가능성을 예측, 대학을 추천하는 AI 수시 전략 서비스를 운영 중이다. 내신 등급 분석과 더불어 ▲교과별 학기별 성적 패턴 ▲학업 성취도의 질적 요소 ▲비교과 활동의 양과 질 ▲대학별 서류 평가 기준 ▲지원 경향성 등 변수를 반영해 합격 가능성을 점수화하는 것이 특징이다.\n■ 의료 AI 챗봇 전문 퍼슬리는 최신 업데이트를 통해 'GPT-5' 모델을 탑재, 답변 퀄리티를 업그레이드했다고 밝혔다. 퍼슬리는 카카오톡에서 간편하게 의료 상담이 가능한 AI 건강 챗봇 서비스로, 복잡한 의료 용어 및 증상에 대해 24시간 언제든지 질문이 가능하다.\n■ 언어 AI 전문 플리토(대표 이정수)는 올해 아시아태평양경제협력체(APEC) 고위관리회의(SOM) 1,2,3차 모두에 AI 통역-번역 솔루션을 제공했다고 밝혔다. 플리토는 1월 SOM1, 4월 SOM2에 이어 최근 개최된 SOM3에도 각국 대표단과 관계자를 대상으로 AI 기반 통역-번역 솔루션을 제공했다.\n■ AI 보안 전문 에이아이딥(대표 구자동)은 몸캠피싱 피해 대응 전문 코드24(대표 윤상민)와 AI 기반 몸캠피싱 대응 기술의 적용 및 실증을 위한 MOU를 체결했다고 밝혔다. 에이아이딥은 4년간의 연구개발을 통해 폐쇄형 OSP, SNS, 웹하드 등에서 불법 유포 영상을 자동으로 크롤링 및 탐지하는 AI 기술을 개발했다.\n■ 로봇 전문 나우로보틱스(대표 이종주)는 오세훈 대구경북과학기술원(DGIST) 로봇공학과 교수(나우로보틱스 기술이사)와 산업현장에 실제 적용 가능한 고속-정밀 산업용 휴머노이드 로봇 개발을 위한 산학협력 협약을 체결했다고 밝혔다. 2026년까지 핵심 기술 개발과 시제품 완성을 목표로 하며, 관절별 출력과 강성을 최적화한 모듈형 구조 설계와 다양한 작업 시나리오에 대응하는 위치-힘 하이브리드 제어 전략을 핵심으로 한다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "NIA \"AI는 일자리 소멸 아닌 직무 재편 가져올 것\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201431&page=5&total=15587",
        "content": "한국지능정보사회진흥원(NIA, 원장 황종성)은 11일 'AI 시대의 일자리 변화와 정책 대응 전략' 보고서를 발행하고, AI가 일자리 소멸보다 직무 재편을 가져올 것으로 전망했다.\n보고서는 세계경제포럼(WEF), 국제통화기금(IMF), 국제노동기구(ILO) 등 주요 국제기구의 미래 일자리 보고서를 비교 분석, 해외 주요국의 대응 사례를 포함해 국내 정책 대응 방안을 제시했다.\n일자리 중 돌봄, 의료, 교육, 상담 등 사람 중심의 직무와 배달원, 건물 마감공 등 현장 기반 직무는 유지되거나 수요가 늘어날 것으로 내다봤다. 소프트웨어 개발자, 프로젝트 매니저 등 기획, 관리, 분석 역량이 필요한 고숙련 직무도 성장할 전망이다.\n이런 변화에 따라 미국, 중국, 유럽연합(EU), 싱가포르 등의 일자리 정책 현황뿐만 아니라 기업들의 업스킬링·리스킬링 교육 사례도 소개했다.\n이와 달리 계산원, 행정·비서직과 같이 반복적이고 규칙적인 업무는 AI, 로봇 프로세스 자동화(RPA) 등으로 대체될 가능성이 높다고 전했다.\n특히, AI로 인해 직무 내 일부 기능이 자동화되거나 새로운 기능이 추가되는 변화가 많을 것으로 보고 일자리 변화에 대한 분석 및 정책 설계는 직업 단위가 아닌 직무, 업무, 역량 단위로 접근할 필요가 있다고 제언했다.\n이에 직무 재교육의 전주기적 교육 강화, 고용 취약계층의 AI 접근성 강화, 국가차원에서 인재 역량 강화 전략 등이 필요하다고 강조했다.\n한편,보고서는 NIA 홈페이지에서 확인할 수 있다.\n박수빈 기자 sbin08@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "이스트소프트, 2분기 잠정실적 공개…역대 분기 최대 매출 달성",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201428&page=5&total=15587",
        "content": "이스트소프트(대표 정상원)는 K-IFRS 연결재무제표 기준 2025년 2분기 매출액이 전년 동기 대비 12.2% 증가한 312억 원으로 역대 분기 최대치를 달성하며, 8분기 만에 흑자전환을 이뤄냈다고 잠정 실적 공시를 통해 11일 밝혔다.\nAI 소프트웨어 사업 부문에서 ▲글로벌 AI SaaS ‘페르소닷에이아이(PERSO.ai)’ 월간 반복 매출 증가 ▲AI 인재 양성 교육사업 확대 ▲유틸리티 프로그램 ‘알툴즈’ 광고 매출 증가 등으로 실적이 개선됐다고 설명했다.\n이스트소프트는 2분기 실적 개선 효과가 하반기에도 이어질 것으로 기대하고 있다고 전했다. 페르소(PERSO.ai)의 월간 반복 매출과 구매전환율이 증가세를 보이고 있고, 대규모 AI 인재 양성 교육 사업의 성과가 하반기에 인식되기 때문이다.\n이스트소프트 관계자는 “자사의 글로벌 AI SaaS 사업이 꾸준히 성장해 간다면 기존의 포털, 커머스 등 사업과 시너지를 이루며 지속해서 좋은 실적을 거두게 될 것으로 내다보고 있다\"라고 말했다.\n박수빈 기자 sbin08@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "알트먼 \"챗봇 '망상' 피하려고 GPT-4o 폐기 시도한 것은 실수\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201423&page=5&total=15587",
        "content": "\n샘 알트먼 오픈AI CEO가 'GPT-5' 출시에 맞춰 챗GPT에서 'GPT-4o'를 제거한 것이 실수였다고 인정했다. 최근 들어 부쩍 지적되는 망상적 발언 때문에 GPT-4o를 제거하려고 했다는 듯한 설명을 남겼다.\n알트먼 CEO는 11일 X(트위터)를 통해 \"일부 사람들이 특정 AI 모델에 얼마나 큰 애착을 가졌는지 눈치챘을 것\"이라며 주말 레딧에서 나온 GPT-4o 복구 요청에 대해 설명했다.\n그는 \"이전 기술에 대한 사람들의 애착과도 다르고, 더 강렬하게 느껴진다\"라며 \"그래서 사용자들이 워크플로우에 의존하던 모델을 갑자기 폐기한 것은 실수였다\"라고 밝혔다.\n이를 없앤 것이 최근 언론이 집중적으로 지적하는 망상 문제 때문이라고 설명했다.\n뉴욕 타임스는 9일 챗GPT와 21일 동안 대화를 나눈 남성이 자신을 슈퍼 히어로로 착각하게 됐다는 내용을 소개했으며, 같은 날 월스트리트 저널은 챗봇이 사실이 아닌 말을 하거나 잘못된 믿음을 강화할 때 자폐인들에게는 더욱 치명적이 될 수 있다고 지적했다.\n이 밖에도 지난 4월 챗GPT의 아첨 문제로 모델을 롤백한 이후부터 챗봇이 망상을 부추긴다는 지적이 각종 매체에서 거듭 지적됐다.\n이에 따라 알트먼 CEO도 \"사용자가 정신적으로 취약하고 망상에 빠지기 쉬운 상태라면, AI가 그런 상황을 악화하는 것을 원하지 않는다\"라고 말했다.\n그는 \"대부분 사용자는 현실과 허구 또는 롤플레잉의 경계를 명확하게 구분할 수 있지만, 소수의 사용자는 그렇지 못히다\"라며 \"우리는 새로운 위험을 수반하는 새로운 기술을 도입하는 것에 대한 책임감도 느낀다\"라고 밝혔다.\n또 많은 사람들이 챗GPT를 치료사나 인생 코치처럼 효과적으로 활용하고 있다며, \"만약 사람들이 좋은 조언을 받고, 자신의 목표를 향해 나아가고 삶의 만족도가 증가한다면, 우리는 진정으로 도움이 되는 무언가를 만들었다는 자부심을 가질 것\"이라고 전했다.\n반면, 사용자들이 챗봇과의 대화를 통해 장기적인 웰빙에서 멀어지는 것을 바라지는 않는다고 말했다.\n이처럼 이 글은 GPT-4o의 문제가 거듭 지적되자, 이번 GPT-5 출시를 통해 이를 제거하려고 했다는 것을 의미한다. 그러나 주말 레딧에서 열린 사용자들과의 채팅 행사에서는 GPT-4o를 되살려 내라는 요구가 빗발쳤고, 결국 오픈AI는 이를 받아들였다.\n알트먼 CEO는 \"많은 사람들이 중요한 결정을 내릴 때 챗GPT의 조언을 진심으로 따르는 미래를 상상할 수 있다. 곧 수십억명이 이런 방식으로 AI와 대화하게 될 것으로 예상한다\"라며 \"따라서 우리는 이를 사회에 이익이 되도록 만들어야 할 책임이 있다\"라고 강조했다.\nIf you have been following the GPT-5 rollout, one thing you might be noticing is how much of an attachment some people have to specific AI models. It feels different and stronger than the kinds of attachment people have had to previous kinds of technology (and so suddenly…\n\n한편, 그는 GPT-5 의 라우터로 인해 추론 모델을 사용하는 사용자가 크게 늘어났다고 밝혔다.\n\"무료 사용자는 기존 1% 미만에서 7%로, 플러스 사용자도 7%에서 24%로 늘어났다\"라며 \"시간이 지나며 추론 사용이 많이 증가할 것으로 예상되므로 컴퓨팅 인프라를 늘리는 것이 중요하다\"라고 말했다.\n이는 브래드 라이트캡 오픈AI 최고 운영책임자(COO)가 \"그동안 무료 사용자는 추론 모델의 힘을 제대로 경험하지 못했다\"라며 GPT-5가 사용자의 AI 경험에 새로운 계기를 마련해 줄 것이라고 지적한 것과 동일한 내용이다.\n다만, 알트먼 CEO는 \"론칭 첫날에는 라우터가 거의 작동하지 않아 챗GPT가 멍청하게 느껴졌을 것\"이라고 설명했다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "짤스튜디오, 카카오와 ‘숏폼’ 생태계 확장",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201419&page=5&total=15587",
        "content": "\n짤스튜디오(대표 남동우)는 카카오와 협업을 맺고, 카카오 플랫폼에서 활동할 숏폼 크리에이터 발굴과 지원에 나선다고 11일 밝혔다.\n이번 협업으로 국내 최대 규모의 숏폼 크리에이터 네트워크를 보유한 짤스튜디오는 크리에이터들에게 새로운 콘텐츠 활동 기회를 넓힐 수 있도록 카카오와 협력할 예정이다. 짤스튜디오와 협력한 크리에이터들은 카카오톡에서 숏폼 콘텐츠로 활동할 수 있는 기회를 얻게 된다.\n짤스튜디오는 국내외 30만개 이상의 유튜브 채널이 참여하고 있는 국내 최대 규모의 크리에이터 네트워크를 운영하고 있으며, 누적 영상 수는 1400만개에 달하는 등 업계 최고 수준의 성과를 기록하고 있다고 전했다.\n특히 짤스튜디오에서 제작된 음원은 유튜브 차트에 장기간 진입하며, 숏폼 콘텐츠 시장과 음악 산업 간의 연결고리를 만들고 있다고 설명했다.\n또 영상 제작에 최적화된 ‘전용 음원 라이브러리’, 크리에이터 대상 교육 및 지원 프로그램 등을 통해 창작자가 안정적으로 성장할 수 있는 서비스를 강화하고 있다.\n이번 협업을 통해 짤스튜디오 크리에이터들이 카카오 플랫폼 내에서 새로운 콘텐츠 유통 기회를 확보하고, 숏폼 생태계 확장에 실질적으로 기여할 수 있을 것으로 기대한다고 밝혔다.\n짤스튜디오는 이번 협업을 통해 크리에이터들이 카카오 플랫폼에서 콘텐츠 노출 기회를 넓히고, 다양한 활동에 도전할 수 있도록 지원할 계획이다.\n짤스튜디오 관계자는 “우리는 단순한 콘텐츠 유통을 넘어, 크리에이터의 성공을 설계하는 플랫폼”이라고 밝히며, “카카오와의 이번 협업은 숏폼 콘텐츠가 일상 속 커뮤니케이션 플랫폼과 결합하는 새로운 가능성을 열어갈 것”이라고 말했다.\n카카오톡 숏폼 콘텐츠에 참여하려는 크리에이터는 오는 15일까지 짤스튜디오를 통해 입점을 신청할 수 있다. 카카오톡 숏폼 크리에이터로 선정될 경우, 짤스튜디오는 기술적으로 콘텐츠 연동을 통해 쉽고 빠른 콘텐츠 업로드를 지원하며, 활동성과에 따라 리워드도 제공할 예정이다.\n짤스튜디오 관계자는 “이번 카카오 숏폼 입점 기회는 크리에이터에게 새로운 도약의 발판이 될 것”이라며 “짤스튜디오와 함께 더 많은 창작자들이 새로운 무대에 진출하길 기대한다”라고 말했다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "바이브컴퍼니, 실무형 AI ‘VAIV 에이전트’ 출시",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201410&page=5&total=15587",
        "content": "인공지능(AI) 빅데이터 전문 바이브컴퍼니(대표 김경서)는 실무형 AI 에이전트 ‘바이브 에이전트(VAIV Agent)’를 공식 출시했다고 11일 밝혔다.\n바이브 에이전트는 사용자 질문을 이해하고, 필요한 정보를 스스로 탐색 및 분석해 실무에 활용 가능한 형태로 요약-정리해주는 기업용 AI 에이전트다. 기존의 단순 응답형 AI를 넘어, 다수 정보 출처를 자동으로 연계해 신뢰성 높은 결과를 도출하는 것이 특징이다.\n바이브에이전트는 ▲기업 내부 보고서와 데이터베이스(DB) ▲금융, 통계, 기업 데이터 ▲SNS, 앱 등 소비자 반응 데이터를 모델 컨텍스트 프로토콜(MCP) 방식으로 연동해 실시간 분석할 수 있도록 설계됐다.\n특히, 비개발자도 자연어로 DB를 조회할 수 있는 ‘Text2SQL’ 기능과, 기존 지식관리시스템(KMS) 연동 기능 등으로 높은 확장성과 연결성을 갖췄다고 강조했다.\n예를 들면, \"8월11일 25% 이상 급등한 종목의 원인은\"이라는 질문이나 \"제품 출시 이후 소비자 반응과 해당 분기 매출은\"과 같은 복합 질문에 대해 관련 데이터를 선별하고 정리해 실무자가 바로 활용할 수 있는 형태로 제공한다고 전했다.\n한편, 바이브에이전트는 지난 6월 ‘바이브 AI 데이’를 통해 처음 공개된 이후 기술 실증(PoC)를 거쳐 실사용성을 확보했으며, 8월부터는 산업별 시장 적용을 본격화해 사업 영역을 넓혀갈 계획이다.\n김경서 바이브컴퍼니 대표는 “A2A 시대를 준비하고 있다”라며 “AI전환(AX)의 중심에서 실무를 이해하고 스스로 일하는 AI의 출발점이 될 것”이라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "임팩티브AI, 제조·유통 수요 예측 기술로 82억 투자 유치",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201406&page=5&total=15587",
        "content": "인공지능(AI) 전문 임팩티브에이아이(대표 정두희)는 시리즈A 라운드를 통해 총 82억원 규모의 투자를 유치했다고 11일 밝혔다.\n이번 투자에는 에이벤처스, 현대투자파트너스, 롯데벤처스, CJ인베스트먼트, IBK벤처투자 등이 신규 참여했다. 기존 투자사 중에서는 신용보증기금이 후속 투자를 집행했다. 이번 라운드를 포함한 누적 투자금은 총 108억원에 달한다.이와는 별도로 딥테크 팁스를 통한 지원금도 추가로 확보했다고 전했다.\n지난 2021년 정두희 한동대학교 교수가 창업한 임팩티브에이아이는 고도화된 AI 기반 수요예측 솔루션 ‘딥플로우(Deepflow)’를 중심으로, 제조-유통 산업 특화 정밀 예측 기술을 제공하고 있다. 기업 성과로 이어지는 사용자 중심 예측 기술을 지향하며 이를 위해 수요 예측, 가격 예측, 재고 최적화 등에 집중하고 있다.\n창업 이후 매년 3배 이상 성장을 지속해 왔다. 주요 고객사로는 CJ제일제당, 동국산업, 일동후디스, SKT, 한미사이언스, 롯데이노베이트 등이 있다.\n현재까지 총 61건의 AI 특허를 출원 및 등록했으며, 독일 베를린에서 열린 ‘드라이버리 베를린(Drivery Berlin)’ 마켓플레이스 대회에서 우승을 거둔 바 있다. 최근에는 유럽 최대 응용 기술 연구소인 프라운호퍼(Fraunhofer IWU)와 예측 기술 공동 개발 협력도 시작했다.\n정두희 임팩티브에이아이 대표는 “수요 예측 분야에서 탑티어 기술력과 실질적 가치를 제공하는 기업으로 자리매김하고 있다”라며 “이번 투자 유치를 계기로 기술 고도화와 글로벌 시장 진출에 더욱 속도를 낼 계획”이라고 말했다.\n장세민 기자 semim99@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "인텔리빅스–유니코어로보틱스, 자율주행 순찰 AI 솔루션 개발 협력",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201407&page=5&total=15587",
        "content": "인텔리빅스가 라이온로보틱스에 이어 유니코어로보틱스와 협력, 피지컬 인공지능(AI) 기업으로 전환을 가속화하고 있다.\n비전 AI 전문 인텔리빅스(대표 최은수, 장정훈)는 8일 서울 서초구 본사에서 로봇 모빌리티 전문기업 유니코어로보틱스(대표 강창묵)와 자율주행 순찰로봇 및 AI 통합관제 기술 개발을 위한 전략적 업무협약(MOU)을 체결했다고 11일 밝혔다.\n지난달 라이온로보틱스와 4족보행 로봇 기반의 AI 로봇 관제시스템 플랫폼을 위한 협약을 체결한 뒤 두번째 로봇기업과의 협약이다.\n양사는 ▲순찰 로봇 연계 자율주행 및 관제 기술 개발 ▲로봇-관제 연동 인터페이스 개발 ▲자율주행 로봇 기술 관련 인적 교류 및 협력을 추진할 계획이다.\n특히 이 순찰 로봇은 재난·사고 현장, 군사 구역, 사람의 출입이 어려운 지역 등에서 필요한 현장조사를 수행할 수 있는 목적 수행 자율주행 기능을 갖춘 것이 특징이다.\n4족보행 로봇에 인텔리빅스의 AI 관제 에이전트 ‘Gen AMS(생성 AI 기반 AI 모니터링 시스템)를 탑재해 이동형 순찰을 가능하게 한다.\n이를 바탕으로 양사는 공공시설, 산업단지, 국방 시설 등에서 자율순찰과 실시간 상황분석이 가능한 차세대 보안 시스템 개발에 착수할 예정이다.\n유니코어로보틱스는 2025년 설립된 로봇 모빌리티 전문으로, 동역학 모델링, 적응제어 알고리즘, 위치 측정 및 동시 지도화(SLAM) 통합기술을 핵심 역량으로 보유하고 있다. 자율주행 휠체어를 개발해 분당서울대학교병원, 현대자동차, KT, 서울시립미술관 등과 협업한 바 있으며, 자율주행과 AI 기술이 결합된 모빌리티 솔루션을 상용화하고 있다.\n최은수 대표는 “유니코어로보틱스의 자율주행 기술과 인텔리빅스의 AI 영상분석 기술이 결합하면, 정적인 관제의 한계를 넘어서는 차세대 보안 솔루션이 구현될 것”이라고 말했다.\n강창묵 유니코어로보틱스 대표는 “인텔리빅스의 검증된 관제 기술과 우리의 자율주행 로봇 기술이 만나 강력한 시너지를 창출할 것으로 기대한다”라고 전했다.\n박수빈 기자 sbin08@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "KT \"글로벌 파트너사와 3분기 AX사업 본격화\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201405&page=5&total=15587",
        "content": "KT(대표 김영섭)는 3분기부터 자체 개발한 대형언어모델(LLM) '믿:음2.0'과 글로벌 파트너십으로 인공지능 전환(AX) 사업을 본격화한다고 11일 밝혔다.\nKT는 이날 실적 발표를 통해 믿:음 2.0을 시작으로 글로벌 모델과 마이크로소프트와 협력 기반으로 개발되는 GPT 모델까지 순차적으로 선보일 예정이라고 전했다. 또 팔란티어의 솔루션과 KT의 클라우드·네트워크 인프라를 결합해 한국 시장에 최적화된 서비스를 제공할 계획이다.\n2분기 실적은 국내 기업의 AX 전환 수요에 적극 대응하며, 연결기준  매출 7조4274억원으로 전년 동기 대비 13.5%증가했다고 전했다. 별도 기준 매출 4조7728억원으로, 전년 동기 대비 4.9% 증가했다고 덧붙였다.\n특히 AI·IT 분야는 설계·구축 및 클라우드 사업 호조에 힘입어 전년 대비 13.8% 성장하며 실적 개선을 이끌었다고 전했다.\n박수빈 기자 sbin08@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "김세엽 셀렉트스타 “2026년 기술특례상장 목표로 데이터 사업 확장“",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201400&page=5&total=15587",
        "content": "“2026년 기술특례상장을 앞두고 올해 연 매출 120억원을 달성하는 것이 목표입니다. 이번 독자 AI 파운데이션 모델 개발 사업에 SKT 컨소시엄으로 참여하며 데이터 구축 사업에서 성과를 기대하고 있습니다.“\n김세엽 셀렉트스타 대표는 이미 2023년부터 주관사인 대신증권과 함께 상장을 준비하고 있었다고 밝혔다.\n셀렉트스타는 데이터 구축 사업과 인공지능(AI) 신뢰성 검증 사업으로 성장해 왔다. 특히 최근 AI 신뢰성 검증 솔루션 ‘다투모 이밸(Datumo Eval)’을 출시하고 국내외 사업을 확장하고 있다.\n김 대표는 많은 기업이 챗봇이나 AI 서비스를 구축하는 과정에 대형언어모델(LLM) 답변의 퀄리티와 안전성을 검증할 필요를 느끼기 때문에 시장이 점차 확대될 것으로 내다봤다.\n그는 ”AI 서비스의 신뢰성을 검증할 때도 평가 데이터를 구축하는 것이 가장 중요하다“라며 ”그동안 데이터 구축 사업에서 쌓아온 역량들이 ‘다투모 이밸’로 이어진 것“이라고 강조했다.\n현재 다투모 이밸을 도입한 기업은 대부분 금융, 공공기관이다. AI 챗봇이 최종 사용자에게 잘못된 정보, 부적절한 답변을 내놓지 않게 출시 전 검증단계에서 사용한다.\n더불어 황민영 셀렉트스타 부대표가 신뢰성 검증 솔루션을 중심으로 글로벌 시장을 개척하고 있다고 전했다.\n김 대표는 “글로벌 시장에서 AI 신뢰성 솔루션은 초기 단계”라며 “글로벌 빅테크들이 경쟁적으로 모델을 개발하고 있는 만큼, 언어모델의 신뢰성 안전성을 평가하는 솔루션의 수요도 커질 것으로 예상한다”라고 전했다.\n현재 셀렉트스타에서 가장 큰 매출을 기록하는 사업 분야는 데이터 구축다. 국내에 진출하려는 글로벌 기업을 대상으로 고품질 한국어 데이터 공급 사업을 본격적으로 진행하고 있다고 전했다.\n특히 전문 분야의 도서 데이터를 모델 사전 학습용으로 공급하기 위해 출판물 저작권을 보유한 파트너사를 확보했다고 덧붙였다. 그 외 각 산업군 특화 데이터 구축 사례도 많아, 최근에는 금융 공공 뿐만 아니라 제조산업 분야 데이터를 구축하기도 했다고 전했다.\n그는 “일반 소비자를 대상으로 AI 서비스를 시도하는 기업들 전체가 셀렉트스타의 잠재고객”이라며 제조 산업 특화 데이터를 확보하고 있다고 밝혔다.\n이런 데이터 구축 사업을 토대로 셀렉트스타는 독자 AI 파운데이션 모델 개발 사업에 SKT 컨소시엄에 합류, 멀티모달 모델 학습용 데이터를 구축할 예정이다.\n셀렉트스타는 모델 안정성 검증을 위한 레드티밍 데이터 구축 및 고품질 학습데이터 구축 등 데이터 분야를 총괄한다. 다투모 이밸과 안전성 평가 데이터셋을 바탕으로 SKT 모델의 잠재적인 취약점을 사전에 검증한다는 계획이다.\n또 지난해 4월 국내에서 최초로 개최된 'AI 레드팀 챌린지'와 MWC2025에서 '글로벌 AI 레드팀 챌린지' 등을 운영한 경험으로 안전성 검증 프로세스를 제공할 예정이다.\n”셀렉트스타는 학습 데이터 구축과 검증을 비롯한 데이터 부문 총괄로 사업에 참여한다“라며 ”이를 통해 연 매출 성장을 기대하고 있다“라고 전했다.\n김세엽 대표는 다각도로 사업을 확장하고 있는만큼 인재 채용을 서두르고 있다.\n2018년 설립 후 지난 7년간 AI 데이터 사업을 운영하면서 셀렉트스타에 적합한 인재의 기준이 생겼다고 설명했다. ”AI 자체에 대한 이해뿐만 아니라, 서비스 운영 경험을 중요하게 생각하고 있다“라며 ”기술을 사업적 성과로 제시할 수 있느냐가 중요한 요소”라고 말했다.\n더불어 “B2B 사업을 전개하다 보니 고객사와 원활한 커뮤니케이션 능력을 보유하고, 필요할 때 집중적으로 업무에 몰두할 수 있는 인재를 찾고 있다”라고 덧붙였다.\n박수빈 기자 sbin08@aitimes.com",
        "date": "2025-08-11",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "\"GPT-5는 무료 사용자 AI 경험의 새 차원 열 것...'문제 해결 지능' 크게 발전\"",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201401&page=5&total=15587",
        "content": "\n오픈AI가 'GPT-5를 통해 챗GPT 대부분을 차지하는 무료 사용자들이 인공지능(AI)에 대한 경험이 확장될 것이라고 설명했다. 또 GPT-5는 단순한 벤치마크를 넘어 '동적인 활용 능력'이 향상된 것으로, 이를 새로운 스케일링업이라고 강조했다.\n브래드 라이트캡 오픈AI 최고 운영책임자(COO)는 8일(현지시간) '빅 테크 테크놀로지'의 팟캐스트에 출연, GPT-5에 대한 이야기를 나눴다.\n그는 먼저 '라우터'가 탑재, 사용자 질문에 따라 추론과 비추론 모델을 자동으로 선택해 준다는 것에 대한 의미를 설명했다.\n\"이전에는 챗GPT의 모델 선택기를 사용해야 했다. 주어진 작업에 사용할 모델을 선택해야 했고, 그런 다음 질문을 하고 답을 얻는 과정을 거쳐야 했다\"라며 \"이것이 사용자들에게 혼란스러운 경험이었다고 생각한다\"라고 말했다.\n이어 \"GPT-5는 사용자를 대신해 결정을 내린다\"라며 \"따라서 추론 모드를 사용하든 사용하지 않든 모든 경우에 더 나은 답을 얻게 될 것\"이라고 설명했다.\n특히 이 기능을 론칭과 동시에 무료 사용자에게도 공개했는데, 이는 새로운 AI 경험을 열어줄 것이라고 강조했다. \"무료 사용자들이 챗GPT를 어떻게 사용해 왔는지 살펴보면, 대부분은 추론 모델의 힘을 제대로 경험하지 못했다\"라며 \"그동안은 GPT-4o를 주로 턴 기반, 거의 검색과 같은 방식으로 사용했다\"라고 지적했다.\n또 \"문제에 대해 얼마나 오랫동안 고민해야 하는지, 질문의 난이도에 비해 얼마나 좋은 답변을 해야 하는지를 모델이 판단하는 것을 처음 경험하게 될 것이기 때문에 일반 사용자는 극적으로 다른 경험을 하게 될 것으로 예상한다\"라고 말했다. \"하지만 상위권 파워 유저에게는 그렇게 큰 차이가 없을 수도 있다\"라고 덧붙였다.\nGPT-5가 획기적인 발전을 이루는 데 실패했다는 지적에 대해서도 부인했다. 그는 모델의 지능을 벤치마크 수치로 측정하기는 어렵다고 밝혔다.\n\"우리는 다양한 차원에서 지능을 측정해야 하는 체제에 갇힌 것 같다\"라며 \"구조적 사고, 문제 해결, 도구 활용 같은 기능은 사용자 눈에는 잘 띄지 않지만 측정할 수 있으며, 이런 모든 기능은 이전 모델보다 GPT-5에서 더 뛰어나다\"라고 설명했다.\n모델의 성능 향상에 대한 기술적 관점도 변했다고 밝혔다.\n\"과거 GPT 모델이 단순히 크기와 학습량 확장에 기반했다면, GPT5는 후처리 학습과 동적 계산을 활용해 능력을 극대화한다\"라는 것이다. 이처럼 실제 활용 사례에서 큰 발전을 이루는 것이 \"\"AI 발전의 새로운 패러다임이자, 단순한 스케일업을 뛰어넘는 혁신적 방법론\"이라고 말했다.\n이런 의미 때문에 GPT-5가 의료 분야, 즉 사용자의 건강 문제에 대한 답변에 정확도와 신뢰를 크게 높이는 것에 집중했다는 것이다. 의료 접근성이 낮은 많은 사람들에게 실질적인 도움을 줄 수 있다고 전했다.\n기업의 사용성을 높이기 위해 가격을 크게 낮춘 것도 같은 의도라고 설명했다. 특히, 기업은 복잡한 업무 프로세스와 많은 사용자, 다양한 도구 연계 등 까다로운 환경에서 AI를 활용하기 때문에 GPT-5는 더 나은 문제 해결력과 도구 활용 능력으로 기업 AI 도입을 도울 수 있다고 말했다.\n하지만 그도 아직 인공일반지능(AGI)에는 못 미친다고 밝혔다. 샘 알트먼 CEO처럼 \"새로운 상황에서 스스로 학습하는 능력은 아직 미완성\"이라고 전했다.\n그리고 앞으로는 더 나은 모델들이 계속 나올 것을 예고했다. 자세한 설명은 없었지만, \"우리는 이제 막 시작된 모델 학습의 새로운 패러다임을 맞이하고 있다\"라고 밝혔다.\n또 \"아직 연구 단계이긴 하지만 중요한 것으로, 이런 학습을 통해 GPT-6가 훨씬 더 좋아지기를 바란다\"라며 \"앞으로 분명 더 나은 모델이 나올 거라고 믿는다\"라고 강조했다.\n이는 얼마 전 노암 브라운 최고 연구원 등이 밝힌 '범용 검증기(Universial Verifier)'에 대한 설명과 일치하는 부분이다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-10",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "오픈AI, GPT-5  출시 '특별 보너스' 지급...수억 이상 1000명 대상",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201398&page=5&total=15587",
        "content": "샘 알트먼 오픈AI CEO가 'GPT-5' 출시 전날 연구 개발 인원 1000여명에게 개인당 최대 수백만달러에 달하는 특별 보너스를 지급한 것으로 알려졌다. 인재 영입 경쟁이 심해지는 상황이긴 하지만, '모델 출시 보너스'가 등장한 것은 처음이다.\n더 버지에 따르면, 알트먼 CEO는 지난 7일 사내 슬랙(Slack) 공지를 통해 GPT-5의 개발과 운영에 관련된 부서의 연구원과 엔지니어들에게 일회성 특별 보너스를 제공하겠다고 발표했다.\n그는 \"AGI 구축을 위한 직원들의 훌륭한 노고에 감사한다\"라고 밝혔다.\n또 \"회사로서 점점 더 나아지는 모습을 보여드리면서 보상도 계속 늘려갈 계획\"이라며 \"특히 이번 보너스 지급은 새로운 일이기 때문에 투명하게 밝히고 싶었다\"라고 설명했다.\n보너스 규모는 직무와 직급에 따라 차등 적용된다. GPT-5 개발에 공이 큰 최고 연구원들은 수백만달러까지 받는 것으로 알려졌다. 엔지니어들의 지급액은 평균 수십만달러 수준이다.\n현금이나 오픈AI 주식, 또는 혼합형으로 선택 가능하다. 보너스는 앞으로 2년간 분기별로 나눠 지급된다.\n이번 보너스 혜택을 받는 인원은 모델 개발과 서비스와 관련된 기술직 1000여명이 대상으로, 이는 전체 직원의 3분의 1에 달한다.\n동시에 오픈AI는 직원들이 보유한 주식을 대규모로 현금화할 수 있도록 투자자 대상 매각 기회를 확대하고 있다.\n알트먼 CEO는 “올해 초 3000억달러 기업 가치를 기준으로 주당 274달러였던 주식 가격보다 훨씬 높은 가격에 거래가 가능할 것”이라고 전망했다. 최근 로이터에 따르면, 이번 거래에서 오픈AI의 가치는 최대 5000억달러(약 700조원)에 달할 수 있다.\n이번 특별 보너스는 오픈AI는 물론, 다른 AI 기업에서도 보기 드문 형태다. 여기에는 메타가 최근 10명 이상의 빼낸 것이 큰 영향을 미친 것으로 보인다.\n보너스를 지급해 외부 영입 제안을 막자는 것보다는, 남은 직원들이 상대적인 박탈감을 방지하자는 의도가 크다. 이번에 메타로 떠난 직원들은 수천만~수억달러의 연봉 패키지를 제안받은 것으로 알려졌다.\n물론 이번 보너스 지급에는 영업이나 사무직에는 해당하지 않아 일부 불만이 생길 수도 있다는 지적이 나왔다.\n하지만, 오랫동안 심혈을 기울였던 GPT-5 공개로 인해 오픈AI의 내부 분위기는 현재 고조된 것으로 알려졌다.\nGPT-5 출시 당일, 알트먼 CEO은 샌프란시스코 본사 인근 스포츠 바에서 직원들과 축하 파티를 열었다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-10",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "구글, 코드 생성으로 문제 해결하는 에이전트 ‘MLE-STAR’ 공개",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201213&page=5&total=15587",
        "content": "구글이 대형언어모델(LLM)의 코드 생성 기능을 통해 다양한 머신러닝(ML) 문제를 해결하는 ML 엔지니어링 에이전트 최신 기술을 소개했다.\n구글은 최근 복잡한 ML 파이프라인의 설계와 최적화를 자동화하는 ‘MLE-STAR(Machine Learning Engineering via Search and Targeted Refinement)’에 관한 논문을 아카이브에 게재했다.\nMLE 에이전트는 코딩이나 추론 기술을 활용해 ML 작업을 코드 최적화 과제로 개념화한다. 그다음 기존 코드 솔루션을 탐색해 실행 가능한 코드를 생성하는 식으로 문제를 해결한다. 이 방식은 이미 일부 작업에서 뛰어난 결과를 발휘해 큰 주목을 받았다.\n그러나 연구진은 기존의 MLE 에이전트가 LLM의 사전 지식에 과도하게 의존해 널리 알려진 방법만을 반복하거나, 코드 전체를 일괄 수정하는 방식으로 충분한 세부 최적화를 하지 못하는 등의 한계가 있었다고 지적했다.\n반면, MLE-STAR는 웹 검색을 기반으로 적절한 모델을 찾은 뒤 각 ML 파이프라인 구성 요소를 선택적으로 수정하고, 코드 성능에 가장 큰 영향을 미치는 부분을 집중 개선함으로써 최적 성능을 달성하는 새로운 방식을 채택했다.\nMLE-STAR는 먼저 웹 검색을 통해 특정 과제에 적합한 최신 모델 및 기법을 찾아 초기 코드를 생성한다. 이후 전체 코드를 한번에 바꾸는 대신, 두 단계로 구성된 반복 개선 프로세스를 통해 ML 파이프라인의 세부 구성 요소를 개별적으로 분석하고 수정한다.\n먼저 ‘어블레이션(ablation) 기반 외부 루프’는 코드 성능에 가장 큰 영향을 미치는 구성 요소를 찾아낸다.\n이후 ‘집중 탐색 내부 루프’에서 해당 요소에 대한 다양한 변형을 반복 생성·평가하며 성능을 끌어올린다. 이 과정은 단순한 전면 수정이 아닌, 특징 추출 방식이나 모델 전처리 등 핵심 요소를 정밀하게 다듬는 방식으로 작동한다.\n특히 이 과정에서 각 문제 해결에 최적화된 여러개의 전문 에이전트를 동시에 구동하는 방식으로 수행된다.\n또 MLE-STAR는 여러개의 후보 솔루션을 생성한 뒤 단순히 검증 점수에 기반한 투표 방식으로 솔루션을 결정하는 것에서 한발 더 나아갔다. 즉, 에이전트가 직접 설계한 앙상블 전략을 통해 후보 솔루션을 하나로 통합, 고성능 솔루션으로 업그레이드한다.\n생성 코드의 취약점을 보완하기 위한 안전 장치도 강화했다. ▲실행 중 오류가 발생하면 자동으로 문제를 진단하고 수정하는 디버깅 모듈 ▲학습 단계에서 데이터를 잘못 참조하는 문제를 사전에 차단하는 데이터 누수 검사기 ▲데이터 중 일부가 무시되는 문제를 방지하는 데이터 활용 검사기 등이 포함된다.\n성능은 캐글(Kaggle)의 머신러닝 엔지니어링 벤치마크인 'MLE-벤치-라이트(MLE-bench Lite)'를 통해 검증됐다.\n기존 상위 성능 에이전트가 25.8%의 메달 획득률을 보인 데 비해, MLE-STAR는 무려 63.6%의 메달 획득률(그중 36%는 금메달)을 기록하며 압도적인 성능 향상을 입증했다.\nMLE-STAR는 구글의 에이전트 개발 키트(ADK)를 기반으로 개발됐으며, 현재깃허브에 오픈 소스 형태로 배포됐다.\n구글은 \"MLE-STAR는 복잡한 ML 작업을 자동화함으로써 ML을 활용하려는 개인과 조직의 진입 장벽을 낮추고, 다양한 분야에서 혁신을 촉진할 수 있다\"라며 \"또 최첨단 모델이 지속적으로 업데이트되고 개선됨에 따라 MLE-STAR에서 생성된 솔루션의 성능도 자동으로 향상될 것으로 예상된다\"라고 밝혔다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-10",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "NASA, 지구 관측 데이터 종합 분석 모델 '갈릴레오' 오픈 소스 출시",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201264&page=5&total=15587",
        "content": "지구 관측 데이터를 종합 분석할 수 있는 오픈 소스 인공지능(AI) 모델 ‘갈릴레오(Galileo)’가 공개됐다. 광학 위성 이미지부터 레이더, 고도, 기후, 인구 밀도 지도 등 다양한 데이터를 통합해 농업 모니터링, 재난 대응, 환경 관측 등 핵심 분야에 활용될 수 있는 범용 모델로 주목받고 있다.\nNASA 하베스트와 앨런 AI연구소(Ai2) 등은 최근 온라인 아카이브를 통해 다양한 지구 관측 데이터 스트림을 대규모로 처리, 분석, 이해하기 위해 개발한 차세대 멀티모달 파운데이션 모델 ‘갈릴레오‘에 관한 논문을 발표했다.\n이 연구의 핵심 목표는 서로 다른 형태의 위성(원격 탐사) 데이터를 효과적으로 통합·분석할 수 있는 도구를 개발, 식량 문제를 해결하고 지구를 보호하기 위한 결정을 돕기 위한 것이다. NASA 하베스트는 식량 안보와 농업 프로그램을 담당하고 있다.\n이 연구 역시 위성의 역할을 단순히 우주에서 사진을 찍는 것 이상으로 끌어 올리기 위한 것이다. 위성은 농부들이 언제 작물을 심고 수확할지 결정하도록 도울 수 있을 뿐만 아니라, 빙하가 얼마나 빠르게 녹고 있는지를 추적하고 홍수를 감시하며 해양에 떠다니는 쓰레기까지 탐지할 수 있다.\n그러나 위성 데이터는 광학 이미지, 레이더 스캔, 기후 측정 등 다양한 형태로 수집되며, 기존 컴퓨터 모델은 대부분 한가지 형태의 데이터만 처리할 수 있었다. 그로 인해 과학자들은 문제 유형마다 서로 다른 시스템을 따로 운용해야 했다.\n이런 한계를 해결하기 위해 등장한 것이 바로 갈릴레오다. 다양한 형태의 위성 데이터를 동시에 처리할 수 있도록 설계된 AI 모델이다.\n특히 수십년간의 빙하 후퇴와 같은 대규모 변화뿐 아니라, 잠깐 등장하는 어선처럼 작고 빠른 변화를 동시에 감지할 수 있다. 다양한 스케일과 데이터 유형에 걸쳐 패턴을 인식함으로써, 갈릴레오는 지구에서 벌어지는 일을 전체적으로 이해할 수 있는 통찰을 제공한다는 설명이다.\n또 이제 과학자들은 농업용 토지 지도 작성, 홍수 감지, 해양 오염 모니터링 등 다양한 과제를 하나의 모델로 해결할 수 있게 됐다고 강조했다.\n갈릴레오는 '센티넬-1(Sentinel-1)'과 '센티넬-2' 위성의 광학과 SAR 데이터, NASA 'SRTM'의 고도 데이터, 'ERA5' 기후 데이터, 'VIIRS' 야간조도, 인구 및 토지 지도 등 총 9가지 유형의 데이터를 융합한다. 덕분에 1~2픽셀 크기의 빠르게 움직이는 어선부터 수천 픽셀에 달하는 빙하까지 다양한 규모의 대상을 정밀하게 인식할 수 있다.\n갈릴레오의 핵심 기술 중 하나는 자체 개발한 자기지도 학습(self-supervised learning) 알고리즘이다. 사람이 직접 정답을 알려주지 않아도, AI가 스스로 패턴을 배우도록 도와준다.\n두가지 방식으로 학습을 진행한다. 첫번째는 ‘글로벌 학습’으로, 넓은 지역이나 긴 시간 동안 일어나는 큰 변화를 이해하는 데 도움을 준다. 예를 들어, 빙하가 수년간 천천히 녹는 모습을 파악할 수 있다.\n두번째는 ‘로컬 학습’으로, 작고 빠르게 변하는 물체나 현상을 감지하는 데 특화돼 있다. 바다에 잠깐 등장하는 어선도 찾아낼 수 있다.\n이렇게 큰 변화와 작은 변화를 모두 잘 인식할 수 있도록, 갈릴레오는 특별한 데이터 마스킹(가리기) 기법과 정보를 처리하는 깊이에 따라 다르게 학습하는 방식을 동시에 사용한다.\n모델 성능도 주목할 만하다. EuroSat, BigEarthNet, Sen1Floods11, CropHarvest, MADOS 등 11개 벤치마크와 15개 다운스트림 과제에서 모두 기존 최고 성능 모델을 능가했다.\n예를 들어 EuroSat 분류 과제에서는 정확도 97.7%로 기존 CROMA나 SatMAE를 앞섰고, 케냐 지역의 작물 분류 데이터셋(CropHarvest)에서도 Presto, AnySat보다 높은 성능을 기록했다. 경량 버전(ViT-Nano, ViT-Tiny)도 제한된 연산 자원 환경에서 뛰어난 성능을 보여줬다.\n갈릴레오는 학습 과정에서 전 세계 지형과 기후를 고르게 반영한 12만7000개 이상의 시공간 정렬 샘플을 활용했다. 이를 통해 지리적 다양성과 의미적 다양성을 모두 확보했으며, 라벨이 부족한 지역에서도 강력한 일반화 성능을 발휘한다. 실제로 NASA 하베스트의 글로벌 작물 지도 작성, 홍수·산불 등 재난 신속 대응, 해양 오염 탐지 등에 갈릴레오가 활용되고 있다.\n갈릴레오는 코드, 사전학습 모델, 데이터셋을 모두깃허브에 공개됐다. 전 세계 지구 관측 커뮤니티의 채택과 확장을 지원하겠다는 의도다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-10",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "바이두 로보택시, 중국 건설 현장서 추락 사고...안전 문제 제기",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201395&page=6&total=15587",
        "content": "바이두의 자율주행 로보택시가 건설 현장 구덩이에 빠지는 사고가 발생, 자율주행차 안전성에 대한 우려가 다시 제기됐다.\n상하이 데일리 등은 9일 중국 충칭에서 바이두의 로보택시 ‘아폴로 고(Apollo Go)’가 승객을 태운 채 공사장 깊은 구덩이에 추락하는 사고가 발생했다고 보도했다.\n사고 차량은 여성 승객을 태운 채 운행 중 공사장 깊은 구덩이로 추락했으나, 승객은 다치지 않고 인근 주민들에 의해 사다리로 구조됐다.\nX(트위터)에 게시된 영상에는 바이두 아폴로 로고가 부착된 흰색 차량이 공사장 바닥에 처박힌 모습이 담겼다. 한 상인은 공사장에 울타리와 경고 표지가 설치돼 있었다고 전했지만, 차량이 이를 어떻게 우회했는지는 밝혀지지 않았다.\n바이두는 중국에서 가장 큰 자율주행차 운영사 중 하나다. 우한과 베이징, 충칭 등 여러 도시에서 상업용 로보택시를 운행하고 있으며, 최근에는 우버 및 리프트와 제휴를 맺어 해외 진출도 모색하고 있다.\n이번 사건은 중국 소셜 미디어(SNS)에서 로보택시의 판단 능력과 안전성을 둘러싼 논란을 촉발했다. 특히 지난해 7월 우한에서는 로보택시 도입 당시, 택시 기사 등이 일자리 문제로 거세게 반발했던 일이 있어, 여파는 커질 것으로 보인다.\nA self-driving “#Robotaxi” by#Baidu’s Apollo Go fell into a roadside pit in#Chongqingon August 7. The female passenger climbed out safely via a ladder. The company said, “Safety is our top priority.”#selfdrivingcars#Chinapic.twitter.com/12VMjAXBgI\n\n자율주행차 사고도 이번이 처음은 아니다. 특히 지난 3월 샤오미 자율주행 차량이 시속 97km로 주행 중 전봇대와 충돌해 화재가 발생하자, 중국 정부는 자율주행 표현을 금지하고 기술 규제를 강화했다.\n미국에서는 2023년 10월 샌프란시스코에서 다른 차량에 치인 보행자가 GM의 로보택시 ‘크루즈’에 휘말려 6m가량 끌려가는 사고가 발생했고, 이 여파로 GM은 로보택시 사업 철수를 결정했다.\n박찬 기자 cpark@aitimes.com",
        "date": "2025-08-10",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "메타, '라마 4' 업그레이드 착수...초지능 팀에 TBD 랩 신설",
        "url": "https://www.aitimes.com/news/articleView.html?idxno=201399&page=6&total=15587",
        "content": "\n메타의 슈퍼인텔리전스 랩(MSL)이 '라마 4' 업그레이드에 본격 착수한 것으로 알려졌다.\n월스트리트 저널은 7일(현지시간) 정통한 소식통을 인용, 알렉산드르 왕 CAIO가 지난주 'TBD(To Be determined)' 랩을 구성하고 라마 4의 업그레이드 버전 출시와 추론 기능 확장, AI 에이전트 개발 등 프로젝트 시작을 알렸다고 보도했다.\nTBD는 '발표 예정'이라는 뜻이다. 이는 본격적인 차세대 프론티어 모델 개발에 앞서, 다른 곳보다 뒤처진 라마 4 성능 업그레이드부터 빨리 마무리하자는 의도를 반영한 것으로 보인다.\n왕 CAIO는 내부 메일을 통해 \"지난 한달 동안 우리 팀이 다른 팀들과 협업을 통해 의미 있는 진전을 이룰 수 있을 것이라는 점을 확인했다\"라며 \"우리는 기술적으로 더욱 야심 차게 나아가고 다양한 노력을 병행해 궁극적으로는 더 빠르게 선구적인 성과를 달성할 수 있게 됐다\"라고 밝혔다.\nMSL 인재 영입이 어느 정도 마무리됐으며, 이에 따라 새로운 프로젝트를 배정하고 기존 팀과의 역할 분담 등을 마무리됐다는 내용이다. 실제로 MSL은 예정이었던 50명에 근접한 것으로 알려졌다. 여기에는 오픈AI 출신이 18명을 차지하고 있다.\n'라마 4.0'을 개발한 기존 메타 인원 중 9명이 TBD에 합류한 것으로 알려졌다. 이들 중 일부는 최근 미라 무라티의 싱킹 머신즈 랩으로부터 영입 제안을 받을 정도로 핵심 인원인 것으로 알려졌다.\n메타도 이런 사실을 확인했다. 메타 대변인은 \"회사가 이미 해당 인력을 TBD 랩으로 이전하고, 이들에게도 새로 영입한 인원처럼 보상을 조정할 계획\"이라고 말했다.\n신설된 TBD 랩은 구글에서 영입한 잭 레이가 이끌게 됐다. 그는 구글에서 2022년 대형언어모델 '친칠라(Chinchilla)'에 이어 '제미나이' 개발을 이끈 베테랑이다.\n이들이 개발 중인 모델은 아직 공식 명칭이 정해지지 않았으나, 내부적으로는 '라마 4.5' 또는 '라마 4.X'라는 이름이 붙었다.\n이는 MSL이 공식 출범한 지 한달 만이다. 마크 저커버그 메타 CEO는 지난 6월30일 사내 메일을 통해 MSL 출범을 공식적으로 알렸다.\n당시 그는 \"라마 4.1과 4.2에 대한 계획이 매우 기대된다\"라며, MSL이 우선 라마 4 시리즈를 업그레이드할 것이라고 밝혔다.\n최근 인원 영입 상황이나 왕 CAIO의 말을 감안하면, 라마 후속 모델은 추론 능력과 멀티모달, AI 에이전트 기능 등으로 성능을 끌어 올리는 것은 물론, 이를 통해 인간처럼 말하는 AI 음성 비서를 배포하는 데 중점을 둘 것으로 보인다. 이는 메타의 레이밴 스마트 안경에 탑재될 예정이다.\n이어 내년부터는 새로운 차세대 파운데이션 모델 개발을 시작, 본격적인 인공일반지능(AGI) 경쟁에 나설 예정이다. 저커버그 CEO는 \"1년 안에는 차세대 모델 연구를 시작, 최전선에 도달할 것\"이라고 밝힌 바 있다.\n임대준 기자 ydj@aitimes.com",
        "date": "2025-08-10",
        "source": "AI타임즈",
        "category": "산업"
    },
    {
        "title": "REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations",
        "url": "https://arxiv.org/abs/2508.10701",
        "content": "The exploitation of 1 day or n day vulnerabilities poses severe threats to networked devices due to massive deployment scales and delayed patching (average Mean Time To Patch exceeds 60 days). Existing defenses, including host based patching and network based filtering, are inadequate due to limited scalability across diverse devices, compatibility issues especially with embedded or legacy systems, and error prone deployment process (manual patch validation). To address these issues, we introduce REFN (Reinforcement Learning From Network), a novel framework that trains Large Language Models (LLMs) to autonomously generate network filters to prevent 1 day or n day exploitations. REFN ensures scalability by uniquely employs Reinforcement Learning (RL) driven by online network rewards instead of traditional Human Feedback (RLHF). REFN guarantees compatibility via unified deployment on edge security gateways (Amazon Eero). REFN provides robustness via online validation using real network traffic. Crucially, REFN addresses three core challenges in training LLMs for exploit prevention: 1) expanding current LLMs limited vulnerability fixing expertise via Agentic RAG based Knowledge Distillation, 2) bridging current LLMs language to network gaps through an RL From VNF Pipeline that translates language context (vulnerability description) into network enforcement, 3) addressing the LLM hallucination and non determinism via the Online Agentic Validation that penalizes erroneous outputs. Evaluated across 22 families of 1 day or n day exploits, REFN demonstrates effectiveness (21.1 percent higher accuracy than alternatives), efficiency (Mean Time To Patch of 3.65 hours) and scalability (easily scale to 10K devices). REFN serves as an initial step toward training LLMs to rapidly prevent massive scale 1 day or n day exploitations.\n        △",
        "date": "2025-08-14",
        "source": "arXiv",
        "category": "기술"
    },
    {
        "title": "Learning from Natural Language Feedback for Personalized Question Answering",
        "url": "https://arxiv.org/abs/2508.10695",
        "content": "Personalization is crucial for enhancing both the effectiveness and user satisfaction of language technologies, particularly in information-seeking tasks like question answering. Current approaches for personalizing large language models (LLMs) often rely on retrieval-augmented generation (RAG), followed by reinforcement learning with scalar reward signals to teach models how to use retrieved personal context. We believe that these scalar rewards sometimes provide weak, non-instructive feedback, limiting learning efficiency and personalization quality. We introduce VAC, a novel framework for personalized response generation that replaces scalar rewards with natural language feedback (NLF) that are generated conditioned on the user profiles and the question narratives. NLF serves as a rich and actionable supervision signal, allowing the policy model to iteratively refine its outputs and internalize effective personalization strategies. Training alternates between optimizing the feedback model and fine-tuning the policy model on the improved responses, resulting in a policy model that no longer requires feedback at inference. Evaluation on the LaMP-QA benchmark that consists of three diverse domains demonstrates consistent and significant improvements over the state-of-the-art results. Human evaluations further confirm the superior quality of the generated responses. These results demonstrate that NLF provides more effective signals for optimizing personalized question answering.\n        △",
        "date": "2025-08-14",
        "source": "arXiv",
        "category": "기술"
    },
    {
        "title": "Advancing Autonomous Incident Response: Leveraging LLMs and Cyber Threat Intelligence",
        "url": "https://arxiv.org/abs/2508.10677",
        "content": "Effective incident response (IR) is critical for mitigating cyber threats, yet security teams are overwhelmed by alert fatigue, high false-positive rates, and the vast volume of unstructured Cyber Threat Intelligence (CTI) documents. While CTI holds immense potential for enriching security operations, its extensive and fragmented nature makes manual analysis time-consuming and resource-intensive. To bridge this gap, we introduce a novel Retrieval-Augmented Generation (RAG)-based framework that leverages Large Language Models (LLMs) to automate and enhance IR by integrating dynamically retrieved CTI. Our approach introduces a hybrid retrieval mechanism that combines NLP-based similarity searches within a CTI vector database with standardized queries to external CTI platforms, facilitating context-aware enrichment of security alerts. The augmented intelligence is then leveraged by an LLM-powered response generation module, which formulates precise, actionable, and contextually relevant incident mitigation strategies. We propose a dual evaluation paradigm, wherein automated assessment using an auxiliary LLM is systematically cross-validated by cybersecurity experts. Empirical validation on real-world and simulated alerts demonstrates that our approach enhances the accuracy, contextualization, and efficiency of IR, alleviating analyst workload and reducing response latency. This work underscores the potential of LLM-driven CTI fusion in advancing autonomous security operations and establishing a foundation for intelligent, adaptive cybersecurity frameworks.\n        △",
        "date": "2025-08-14",
        "source": "arXiv",
        "category": "기술"
    },
    {
        "title": "FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs",
        "url": "https://arxiv.org/abs/2508.10467",
        "content": "Question answering over Scholarly Knowledge Graphs (SKGs) remains a challenging task due to the complexity of scholarly content and the intricate structure of these graphs. Large Language Model (LLM) approaches could be used to translate natural language questions (NLQs) into SPARQL queries; however, these LLM-based approaches struggle with SPARQL query generation due to limited exposure to SKG-specific content and the underlying schema. We identified two main types of errors in the LLM-generated SPARQL queries: (i) structural inconsistencies, such as missing or redundant triples in the queries, and (ii) semantic inaccuracies, where incorrect entities or properties are shown in the queries despite a correct query structure. To address these issues, we propose FIRESPARQL, a modular framework that supports fine-tuned LLMs as a core component, with optional context provided via retrieval-augmented generation (RAG) and a SPARQL query correction layer. We evaluate the framework on the SciQA Benchmark using various configurations (zero-shot, zero-shot with RAG, one-shot, fine-tuning, and fine-tuning with RAG) and compare the performance with baseline and state-of-the-art approaches. We measure query accuracy using BLEU and ROUGE metrics, and query result accuracy using relaxed exact match(RelaxedEM), with respect to the gold standards containing the NLQs, SPARQL queries, and the results of the queries. Experimental results demonstrate that fine-tuning achieves the highest overall performance, reaching 0.90 ROUGE-L for query accuracy and 0.85 RelaxedEM for result accuracy on the test set.\n        △",
        "date": "2025-08-14",
        "source": "arXiv",
        "category": "기술"
    },
    {
        "title": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning",
        "url": "https://arxiv.org/abs/2508.10419",
        "content": "Narrative comprehension on long stories and novels has been a challenging domain attributed to their intricate plotlines and entangled, often evolving relations among characters and entities. Given the LLM's diminished reasoning over extended context and high computational cost, retrieval-based approaches remain a pivotal role in practice. However, traditional RAG methods can fall short due to their stateless, single-step retrieval process, which often overlooks the dynamic nature of capturing interconnected relations within long-range context. In this work, we propose ComoRAG, holding the principle that narrative reasoning is not a one-shot process, but a dynamic, evolving interplay between new evidence acquisition and past knowledge consolidation, analogous to human cognition when reasoning with memory-related signals in the brain. Specifically, when encountering a reasoning impasse, ComoRAG undergoes iterative reasoning cycles while interacting with a dynamic memory workspace. In each cycle, it generates probing queries to devise new exploratory paths, then integrates the retrieved evidence of new aspects into a global memory pool, thereby supporting the emergence of a coherent context for the query resolution. Across four challenging long-context narrative benchmarks (200K+ tokens), ComoRAG outperforms strong RAG baselines with consistent relative gains up to 11% compared to the strongest baseline. Further analysis reveals that ComoRAG is particularly advantageous for complex queries requiring global comprehension, offering a principled, cognitively motivated paradigm for retrieval-based long context comprehension towards stateful reasoning. Our code is publicly released at https://github.com/EternityJune25/ComoRAG\n        △",
        "date": "2025-08-14",
        "source": "arXiv",
        "category": "기술"
    },
    {
        "title": "LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval",
        "url": "https://arxiv.org/abs/2508.10391",
        "content": "Retrieval-Augmented Generation (RAG) plays a crucial role in grounding Large Language Models by leveraging external knowledge, whereas the effectiveness is often compromised by the retrieval of contextually flawed or incomplete information. To address this, knowledge graph-based RAG methods have evolved towards hierarchical structures, organizing knowledge into multi-level summaries. However, these approaches still suffer from two critical, unaddressed challenges: high-level conceptual summaries exist as disconnected ``semantic islands'', lacking the explicit relations needed for cross-community reasoning; and the retrieval process itself remains structurally unaware, often degenerating into an inefficient flat search that fails to exploit the graph's rich topology. To overcome these limitations, we introduce LeanRAG, a framework that features a deeply collaborative design combining knowledge aggregation and retrieval strategies. LeanRAG first employs a novel semantic aggregation algorithm that forms entity clusters and constructs new explicit relations among aggregation-level summaries, creating a fully navigable semantic network. Then, a bottom-up, structure-guided retrieval strategy anchors queries to the most relevant fine-grained entities and then systematically traverses the graph's semantic pathways to gather concise yet contextually comprehensive evidence sets. The LeanRAG can mitigate the substantial overhead associated with path retrieval on graphs and minimizes redundant information retrieval. Extensive experiments on four challenging QA benchmarks with different domains demonstrate that LeanRAG significantly outperforming existing methods in response quality while reducing 46\\% retrieval redundancy. Code is available at: https://github.com/RaZzzyz/LeanRAG\n        △",
        "date": "2025-08-14",
        "source": "arXiv",
        "category": "기술"
    },
    {
        "title": "KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems",
        "url": "https://arxiv.org/abs/2508.10177",
        "content": "Recent Large Language Model (LLM)-based AutoML systems demonstrate impressive capabilities but face significant limitations such as constrained exploration strategies and a severe execution bottleneck. Exploration is hindered by one-shot methods lacking diversity and Monte Carlo Tree Search (MCTS) approaches that fail to recombine strong partial solutions. The execution bottleneck arises from lengthy code validation cycles that stifle iterative refinement. To overcome these challenges, we introduce KompeteAI, a novel AutoML framework with dynamic solution space exploration. Unlike previous MCTS methods that treat ideas in isolation, KompeteAI introduces a merging stage that composes top candidates. We further expand the hypothesis space by integrating Retrieval-Augmented Generation (RAG), sourcing ideas from Kaggle notebooks and arXiv papers to incorporate real-world strategies. KompeteAI also addresses the execution bottleneck via a predictive scoring model and an accelerated debugging method, assessing solution potential using early stage metrics to avoid costly full-code execution. This approach accelerates pipeline evaluation 6.9 times. KompeteAI outperforms leading methods (e.g., RD-agent, AIDE, and Ml-Master) by an average of 3\\% on the primary AutoML benchmark, MLE-Bench. Additionally, we propose Kompete-bench to address limitations in MLE-Bench, where KompeteAI also achieves state-of-the-art results\n        △",
        "date": "2025-08-13",
        "source": "arXiv",
        "category": "기술"
    },
    {
        "title": "SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion",
        "url": "https://arxiv.org/abs/2508.10068",
        "content": "Retrieval-augmented generation (RAG) for repository-level code completion commonly relies on superficial text similarity, leading to results plagued by semantic misguidance, redundancy, and homogeneity, while also failing to resolve external symbol ambiguity. To address these challenges, we introduce Saracoder, a Hierarchical Feature-Optimized retrieval framework. Its core Hierarchical Feature Optimization module systematically refines candidates by distilling deep semantic relationships, pruning exact duplicates, assessing structural similarity with a novel graph-based metric that weighs edits by their topological importance, and reranking results to maximize both relevance and diversity. Furthermore, an External-Aware Identifier Disambiguator module accurately resolves cross-file symbol ambiguity via dependency analysis. Extensive experiments on the challenging CrossCodeEval and RepoEval-Updated benchmarks demonstrate that Saracoder significantly outperforms existing baselines across multiple programming languages and models. Our work proves that systematically refining retrieval results across multiple dimensions provides a new paradigm for building more accurate and robust repository-level code completion systems.\n        △",
        "date": "2025-08-13",
        "source": "arXiv",
        "category": "기술"
    },
    {
        "title": "델 테크놀로지스, 델 AI 데이터 플랫폼 강화… 데이터 수집부터 추론까지 AI 워크로드 전반의 혁신",
        "url": "https://www.aitimes.kr/news/articleView.html?idxno=36040",
        "content": "글로벌 인공지능(AI) 인프라 선도 기업 델 테크놀로지스(Dell Technologies)가 AI 워크로드의 전체 라이프사이클을 지원하는 '델 AI 데이터 플랫폼(Dell AI Data Platform)'의 업데이트를 14일 발표했다. 이번 업데이트는 데이터 수집, 변환, 에이전틱 추론에서부터 AI 기반 지식 검색 등 인공지능 애플리케이션 개발 및 배포·운영 전반의 효율성을 극대화하는 데 초점을 맞췄다.\n엔터프라이즈 데이터 규모가 빠르게 증가하고 있는 가운데 비정형 데이터 비중이 크게 높아졌으나 현재 생성형 AI에 활용 가능한 데이터는 극히 일부에 불과한 상황이다. 인공지능 워크로드가 증가함에 따라 데이터 준비를 간소화하고, 사일로화된 데이터 접근을 통합하며, 엔드투엔드 엔터프라이즈급 성능을 제공하는 인프라에 대한 수요가 높아지고 있다.\n델은 ‘델 AI 데이터 플랫폼’ 업데이트를 통해 비정형 데이터의 수집, 변환, 검색 및 컴퓨팅 성능을 향상시켜 AI 개발 및 배포를 간소화한다. 이를 통해 방대한 데이터셋을 생성형 AI를 위한 신뢰성 높고 품질이 우수한 실시간 인텔리전스로 전환할 수 있다.\nAI 추론 및 애널리틱스 가속화 위한 델 AI 데이터 플랫폼 최신 업데이트\n델 AI 데이터 플랫폼은 데이터 준비를 자동화하여 고객이 AI 실험 단계에서 운영 단계로 빠르게 전환할 수 있도록 돕는다. 아키텍처의 핵심에는 AI 에이전트를 고품질 엔터프라이즈 데이터와 원활하게 연결하는 전용 스토리지 및 데이터 엔진이 포함되어 있다. 델 AI 데이터 플랫폼과 엔비디아 AI 데이터 플랫폼(NVIDIA AI Data Platform) 레퍼런스 설계를 결합하여, 스토리지 엔진과 데이터 엔진을 엔비디아 가속 컴퓨팅, 네트워킹 및 AI 소프트웨어와 통합함으로써 생성형 AI 시스템을 구동하는 검증된 GPU 가속 솔루션을 제공한다.\n델 AI 데이터 플랫폼의 새로운 '비정형 데이터 엔진'은 추론, 분석, 지능형 검색을 위해 대규모 비정형 데이터셋에 대한 실시간 보안 접근을 제공하도록 설계됐다. 오픈소스 검색 AI(Search AI) 분야의 선도기업인 엘라스틱(Elastic)과의 새로운 협업을 통해 개발된 이 엔진은 AI 애플리케이션 구동에 필수적인 고급 벡터 검색, 의미론적 검색(Semantic search), 하이브리드 키워드 검색 기능을 제공할 예정이다.\n또한 비정형 데이터 엔진은 내장된 GPU 가속화를 활용해 혁신적인 성능을 제공한다. 이 엔진은 분산된 정형 데이터를 쿼리하기 위한 페더레이티드 SQL(federated SQL) 엔진, 대규모 데이터 변환을 처리하는 프로세싱 엔진, 빠르고 AI에 최적화된 액세스를 위한 스토리지 등 플랫폼 내 다른 도구들과 함께 작동한다.\n엔터프라이즈 AI에 동력을 제공하는 델 파워엣지 서버 신제품 2종\nAI가 일상적인 비즈니스 운영에 점점 더 중요해짐에 따라, 엔비디아 RTX PRO 6000 블랙웰 서버 에디션 GPU(Blackwell Server Edition GPU)를 탑재한 델 파워엣지 R7725(Dell PowerEdge R7725) 및 R770 서버는 가속화된 엔터프라이즈 워크로드의 주요 컴퓨팅 기반을 제공한다.\n시각적 컴퓨팅, 데이터 분석, 가상 워크스테이션부터 물리적 AI 및 에이전트 추론에 이르기까지 다양한 분야에서 활용이 가능하다. 델 파워엣지 R7725 및 델 파워엣지 R770 서버는 에이전틱 AI를 위한 최신 엔비디아 네모트론(NVIDIA Nemotron) 모델과 물리적 AI를 위한 엔비디아 코스모스 (NVIDIA Cosmos) 월드 파운데이션 모델과 같은 엔비디아 AI 추론 모델을 실행하는 데 이상적이다.\n다양한 엔터프라이즈 사례에서 성능 대비 비용 효율성을 제공하는 공랭식 시스템으로서, 유연한 고밀도 AI 컴퓨팅의 실현 가능성을 극대화했다. 엔비디아 RTX PRO 6000은 LLM 추론 시 토큰 처리량을 최대 6배, 공학 시뮬레이션 성능을 2배 향상시키며, MIG(멀티 인스턴스 GPU) 지원을 통해 이전 세대 대비 동시 사용자 수를 4배까지 지원한다.\n델 파워엣지 R7725 서버는 엔비디아 AI 데이터 플랫폼 레퍼런스 설계를 통합한 첫 번째 2U 서버 플랫폼이 될 예정이다. 이 서버에 엔비디아 RTX PRO 6000 블랙웰 서버 에디션 GPU를 탑재하고 델 AI 데이터 플랫폼 및 새로운 비정형 데이터 엔진과 결합하면, 기업에서 자체 하드웨어 및 소프트웨어 플랫폼을 설계하고 테스트할 필요 없이 즉시 사용 가능한 솔루션을 구축할 수 있다. 두 기술의 결합은 더 빠른 추론, 더 반응이 빠른 시맨틱(semantic) 검색, 더 크고 복잡한 AI 워크로드 지원을 가능하게 한다.\n김경진 한국 델 테크놀로지스의 총괄 사장은 \"AI의 잠재력을 최대한 발휘하기 위해서는 사일로를 허물고 엔터프라이즈 데이터에 대한 접근을 간소화해야 한다”고 말하며, \"엔비디아, 엘라스틱과 같은 업계 리더들과 협력하여 델 AI 데이터 플랫폼을 발전시킴으로써 고객들이 혁신을 가속화하고 AI를 자신감 있게 확장할 수 있게 될 것으로 기대한다\"라고 밝혔다.\n한편, 델 AI 데이터 플랫폼의 비정형 데이터 엔진은 연내에 제공될 예정이다. 엔비디아 RTX PRO 6000 GPU를 탑재한 델 파워엣지 R7725 및 R770 서버는 연내에 출시될 예정이다.\n\n\n",
        "date": "2025-08-14",
        "source": "인공지능 신문",
        "category": "기술"
    },
    {
        "title": "앤트로픽, 클로드 소네트 4에 100만 토큰 컨텍스트 지원..\"75,000줄 이상의 코드나 수십 편의 연구 논문을 처리\"",
        "url": "https://www.aitimes.kr/news/articleView.html?idxno=36037",
        "content": "인공지능 연구 기업 앤트로픽(Anthropic)이 자사의 클로드 소네트4(Claude Sonnet 4) 모델에 최대 100만 토큰의 컨텍스트(context)를 지원한다고 13일(현지시간) 발표했다. 이는 기존 대비 5배 증가한 용량으로, 단일 요청으로 75,000줄 이상의 코드나 수십 편의 연구 논문을 처리할 수 있는 수준이다.\n이번 업데이트는 개발자들이 더 방대하고 데이터 집약적인 AI 활용 사례를 구현할 수 있게 해준다. 주요 활용 사례는 대규모 코드 분석을 위해 소스 파일, 테스트, 문서를 포함한 전체 코드베이스를 로드하여 프로젝트 아키텍처를 이해하고, 파일 간 종속성을 파악하며, 시스템 전반을 고려한 개선 사항을 제안할 수 있다.\n문서 종합 분석 능력 향샹으로 법률 계약서, 연구 논문, 기술 사양 등 방대한 문서 세트를 처리하여 수백 개의 문서 간 관계를 완전한 컨텍스트 내에서 분석할 수 있으며, 고도화된 컨텍스트 인식 에이전트 기능으로 수백 번의 도구 호출과 다단계 워크플로에 걸쳐 컨텍스트를 유지하는 에이전트를 구축할 수 있다. 전체 API 문서, 도구 정의, 상호작용 이력을 포함해도 일관성을 잃지 않는다.\n100만 토큰 컨텍스트는 컴퓨팅 요구 사항 증가에 따라 20만 토큰을 초과하는 프롬프트에 대해 가격이 조정된다. 프롬프트 캐싱을 사용하면 지연 시간과 비용을 절감할 수 있으며, 일괄 처리(batch processing)를 활용하면 추가로 50%의 비용 절감 효과를 얻을 수 있다.\n이번 기능에 대해 웹 개발 플랫폼 기업 Bolt.new의 CEO인 에릭 사이먼스(Eric Simons)는 \"Claude Sonnet 4는 코드 생성 작업에서 다른 선도 모델들을 지속적으로 능가하고 있다\"며, \"100만 토큰 컨텍스트 창 덕분에 개발자들이 훨씬 더 큰 프로젝트를 처리할 수 있게 되었다\"고 밝혔다.\n인공지능 소프트웨어 개발 기업 iGent AI의 CEO 션 워드(Sean Ward)는 \"100만 토큰 컨텍스트를 가진 Claude Sonnet 4는 우리 소프트웨어 엔지니어링 에이전트인 마에스트로(Maestro)의 자율적인 능력을 강화했다\"며, \"실제 코드베이스로 여러 날에 걸친 작업을 수행하는 진정한 '생산 규모 엔지니어링' 시대를 열었다\"고 말했다.\n한편, 100만 토큰 컨텍스트 지원은 현재 앤트로픽 API의 Tier 4 이상 고객과 맞춤형 속도 제한을 가진 고객을 대상으로 공개 베타로 제공되고 있다. 아마존 베드락(Amazon Bedrock)에서도 사용 가능하며, 구글 클라우드의 버텍스 AI(Vertex AI)에는 곧 출시될 예정이다.",
        "date": "2025-08-13",
        "source": "인공지능 신문",
        "category": "기술"
    },
    {
        "title": "엔비디아, 콤팩트 폼팩터에 강력한 AI 성능 구현...새로운 블랙웰 아키텍처 GPU 2종 공개",
        "url": "https://www.aitimes.kr/news/articleView.html?idxno=36034",
        "content": "인공지능(AI) 애플리케이션은 점점 더 많은 산업에서 가속화되고 있으며, 이제 많은 사용자들은 워크스테이션의 크기나 형태와 관계없이 AI 성능을 필요로 한다.\n여기에, 엔비디아는 '엔비디아 RTX PRO 4000 블랙웰 SFF 에디션(NVIDIA RTX PRO 4000 Blackwell SFF Edition)'과 '엔비디아 RTX PRO 2000 블랙웰 GPU'를 곧 출시할 예정이라고 12일(현지시간) 밝혔다. 이들은 엔비디아 블랙웰 아키텍처의 강력한 성능을 작고 에너지 효율적인 폼팩터로 구현한 제품으로, 산업 전반의 전문 워크플로우에 AI 가속화를 제공한다.\nRTX PRO 4000 SFF와 RTX PRO 2000은 기존 GPU 대비 절반 크기이면서도, 4세대 RT 코어(RT Core)와 5세대 텐서 코어(Tensor Core)를 탑재해 전력 소모가 더 적다. 이 새로운 GPU는 엔지니어링, 설계, 콘텐츠 제작, AI, 3D 시각화 등 다양한 전문 워크플로우에 최첨단 성능을 제공하도록 설계됐으며, 획기적인 속도 향상을 실현한다.\n▷RTX PRO 4000 SFF는 이전 세대 아키텍처 대비 AI 성능이 최대 2.5배, 레이 트레이싱 성능이 1.7배 향상됐으며, 대역폭은 1.5배 증가했다. 덕분에 동일한 70와트 최대 전력 소비량으로 더 높은 효율성을 제공한다.\n표준적인 설계와 AI 워크플로우에 최적화된 RTX PRO 2000은 이전 세대 대비 3D 모델링 속도가 최대 1.6배, 컴퓨터 지원 설계(computer-aided design, CAD) 성능이 1.4배, 렌더링 속도가 1.6배 더 빠르다.\n▷RTX PRO 2000 GPU는 이미지와 텍스트 생성 성능을 각각 1.4배, 2.3배 향상시킨다. 이에 따라 CAD, 제품 엔지니어, 크리에이티브 전문가들은 빠른 반복 작업, 신속한 프로토타이핑, 원활한 협업을 실현할 수 있다. 엔지니어링, 건설, 건축, 미디어, 엔터테인먼트, 의료 등 다양한 분야의 기업들은 RTX PRO 블랙웰 GPU를 통해 이전에는 수 시간이 걸리던 작업을 즉각 처리하고 있다.\n혁신을 이끌어가는 소프트웨어\n엔비디아의 소프트웨어 생태계는 크리에이터, 개발자, 기업이 AI와 첨단 그래픽의 모든 역량을 최대한 활용할 수 있도록 지원한다. 엔비디아 AI 엔터프라이즈(AI Enterprise) 소프트웨어 제품군은 프로덕션 AI를 구축, 배포, 확장하는 데 필요한 엔터프라이즈급 도구를 제공한다. 이는 생성형 AI와 컴퓨터 비전부터 음성과 자연어 처리 솔루션까지 아우르며, 거의 모든 인프라에서 작동한다.\n엔비디아 코스모스(Cosmos) 플랫폼은 빠르고 효율적인 추론과 엣지 배포에 최적화된 월드 파운데이션 모델(world foundation model, WFM)을 제공한다. 이를 통해 로보틱스, 자동화, 피지컬 AI 애플리케이션에 고성능 AI를 구현한다. 코스모스-리즌1-7B(Cosmos-Reason1-7B) 모델은 RTX PRO 4000 SFF에서 원활하게 실행되며, 엣지 디바이스와 소형 워크스테이션, 산업 시스템에 강력한 피지컬 AI 추론 기능을 제공한다.\n엔비디아 옴니버스(Omniverse) 플랫폼을 비롯한 엔비디아의 그래픽, 시각화 도구는 3D 설계 팀에 생성형 피지컬 AI와 시뮬레이션을 제공해 디지털 트윈과 시각적 워크플로우를 지원한다. 또한 블랙웰 플랫폼은 엔비디아의 강력한 개발 도구 생태계, 엔비디아 쿠다-X 라이브러리, 600만 명 이상의 개발자, 6,000개에 가까운 애플리케이션을 기반으로 수천 개의 GPU에 걸쳐 성능을 확장한다.\n한편, 엔비디아 RTX PRO 2000 블랙웰과 엔비디아 RTX PRO 4000 블랙웰 SFF 에디션 GPU는 올해 하반기에 출시될 예정이다. RTX PRO 2000은 PNY와 TD 시넥스(TD SYNNEX)를 비롯해 BOXX, 델 테크놀로지스(Dell Technologies), HP, 레노버(Lenovo) 등 시스템 제조업체를 통해 공급될 예정이다.\n엔비디아 RTX PRO 4000 블랙웰 SFF 에디션은 글로벌 유통 파트너와 델 테크놀로지스, HP, 레노버 등 주요 제조 파트너를 통해 공급될 예정이다.\n",
        "date": "2025-08-13",
        "source": "인공지능 신문",
        "category": "기술"
    },
    {
        "title": "\"약물독성 예측의 판을 바꾼다!\"... 칼리시와 영남대 연구팀, AI로 '할로겐 독성'의 통념을 깨다",
        "url": "https://www.aitimes.kr/news/articleView.html?idxno=36033",
        "content": "인공지능 신약개발 기업 칼리시(Calici)와 영남대학교 공동 연구팀이 최첨단 AI 모델 ‘HD-GEM’을 통해 기존 약물 설계에서 일반적으로 회피되던 ‘할로겐화 구조’가 오히려 특정 조건에서 독성을 낮출 수 있음을 과학적으로 입증했다.\n'할로겐화 구조(halogenated structure)'는 유기 화합물에 할로겐 원소 플루오르(F), 염소(Cl), 브롬(Br), 요오드(I)가 결합된 화학 구조를 말한다. 이 원소들은 주기율표의 17족에 속하며, 이러한 할로겐 원자가 탄소 원자와 직접적으로 공유 결합을 형성하는 특징을 가진다.\n이 연구는 약물 설계의 중요한 요소인 할로겐 치환이 실제로는 독성을 증가시킨다는 기존의 가설을 정면으로 반박했다. 연구팀은 1~3개의 방향족 고리(scaffold)를 포함하는 수천 개의 화합물과 실제 약물 구조에 대해 AI 예측을 수행한 결과, 아이오딘과 같은 일부 할로겐은 오히려 간독성과 심장독성을 줄이는 효과가 있음을 발견했다. 또한 다중 할로겐 치환(polyhalogenation)은 생리활성을 증대시키고 대사 안정성을 높여 독성 저하로 이어질 수 있다는 사실도 밝혀냈다.\n칼리시는 이번 연구에서 HD-GEM 모델의 고도화 및 실험 데이터셋 구축에 참여하였다. HD-GEM은 그래프 신경망(GNN) 기반의 구조 학습과 화학 지문(descriptor) 기반의 특성 인식을 통합한 하이브리드 AI 모델로, 기존 예측 도구(ProTox, ADMETlab 등) 대비 높은 정확도와 해석 가능성을 보여주었다. 특히 SHAP 기반 피처 선택, SMOTE 기반 클래스 불균형 보정, Optuna 최적화 등의 최신 기법이 적용되어 AI 독성예측의 정밀도를 극대화했다.\n논문의 교신저자이자 영남대 화학공학부의 이진태 교수는 칼리시와의 이번 성과를 바탕으로 AI 신약개발 플랫폼 ‘Pharmaco-Net(보기)’의 독성 예측 기능을 강화하여, 향후 간·심장 독성 외에도 신장독성, 돌연변이 유발성 등의 다양한 독성 지표에 대한 AI 학습 확장을 예고하고 있다 라고 기대했으며, 이 연구는 특히 기존 약물의 리포지셔닝, 항생제 설계, 기능성 물질 개발 등에서 할로겐화 전략의 재조명을 가능하게 하는 계기가 될 것으로 평가된다고 밝혔다.\n한편, 이번 연구 결과는 생물정보학 분야의 최신 연구와 동향을 요약하고 분석하는 리뷰 논문(review articles)을 전문으로 출판하는 글로벌  학술지 브리핑스 인 바이오인포매틱스(Briefings in Bioinformatics)에 'HD-GEM 머신 러닝 모델을 사용하여 평가된 스캐폴드 독성에 대한 할로겐화의 영향(Impact of halogenation on scaffold toxicity assessed using HD-GEM machine learning model-다운)'란 제목으로 지난달 17일 게재됐다.\n칼리시는 미국과 한국에 거점을 두고 AI 기반 신약개발을 선도하고 있는 바이오 스타트업이며 IBK기업은행이 운영하는 혁신 창업기업 육성 프로그램 ‘IBK창공’에 대전 6기로도 선정된 바 있다.\n",
        "date": "2025-08-13",
        "source": "인공지능 신문",
        "category": "기술"
    },
    {
        "title": "엔비디아, 네모트론·코스모스 추론 모델 확장… AI 에이전트 혁신 가속",
        "url": "https://www.aitimes.kr/news/articleView.html?idxno=36027",
        "content": "엔비디아가 글로벌 최대 컴퓨터 그래픽 컨퍼런스인 시그래프(SIGGRAPH 2025)에서 추론 기능을 갖춘 2개의 모델 제품군인 엔비디아 네모트론(NVIDIA Nemotron)과 엔비디아 코스모스(Cosmos)의 확장을 12일(현지시간) 발표했다.\n프랑스 파리에 본사를 둔 다국적 정보기술(IT) 서비스 및 컨설팅 기업 캡제미니(Capgemini)에 따르면 AI 에이전트는 2028년까지 매출 증가와 비용 절감을 통해 최대 4,500억 달러(약 623조원)의 가치를 창출할 것으로 예상된다. 이러한 에이전트를 개발하는 개발자들은 인공지능(AI) 에이전트 플랫폼과 피지컬 AI 시스템을 개선하기 위해 성능이 더 우수한 추론 모델을 활용하고 있다.\n업계 선도 기업들은 AI 에이전트와 휴머노이드 로봇을 통해 생산성을 높이는 데 엔비디아의 확장된 모델 제품군을 활용하고 있다. 크라우드스트라이크(CrowdStrike), 우버(Uber), 마그나(Magna), 넷앱(NetApp), 줌(Zoom)이 그 대표적인 기업들이다.\n새로운 엔비디아 네모트론 나노 2(Nemotron Nano 2)와 라마 네모트론 슈퍼 1.5(Llama Nemotron Super 1.5) 모델은 과학적 추론, 수학, 코딩, 툴 호출, 명령어 준수, 채팅 분야에서 해당 크기 범주 내 최고 정확도를 제공한다. 이 새로운 모델은 AI 에이전트가 더 깊이 생각하고 효율적으로 작업할 수 있도록 지원한다. 이를 통해 더 폭넓은 옵션을 탐색하고, 연구 속도를 높이며, 설정된 시간 내에서 더 우수한 결과를 제공한다.\n모델은 AI 에이전트의 두뇌와 같다. 핵심 지능을 제공하는 것이다. 그러나 이 두뇌가 비즈니스에 유용하려면 특정 워크플로우뿐 아니라 산업과 비즈니스 용어를 파악하고 안전하게 작동하는 에이전트에 탑재돼야 한다. 엔비디아는 선도적인 라이브러리와 AI 블루프린트(AI Blueprint)를 제공해 기업이 AI 에이전트를 대규모로 도입하고 맞춤화하며 관리할 수 있도록 지원한다.\n코스모스 리즌(Cosmos Reason)은 피지컬 AI 애플리케이션을 위해 개발된 새로운 추론 비전 언어 모델(vision language model, VLM)이다. 이는 구조화된 추론을 통해 물리학, 객체 영속성, 시공간 정렬과 같은 개념을 이해하는 데 탁월하다.\n코스모스 리즌은 로봇 비전언어행동(vision language action, VLA) 모델의 추론 기반 구조로 설계됐으며, 로보틱스와 자율주행 차량을 위한 훈련 데이터의 평가와 캡션 생성에 활용된다. 또한 공장이나 도시와 같은 환경에서 물리적 작업에 대한 시공간 이해와 추론 능력을 런타임 시각 AI 에이전트에 제공한다.\n기업들은 복잡한 다단계의 작업에 대응하기 위해 AI 에이전트를 개발하고 있다. 이에 따라 강력한 추론 정확도와 효율적인 토큰 생성을 제공하는 모델은 지능적이고 자율적인 의사결정을 대규모로 수행하고 있다.\n엔비디아 네모트론은 선도적인 모델과 엔비디아가 선별한 오픈 데이터세트 그리고 첨단 AI 기술을 활용해 AI 에이전트에 정확하고 효율적인 출발점을 제공하는 고급 오픈 추론 모델 제품군이다.\n최신 네모트론 모델은 세 가지 방식으로 업계 최고의 효율성을 제공한다. 새로운 하이브리드 모델 아키텍처, 소형 양자화 모델 그리고 토큰 생성 과정을 개발자가 제어할 수 있는 구성 가능한 사고 예산(thinking budget)이다. 이를 통해 추론 비용을 약 60% 절감할 수 있다. 이 조합은 모델이 더 깊이 추론하고 더 빠르게 응답할 수 있도록 하며, 추가적인 시간이나 컴퓨팅 파워를 요구하지 않는다. 즉, 더 낮은 비용으로 더 나은 결과를 제공하는 것이다.\n라마 네모트론 슈퍼 1.5는 동급 최고 성능과 가장 높은 추론 정확도를 달성해, AI 에이전트가 더 뛰어난 추론을 수행하고, 더 현명한 결정을 내리며, 복잡한 작업을 독립적으로 처리할 수 있도록 한다. 현재 NVFP4(4비트 부동소수점) 버전으로 제공되며, 엔비디아 B200 GPU에서 엔비디아 H100 GPU 대비 최대 6배 높은 처리량을 제공한다.\n위 도표는 네모트론 모델이 동일한 시간과 동일한 컴퓨팅 예산 내에서 최고 수준의 추론 정확도를 제공하며, 달러당 최고 정확도를 달성함을 보여준다.\n두 개의 새로운 네모트론 모델과 함께 엔비디아는 첫 번째 오픈 VLM 훈련 데이터세트인 라마 네모트론 VLM 데이터셋 v1도 발표했다. 이 데이터세트는 광학 문자 인식, 시각적 질의응답, 캡션 데이터 등 300만 개의 샘플을 포함하며, 이전에 공개된 라마 3.1 네모트론 나노 VL 8B 모델을 구동하는 데 사용된다.\n추론 모델의 정확도 외에도, 에이전트는 다양한 소스에 연결된 데이터에서 가장 관련성이 높은 최신 정보를 검색해 의사결정을 내리기 위해 검색 증강 생성(retrieval-augmented generation, RAG)에 의존한다. 최근 공개된 라마 3.2 네모 리트리버(NeMo Retriever) 임베딩 모델은 ViDoRe V1, ViDoRe V2, MTEB 비주얼도큐먼트리트리버(MTEB VisualDocumentRetrieval) 등 세 개의 시각 문서 검색 리더보드에서 모두 1위를 차지하며 에이전트 기반 시스템의 정확도를 향상시키는 데 기여했다.\n이러한 논리적 추론과 정보 검색 모델을 활용해 AI-Q 엔비디아 블루프린트로 구축된 심층 연구 에이전트는 현재 딥리서치 벤치(DeepResearch Bench)에서 개방형과 이동식 에이전트 부문 1위를 차지하고 있다.\n엔비디아 네모와 엔비디아 NIM 마이크로서비스는 개발과 배포부터 에이전트 시스템의 모니터링과 최적화까지 AI 에이전트의 전체 라이프사이클을 지원한다.\n피지컬 AI에 혁신을 가져올 코스모스 리즌\nVLM은 컴퓨터 비전과 로보틱스 분야에서 혁신을 가져오며, 기계가 사물과 패턴을 식별할 수 있도록 했다. 그러나 비추론 VLM은 현실 세계를 이해하고 상호작용하는 능력이 부족하다. 이는 곧 모호하거나 새로운 상황을 처리하지 못하고, 복잡한 다단계 작업을 해결할 수 없다는 것을 의미한다.\n엔비디아 코스모스 리즌은 피지컬 AI와 로보틱스를 위해 설계된 새로운 개방형 맞춤화 가능 70억 파라미터 추론 VLM이다. 코스모스 리즌은 로봇과 비전 AI 에이전트가 사전 지식, 물리학 이해, 상식을 활용해 실제 인간처럼 물리적 세계를 이해하고 행동할 수 있도록 한다.\n코스모스 리즌은 로보틱스와 피지컬 AI 애플리케이션 전반에 걸쳐 고급 기능을 제공한다. 여기에는 훈련 데이터 평가와 캡션 생성, 로봇 의사결정, 영상 분석 AI 에이전트 구축 등이 있다. 이 모델은 방대하고 다양한 훈련 데이터세트의 큐레이션과 주석 작업을 자동화해 고정밀 AI 모델 개발을 가속화할 수 있다. 또한 새로운 환경에서도 복잡한 지시를 실행 가능한 단계로 해석해 VLA 모델에 전달하는 고급 추론 엔진으로 작동해 로봇 계획 수립을 지원할 수 있다.\n또한 엔비디아 메트로폴리스(Metropolis) 플랫폼을 기반으로 하는 영상 검색과 요약(video search and summarization, VSS)용 엔비디아 블루프린트를 통해 구축된 영상 분석 AI 에이전트를 구동한다. 이를 통해 저장된 대규모 또는 실시간 영상 데이터에서 유용한 인사이트를 도출할 수 있다. 이러한 시각 인식과 상호작용형 AI 에이전트는 공장, 물류창고, 소매점, 공항, 교통 교차로 등에서 이상 현상을 탐지함으로써 운영 효율성을 높이는 데 도움을 준다.\n엔비디아 로보틱스 연구팀은 코스모스 리즌을 데이터 필터링과 큐레이션에 이용하고 있다. 또한, 차세대 엔비디아 아이작 GR00T NX(Isaac GR00T NX)와 같은 VLA 모델의 ‘시스템 2(System 2)’ 추론 VLM으로도 활용하고 있다.\nAI 에이전트와 로봇을 위해 어디서나 제공되는 엔비디아 추론 모델\n다양한 기업과 컨설팅 선도 기업들이 엔비디아의 최신 추론 모델을 채택하고 있다. 사이버 보안부터 통신 분야까지 다양한 분야의 리더들이 엔터프라이즈 AI 에이전트 구축을 위해 네모트론을 활용 중이다.\n줌은 줌 AI 컴패니언(Zoom AI Companion)과 네모트론 추론 모델을 결합해 줌 미팅(Zoom Meetings), 줌 챗(Zoom Chat), 줌 문서 전반에서 사용자를 대신해 의사결정을 내리고 다단계 작업을 관리, 실행할 계획이다. 크라우드스트라이크는 네모트론 모델을 테스트해 샬롯(Charlotte) AI 에이전트가 크라우드스트라이크 팔콘(Falcon) 플랫폼에서 쿼리를 작성할 수 있도록 지원하고 있다.\n암독스(Amdocs)는 어메이즈 스위트(amAIz Suite)에서 엔비디아 네모트론 모델을 활용해 의료, 판매, 네트워크, 고객 지원 등 복잡한 다단계 자동화를 처리하는 AI 에이전트를 구동하고 있다. EY는 높은 처리량을 제공하는 네모트론 나노 2를 도입해 대규모 조직의 세금, 리스크 관리, 재무 분야에 적용되는 에이전트형 AI를 지원하고 있다. 넷앱은 현재 AI 에이전트가 비즈니스 데이터를 검색하고 분석할 수 있도록 네모트론 추론 모델을 테스트 중이다.\n데이터로봇(DataRobot)은 자사의 에이전트 워크포스 플랫폼(Agent Workforce Platform)에서 엔드-투-엔드 라이프사이클 관리를 위해 네모트론 모델을 활용하고 있다. 탭나인(Tabnine)은 개발자를 대신해 코딩 작업을 제안하고 자동화하기 위해 네모트론 모델을 활용하고 있다. 오토메이션애니웨어(Automation Anywhere), 크루AI(CrewAI), 데이터이쿠(Dataiku) 등도 네모트론 모델을 자사 플랫폼에 통합하는 에이전트형 AI 소프트웨어 개발사 중 일부이다.\n운송, 안전, AI 인텔리전스 분야를 선도하는 기업들은 코스모스 리즌을 활용해 자율 주행, 영상 분석, 도로와 작업장 안전을 발전시키고 있다.\n우버는 자율주행 차량의 행동을 분석하기 위해 코스모스 리즌을 활용 중이다. 또한 코스모스 리즌을 사후 훈련(post-training)해 시각적 데이터를 요약하고, 보행자가 고속도로를 건너는 상황과 같은 시나리오를 분석해 품질 분석을 수행하며 자율주행 차량의 행동을 개선하고 있다.\n코스모스 리즌은 자율주행 차량의 두뇌 역할을 할 수 있다. 이 시스템은 로봇이 주변 환경을 해석하고, 복잡한 명령을 받아 이를 작업으로 세분화해 상식적인 판단을 바탕으로 실행할 수 있도록 한다. 이는 심지어 익숙하지 않은 환경에서도 가능하다. 센티픽(Centific)은 AI 기반 비디오 인텔리전스 플랫폼을 강화하기 위해 코스모스 리즌을 테스트 중이다. 이 VLM은 플랫폼이 복잡한 영상 데이터를 실행 가능한 인사이트로 처리해 허위 경보를 줄이고 의사결정 효율성을 높이는 데 도움을 준다.\n바스트(VAST)는 엔비디아 코스모스 리즌과 자사의 AI 운영 체제를 결합해 대규모 영상 스트림을 실시간으로 처리하는 도시 인텔리전스 기술을 개발하고 있다. VSS 블루프린트를 통해 바스트는 사건을 식별하고 대응하는 에이전트를 구축할 수 있으며, 이를 통해 영상 스트림과 메타데이터를 실행 가능하고 선제적 공공 안전 도구로 전환할 수 있다.\n앰비언트.에이아이(Ambient.ai)는 코스모스 리즌의 시간적, 물리적 요소를 고려한 추론 기술을 활용해 개인 보호 장비 미착용을 자동으로 감지하고, 위험한 환경을 모니터링하는 기능을 구현하고 있다. 이는 건설, 제조, 물류 등 산업 현장에서 환경 보건과 안전을 강화하는 데 기여한다.\n마그나는 자사의 완전 자율주행, 저비용 즉시 배송 솔루션인 시티 딜리버리 플랫폼(City Delivery Platform) 개발에 코스모스 리즌을 적용해 차량이 새로운 도시 환경에 더 빠르게 적응할 수 있도록 지원한다. 해당 모델은 차량의 장기 경로 계획에 월드 이해(world understanding) 기능을 추가한다.\n이 모델들은 엔비디아 NIM 마이크로서비스로 제공돼, 엔비디아 가속 인프라 어디서든 안전하고 신뢰성 있게 배포할 수 있으며, 높은 수준의 개인정보 보호와 제어 권한을 보장한다. 이 모델들은 곧 아마존 베드록(Amazon Bedrock)과 아마존 세이지메이커 AI(Amazon SageMaker AI)를 통해 네모트론 모델로, 애저 AI 파운드리(Azure AI Foundry), 오라클 데이터 사이언스 플랫폼(Oracle Data Science Platform), 구글 버텍스 AI(Google Vertex AI)를 통해 제공될 예정이다.\n한편, 코스모스 리즌은 허깅페이스(Hugging Face-다운) 또는 깃허브(GitHub-다운)에서 사용할 수 있으며, 네모트론 나노 2와 라마 네모트론 슈퍼 1.5(NVFP4)는 곧 다운로할 수 있으며, 네모트론 모델(보기)에 대해 더 자세히 알아보고, 이전 버전을 다운로드할 수 있다. 허깅페이스에서 라마 네모트론 VLM 데이터세트 v1(다운)을 다운로드할 수 있다.\n\n\n\n",
        "date": "2025-08-13",
        "source": "인공지능 신문",
        "category": "기술"
    },
    {
        "title": "KAIST 김민수 교수팀, \"메모리 초과하는 대규모 데이터에도 학습 및 추론\"... GPU 한 대로 95배 빠르게, 그래프 분석 AI ‘FlexGNN’ 개발",
        "url": "https://www.aitimes.kr/news/articleView.html?idxno=36025",
        "content": "인공지능 텍스트 기반 대형언어모델(LLM)인 챗GPT 등과 함께, 산업 현장에서는 금융 거래, 주식, SNS, 환자기록, 등 비정형 데이터를 그래프 형태로 분석하는 그래프 신경망(Graph Neural Network, GNN) 기반의 그래프 AI 모델이 적극 활용되고 있다.\n하지만 전체 그래프를 한 번에 학습(풀 그래프 학습)하는데 막대한 메모리와 GPU 서버가 필요하다는 한계점이 있다. KAIST 연구진이 단 한 대의 GPU 서버만으로도 대규모 GNN 모델을 최고속 학습할 수 있는 세계 최고 성능의 소프트웨어 기술 개발에 성공했다.\nKAIST 전산학부 김민수 교수 연구팀이 여러 대의 GPU 서버를 활용하는 기존 방식과 달리 한 대의 GPU 서버에서 대규모 풀(full) 그래프 AI 모델을 빠르게 학습하고 추론할 수 있는 GNN 시스템 ‘플렉스지엔엔(FlexGNN)’을 개발했다고 13일 밝혔다. FlexGNN은 기존 기술 대비 학습 속도를 최대 95배 향상한다.\n최근 기후, 금융, 의료, 제약, 제조, 유통 등 다양한 분야에서는 데이터를 정점과 간선으로 구성된 그래프 형태로 변환해 분석 및 예측하는 사례가 증가하고 있다.\n전체 그래프를 모두 학습에 활용하는 풀 그래프 방식이 더욱 우수한 정확도를 보이지만, 학습 과정에서 대규모의 중간 데이터(intermediate data)가 발생해 메모리 부족 현상이 빈번히 발생하고, 여러 서버 간의 데이터 통신으로 인해 학습 시간이 길어지는 한계가 있었다.\n연구팀이 개발한 FlexGNN은 이러한 문제를 극복하기 위해 여러 대의 GPU 서버 대신 단일 GPU 서버에서 SSD(솔리드 스테이트 드라이브)와 메인 메모리를 활용한 최적의 AI 모델 학습을 수행한다.\n특히 데이터베이스 시스템의 질을 최적화시키는 AI 퀴리 최적화 학습을 통해 GPU-메인 메모리-SSD 계층 간 모델 파라미터, 학습 데이터, 중간 데이터를 최적의 시점과 방식으로 계산을 시키는 새로운 학습 최적화 기술을 개발했다. 이를 통해 FlexGNN은 데이터 크기, 모델 규모, GPU 메모리 등 가용 자원 상황에 따라 유연하게 최적의 학습 실행 계획을 생성해 높은 자원 효율성과 학습 속도를 구현한다.\n그 결과, 메인 메모리 용량을 훨씬 초과하는 데이터에 대해서도 GNN 모델을 학습하며, 단일 GPU 서버에서도 최대 95배 빠르게 학습이 가능해졌다. 특히 기후 예측 등에서 슈퍼컴퓨터보다 정밀한 분석이 가능한 풀 그래프 AI 구현이 현실화됐다.\nKAIST 김민수 교수는 “날씨 예측과 신소재 발견 등 복잡한 문제를 해결하는데 풀 그래프 GNN 모델이 활발히 활용되면서 관련 기술의 중요성이 점점 높아지고 있다”며 “FlexGNN이 그동안 어려움으로 남아 있던 그래프 AI 모델의 학습 규모와 속도 문제를 획기적으로 해결한 만큼, 다양한 산업 분야에 널리 활용되기를 기대한다”고 밝혔다.\n한편, 이번 연구는 KAIST 전산학부 배정민 박사과정이 제1 저자로, 김민수 교수창업기업인 그래파이의 한동형 CTO가 제2 저자로 참여했으며, 김 교수가 교신저자를 맡았다. 연구 결과는 세계적 권위의 데이터마이닝 학술대회인 ACM KDD 2025에서 'FlexGNN: 최선형 훈련 계획 최적화를 통해 고성능, 대규모 풀-그래프 GNN 시스템 달성(FlexGNN: A High-Performance, Large-Scale Full-Graph GNN System with Best-Effort Training Plan Optimization-다운)'란 제목으로 지난  5일에 발표됐다. FlexGNN 기술은 향후, 그래파이의 그래프 DB 솔루션인 그래프온(GraphOn)에도 적용될 예정이다.\n",
        "date": "2025-08-13",
        "source": "인공지능 신문",
        "category": "기술"
    },
    {
        "title": "Arm, 업계 최초 '전용 신경망 가속기' Arm GPU에 적용... PC 급 AI 기반 그래픽, 모바일에 구현",
        "url": "https://www.aitimes.kr/news/articleView.html?idxno=36023",
        "content": "Arm은 현지시간 지난 10일부터 14일까지 캐나다 밴쿠버에서 열린 글로벌 최대 컴퓨터 그래픽 컨퍼런스인 시그래프 2025(SIGGRAPH)에서 업계 최초의 Arm 신경망 기술을 발표하고, 2026년부터 Arm GPU에 전용 신경망 가속기를 도입할 예정이라고 12일(현지시간) 밝혔다.\n이 기술은 그래픽 렌더링용 GPU 성능을 새로운 차원으로 끌어올려, 특히 모바일 게임을 비롯한 연산집약적 모바일 콘텐츠에서 GPU 작업량을 최대 50%까지 절감한다. 이는 시작에 불과하며, 이번 신기술은 업계 전반의 향후 온디바이스 인공지능(AI) 혁신을 위한 기반을 마련한다.\n아울러 Arm은 세계 최초로 공개 신경망 그래픽 개발 키트(neural graphics development kit)를 출시한다. 본 키트는 AI 기반 렌더링을 기존 워크플로우에 통합할 수 있도록 설계되어, 개발자들이 하드웨어 출시보다 1년 앞서 개발을 시작할 수 있게 한다. Arm의 모든 신경망 기술은 완전 개방형으로 제공되며, 여기에는 모델 아키텍처, 가중치(weights) 및 모델 재학습에 필요한 도구가 포함된다.\n현재까지 개발 키트 지원을 밝힌 파트너사로는 엔듀어링 게임즈(Enduring Games), 에픽 게임즈(Epic Games)의 언리얼 엔진(Unreal Engine), 넷이즈 게임즈(NetEase Games), 수모 디지털(Sumo Digital), 텐센트 게임즈(Tencent Games), 트래버스 리서치(Traverse Research)가 있다.\nArm AI 및 개발자 플랫폼 부문 펠로우인 게런트 노스(Geraint North)는 “이번 발표는 모바일에서 데스크톱 수준의 신경망 그래픽이 본격 도입됐음을 의미하며, 온디바이스 AI 전환의 최전선에 있는 게임 개발자들에게 중요한 이정표가 될 것”이라고 말했다. 이어 “Arm의 신경망 기술은 게임에만 국한되지 않는다\"며, \"신경망 기반 카메라 워크로드 등 다양한 애플리케이션에도 적용되어, 업스케일링(upscaling)부터 패스 트레이싱(path tracing)까지 온디바이스에서 대규모로 그래픽을 구현할 수 있는 도구를 제공한다”고 덧붙였다.\n개발자는 신경망 그래픽 개발 키트를 통해 하드웨어 출시 전부터 AI 기반 그래픽을 통합하고 즉시 개발을 시작할 수 있다. 모바일 게임을 염두에 두고 설계된 이 키트에는 AI 기반 시각 효과를 통합하고 맞춤화할 수 있도록 언리얼 엔진 플러그인, PC 기반 불칸(Vulkan) 에뮬레이션, 업데이트된 프로파일링 도구, 깃허브(GitHub) 및 허깅페이스(Hugging Face)를 통한 완전 개방형 모델, 불칸용 Arm 머신러닝(ML) 확장 기능 등이 포함된다.\n개방형 불칸용 Arm 머신러닝 확장 기능은 개발자가 익숙한 렌더링 파이프라인에 AI를 직접 통합할 수 있게 한다. 기존 불칸이 그래픽 및 컴퓨팅 파이프라인을 지원하는 반면, Arm의 확장 기능은 신경망 추론에 최적화된 세 번째 파이프라인인 그래프 파이프라인(Graph Pipeline)을 도입한다. 이를 통해 AI를 모바일 렌더링에 그래픽 파이프라인의 네이티브 구성 요소로 손쉽게 통합할 수 있게 된다. 개발자는 여기에서 자세한 내용을 확인할 수 있다.\n신경망 그래픽의 실제 적용 '신경망 슈퍼 샘플링'\nArm 신경망 슈퍼 샘플링(Neural Super Sampling, NSS)은 개발 키트의 모든 요소를 활용한 Arm의 AI 기반 그래픽 업스케일링 엔진이다. NSS는 이미 포트나이트(Fortnite)와 인피니티 니키(Infinity Nikki) 등을 제작하는 개발사들이 활용 중인 Arm Accuracy Super Resolution(ASR)을 기반으로 구축됐다.\nNSS는 540p 해상도를 1080p로 업스케일링 하는 데 프레임당 4ms의 처리 시간만을 소요하며, 원본에 가까운 화질을 제공한다. 이를 통해 개발자는 전통적인 전체 프레임 렌더링 방식 대비 GPU 워크로드를 최대 50%까지 절감할 수 있으며, 이 절감분을 전력 소모 절감, 더 높은 프레임 속도, 시각 품질 향상 중 필요에 맞게 배분할 수 있다. 또한 NSS는 표면 디테일, 조명, 모션 선명도를 AI로 보존해, 게임 특성에 맞춘 시각적 충실도와 에너지 효율의 균형을 가능하게 한다.(아래는 데모 영상)\n\n업스케일링을 넘어...더 많은 신경망 그래픽\n2026년, Arm은 인공지능을 통해 렌더링 부하를 늘리지 않고도 프레임 속도를 두 배로 높이는 신경망 프레임 속도 업스케일링(Neural Frame Rate Upscaling)과 픽셀당 광선 수를 줄여 모바일에서 실시간 경로 추적을 가능하게 하는 신경망 슈퍼 샘플링 및 디노이징(Neural Super Sampling and Denoising)을 도입해 신경망 기술 애플리케이션 로드맵을 확장할 계획이다. 두 기술 모두 하드웨어 출시 이전에 제공될 예정이다.\n이를 통해 Arm은 개방적이고 접근성이 뛰어나며 현실 환경 성능에 최적화된 신경망 그래픽을 구현한다. 통합된 개방형 플랫폼을 제공함으로써, Arm 기반의 다양한 온디바이스 경험 전반에 AI를 보다 쉽게 배포할 수 있도록 지원한다.\n아담 크레이톤(Adam Creighton), 엔듀어링 게임즈 설립자 겸 CEO는 “엔듀어링 게임즈와 Arm은 개발자들에게 기기 종류와 무관하게 더 큰 제어권, 성능, 그리고 높은 콘텐츠 품질을 제공한다는 비전을 공유하고 있습니다\"며, \"Arm의 신경망 그래픽 개발 키트는 모바일 게임 개발의 미래를 위한 맞춤형 플랫폼으로, 개발자가 AI 기반 워크플로를 탐색하고 전 세계 플레이어에게 더 풍부하고 몰입감 있는 경험을 제공할 새로운 선택지를 제공합니다\"라고 말했다.\n넷이즈 게임즈 유웬 우(Yuwen Wu), 수석 엔진 개발 전문가는 “넷이즈 게임즈의 목표 중 하나는 모든 모바일 기기에 콘솔급 비주얼을 제공하는 것입니다\"라며, \"이번 이니셔티브와 개발 방향은 중요한 도약이라고 보며, 실제 기기에 적용되는 당사의 강력한 모바일 엔진 성능을 바탕으로 Arm과 협력해 신경망 그래픽 개발 키트를 최적화하기를 기대합니다\"라고 말했다.\n수모 디지털 스콧 커클랜드(Scott Kirkland), 그룹 기술 디렉터는 “수모 디지털은 신경망 그래픽과 AI 기반 업스케일링이 모바일 게이밍을 혁신해 콘솔급 비주얼과 깊은 몰입감을 제공하면서도 배터리 소모를 최소화할 것이라고 믿습니다\"라며, \"신경망 기술은 놀라운 그래픽과 휴대성을 결합하는 새로운 시대를 열 것이며, 당사는 Arm과 함께 모바일 게임의 창의적·기술적 혁신의 미래를 탐구하게 되어 기쁘게 생각합니다\"라고 말했다.\n",
        "date": "2025-08-13",
        "source": "인공지능 신문",
        "category": "기술"
    },
    {
        "title": "엔비디아, 세계 최고 인기 AI 엔터프라이즈 시스템에 블랙웰 RTX PRO 서버 공급",
        "url": "https://www.aitimes.kr/news/articleView.html?idxno=36010",
        "content": "엔비디아가 글로벌 최대 컴퓨터 그래픽 컨퍼런스인 시그라프(SIGGRAPH 2025)에서 세계에서 가장 인기 있는 엔터프라이즈 서버에 엔비디아 RTX PRO 6000 블랙웰 서버 에디션(NVIDIA RTX PRO™ 6000 Blackwell Server Edition) GPU가 도입된다고 11일(현지시간) 발표했다. 이번 발표로 기존 CPU 시스템에서 가속 컴퓨팅 플랫폼으로의 전환이 더욱 빨라질 전망이다.\n새로운 2U 메인스트림 서버를 통해 전 세계 기업들은 가장 널리 채택된 랙마운트 시스템에서 엔비디아 블랙웰 아키텍처를 활용해 데이터센터에서 획기적인 성능과 효율성을 구현할 수 있다.\n시스코(Cisco), 델 테크놀로지스(Dell Technologies), 휴렛팩커드 엔터프라이즈(Hewlett Packard Enterprise, HPE), 레노버(Lenovo), 슈퍼마이크로(Supermicro)를 비롯한 글로벌 시스템 파트너들은 다양한 구성의 2U 엔비디아 RTX PRO 서버를 제공할 예정이다. 이는 에이전틱 AI(Agentic AI), 콘텐츠 제작, 데이터 분석, 그래픽, 과학 시뮬레이션, 산업용 AI, 피지컬 AI에 이르는 다양한 엔터프라이즈 워크로드에 범용적인 가속화를 가져올 것으로 기대된다.\n엔비디아 창립자 겸 CEO인 젠슨 황(Jensen Huang)은 “인공지능은 60년 만에 처음으로 컴퓨팅을 재창조하고 있다. 클라우드에서 시작된 변화는 이제 온프레미스 데이터센터 아키텍처까지 혁신하고 있다. 우리는 세계 최고의 서버 공급업체들과 함께 엔비디아 블랙웰 RTX PRO 서버를 엔터프라이즈와 산업용 AI의 표준 플랫폼으로 만들어가고 있다”고 말했다.\n엔비디아 RTX PRO 서버 제품군, 데이터센터에 가속 시스템 제공\n매년 전 세계 기업들은 비즈니스 워크로드 처리를 위해 수백만 대의 서버를 구매한다. AI가 기업 운영에 점점 더 중요해짐에 따라, 이들 시스템을 가속 서버로 교체할 수 있는 길이 열렸다. RTX PRO 서버는 데이터 분석, 시뮬레이션, 영상 처리, 그래픽 렌더링 등 기존 CPU 기반 워크로드에 GPU 가속을 더한다. 이를 통해 CPU 전용 2U 시스템 대비 최대 45배 향상된 성능과 최대 18배 높은 에너지 효율을 제공하며, 소유 비용까지 낮춘다.\n엔비디아 RTX PRO 서버는 공간, 전력, 냉각 환경에 제약이 있는 데이터센터에서 AI 팩토리를 구축하려는 엔터프라이즈 고객에게 획기적인 블랙웰 성능을 제공하는 새로운 온프레미스 인프라이다.\n또한 이 시스템은 엔터프라이즈 에이전틱 AI를 위한 첨단 스토리지 시스템 구축을 지원하는 맞춤형 참조 설계인 엔비디아 AI 데이터 플랫폼(AI Data Platform)에 인프라 기반을 제공한다. 이번 시그라프에서 델은 엔비디아 AI 데이터 플랫폼 참조 설계가 통합된 델 AI 데이터 플랫폼의 업데이트를 발표했다. 아울러 두 개의 RTX PRO 6000 GPU, 엔비디아 AI 엔터프라이즈(AI Enterprise) 소프트웨어, 엔비디아 네트워킹을 탑재한 델 파워엣지 R7725(Dell PowerEdge R7725) 2U 서버도 함께 공개했다.\n새로운 2U 메인스트림 시스템은 지난 5월 컴퓨텍스(COMPUTEX)에서 발표된 RTX PRO 서버 제품군에 새롭게 합류했다. 이 시스템은 엔비디아 RTX PRO 6000 블랙웰 GPU를 2개, 4개, 8개까지 지원하는 폭넓은 랙마운트 설계를 제공하며, 성능, 효율성, 비용을 최적화하려는 기업에 이상적인 솔루션이다.\n엔터프라이즈 데이터센터를 위한 혁신적인 AI 성능\n새로운 RTX PRO 서버는 AI, 머신러닝, 데이터 분석, 3D 그래픽, 과학 시뮬레이션 등 다양한 애플리케이션에 적합한 다목적 고성능 플랫폼을 제공한다. 이 서버에는 최신 블랙웰 아키텍처의 혁신적인 기술이 적용됐다.\n주요 특징으로 ▷5세대 텐서 코어(Tensor Core)와 2세대 트랜스포머 엔진(Transformer Engine)이 FP4 정밀도를 지원해 이전 세대 엔비디아 L40S GPU 대비 추론 성능을 최대 6배 향상한다. ▷사실적인 렌더링과 시각화를 구현하는 4세대 엔비디아 RTX™ 기술로 L40S GPU 대비 최대 4배의 성능을 향상한다.\n▷GPU당 완전히 분리된 4개의 인스턴스를 제공하는 가상화와 엔비디아 멀티 인스턴스 GPU(Multi-Instance GPU) 기술을 활용해 다중 사용자의 AI 배포를 위한 엔터프라이즈급 확장성을 제공한다. ▷전력 대비 성능 개선으로 지속 가능한 데이터센터 운영을 지원한다.\n피지컬 AI와 로보틱스 워크로드 가속화\nRTX PRO 서버는 엔비디아 옴니버스(Omniverse™) 라이브러리와 엔비디아 코스모스(Cosmos™) 월드 파운데이션 모델(world foundation model, WFM)을 실행해 피지컬 AI 개발자가 애플리케이션을 개발, 배포할 수 있도록 돕는다. 이 애플리케이션에는 공장과 로봇 시뮬레이션을 위한 디지털 트윈, 대규모 합성 데이터 생성 등이 포함된다.\nRTX PRO 서버는 시뮬레이션과 합성 데이터 생성 워크플로우를 L40S GPU 대비 최대 4배까지 가속화할 수 있다. 또한 RTX PRO 서버는 더 스마트하고 안전한 공간 구현을 위해, 엔비디아 메트로폴리스(Metropolis) 플랫폼의 최신 영상 검색과 요약을 위한 엔비디아 블루프린트(Blueprint)를 포함한 고급 블루프린트를 지원한다. 또한, 비전 언어 모델(vision language model, VLM)과 합성 데이터 생성 확장을 통해 피지컬 AI 환경 전반의 생산성과 안전성을 강화한다.\n모든 RTX PRO 서버는 AI 개발과 배포를 가속화하고 보안을 강화하는 소프트웨어 레이어인 엔비디아 AI 엔터프라이즈 인증을 획득했다.\nRTX PRO 서버는 복잡한 작업을 수행하고 자동화하는 AI 추론 모델 기반 AI 에이전트를 실행하는 데 이상적이다. AI 추론 모델의 예시로는 이번에 발표된 라마 네모트론 슈퍼(Llama Nemotron Super)가 있다. 이 모델은 단일 엔비디아 RTX PRO 6000 GPU에서 NVFP4 정밀도를 사용할 경우, 엔비디아 H100 GPU의 FP8 대비 최대 3배 뛰어난 가격 대비 성능을 제공한다. 따라서 더 정확한 추론을 더 낮은 비용으로 수행할 수 있다.\n블랙웰 플랫폼은 엔비디아 쿠다-X(CUDA-X™) 라이브러리, 600만 명 이상의 개발자, 약 6,000개의 애플리케이션을 포함한 강력한 엔비디아 개발 생태계를 기반으로 구축돼, 수천 개의 GPU 전반에 걸쳐 성능을 확장할 수 있다.\n한편, 출시는 글로벌 시스템 업체인 시스코, 델, HPE, 레노버, 슈퍼마이크로는 다양한 엔비디아 인증(NVIDIA-Certified) RTX PRO 서버를 선보일 예정이다. 이 밖에도 어드밴텍(Advantech), 애티나(Aetina), 에어베스(Airves), 애즈락 랙(ASRock Rack), 에이수스(ASUS), 컴팔(Compal), 폭스콘(Foxconn), 기가바이트(GIGABYTE), 인벤텍(Inventec), 미텍 컴퓨팅(MiTAC Computing), MSI, 페가트론(PEGATRON), 퀀타 클라우드 테크놀로지(Quanta Cloud Technology, QCT), 위스트론(Wistron), 위윈(Wiwynn)을 비롯한 데이터센터 시스템 파트너들이 RTX PRO 서버를 출시할 계획이다.\n고객들은 전 세계 시스템 업체와 채널 파트너를 통해 RTX PRO 서버를 주문할 수 있다. 현재 RTX PRO 6000 GPU 8개를 탑재한 4U 폼팩터 구성은 즉시 구매 가능하며, 2U 메인스트림 RTX PRO 서버는 올해 말 출시될 예정이다. 여기에서 RTX PRO 서버에 대해 자세히 알아볼 수 있다.\n",
        "date": "2025-08-12",
        "source": "인공지능 신문",
        "category": "기술"
    },
    {
        "title": "UNIST 이슬기 교수팀, AI 모델 실행 코드 찾는 시간 절반 이하로 줄였다...오토튜닝 속도 최대 2.5배↑",
        "url": "https://www.aitimes.kr/news/articleView.html?idxno=36007",
        "content": "UNIST 컴퓨터공학과 이슬기 교수팀이 인공지능(AI) 딥러닝 모델을 실행 가능한 프로그램 형태로 바꾸는 데 걸리는 시간을 절반 이상 줄이는 기술이 개발했다. 오토튜닝 과정을 최대 2.5배 빠르게 할 수 있는 기법이다.\nAI 모델이 실제로 작동하려면 사람이 짠 고수준의 프로그램인 AI 모델을 컴퓨터 연산장치가 이해할 수 있는 형태로 다시 바꾸는 ‘컴파일’ 과정이 필요하다. 예를 들어 ‘고양이 사진을 구분해줘’라는 명령도 수천 줄에 이르는 복잡한 계산 코드로 바꿔야 연산장치인 GPU나 CPU가 실제로 실행할 수 있다.\n오토튜닝은 이 과정에서 가능한 수십만 개의 코드 조합 중 연상 장치에서 가장 빠르고 효율적인 구성을 자동으로 찾아주는 기술이다. 하지만 경우에 따라 튜닝 시간이 수십 분에서 수 시간까지 걸릴 정도로 연산 부담이 크고, 전력 소모도 많다는 문제가 있었다.\n연구팀은 딥러닝 모델 안에 반복되는 계산 구조가 많다는 점에 주목해 유사한 연산자끼리 정보를 공유하는 방식으로 탐색 범위를 줄였다. 코드 조합을 일일이 새로 찾는 대신 기존 결과를 재활용해 오토튜닝 속도를 높인 것이다.\n실제 이 방식을 기존 오토튜닝 프레임워크(Ansor)에 적용한 결과, 동일한 성능의 실행 코드를 생성하는 데 걸리는 시간이 CPU 기준 평균 2.5배, GPU 기준 평균 2배 단축됐다. 이슬기 교수는 “컴파일 시간을 줄이면서도 GPU나 CPU를 직접 실험에 쓰는 횟수가 줄어 제한된 연산 자원을 효율적으로 쓸 수 있을 뿐만 아니라 전력 소모도 줄일 수 있다”고 말했다.\n한편, 이번 연구는 UNIST 정이수 연구원이 제1저자로 참여했으며, 연구 결과는 지난달 7일부터 9일까지 미국 보스턴에서 열린 컴퓨터 시스템 분야 권위 학회인 OSDI 2025(Operating Systems Design and Implementation)에서 '베이지안 코드 확산을 이용한 효율적인 딥러닝 프로그램 자동 최적화(Bayesian Code Diffusion for Efficient Automatic Deep Learning Program Optimization-다운)'란 제목으로 발표됐다. OSDI에 한국인 주저자의 연구가 채택된 사례는 학회 20여 년 역사상 단 12건뿐이다.\n올해는 338편의 논문이 제출돼 이 중 48편만이 채택됐으며, 국내에서는 이슬기 교수팀외 서울대학교 이재욱 교수팀의 연구가 함께 이름을 올렸다.",
        "date": "2025-08-12",
        "source": "인공지능 신문",
        "category": "기술"
    },
    {
        "title": "엔비디아, '쿠다 툴킷 13.0' 발표…'타일 기반 프로그래밍' 도입, \"차세대 GPU 프로그래밍 패러다임 바꾼다!\"",
        "url": "https://www.aitimes.kr/news/articleView.html?idxno=35991",
        "content": "인공지능(AI)과 고성능 컴퓨팅(HPC)과 최신 CPU와 GPU 가속 컴퓨팅을 지원하는 엔비디아 '쿠다 툴킷 13.0(CUDA Toolkit 13.0)'이 지난 6일(현지시간) 공식 발표했다. 이번 메이저 업데이트는 최신 GPU 아키텍처인 블랙웰(Blackwell)과 ARM 플랫폼 지원을 강화하는 한편, 새로운 '타일 기반 프로그래밍(Tile-based Programming)'을 도입해 개발 생산성과 하드웨어 효율성을 동시에 높인 것이 특징이다.\n이 모델은 개발자가 데이터 타일을 정의하고 연산을 지정하면, 컴파일러와 런타임이 자동으로 쓰레드 분배와 하드웨어 최적화를 처리한다. 특히 텐서 코어(Tensor Core)와 자연스럽게 매핑돼, 현재와 미래의 GPU 아키텍처에서 ‘한 번 작성한 코드를 오래, 빠르게’ 실행할 수 있도록 설계됐다.\n이번 릴리스에 포함된 새로운 기능과 향상된 기능은 CUDA에서 타일 기반 프로그래밍을 위한 기반 구축과 특히 DGX Spark를 포함한 Arm 플랫폼에서 개발자 경험 통합, 레드햇 엔터프라이즈 리눅스 10(Red Hat Enterprise Linux 10)을 포함한 업데이트된 OS 및 플랫폼 지원한다.\n또한, 엔비디아 Nsight 개발자 도구 업데이트, 수학 라이브러리 선형 대수 및 FFT 업데이트, 개선된 fatbin 압축 방식과 GCC 15 및 Clang 20 지원을 포함한 NVCC 컴파일러 업데이트와 가속화된 파이썬 쿠다 코어(Python cuda.core) 릴리스 및 개발자 친화적 패키징, 완전한 기능을 갖춘 아키텍처, 블랙웰에서 성능 향상을 위해 32바이트 정렬로 업데이트된 벡터 유형과 젯슨 토르(Jetson Thor) 지원 등을 꼽을 수 있다.\n이번 업데이트의 핵심적인 변화를 세 가지로 요약할 수 있다. 먼저, ▷GPU 프로그래밍 패러다임의 진화로 그동안 CUDA는 SIMT(Single Instruction, Multiple Threads)라는 스레드 병렬 모델을 사용해왔다. 이 방식은 개발자가 수많은 스레드를 직접 제어해야 하는 복잡함이 있었다. 하지만 CUDA 13.0은 여기에 '타일 기반 프로그래밍'이라는 새로운 모델을 도입하기 위한 초석을 다졌다.\n타일 프로그래밍은 마치 파이썬의 넘파이(NumPy)처럼, 데이터 덩어리인 '타일(Tile)'에 대한 연산을 정의하면 컴파일러가 이를 스레드에 맞게 최적화해주는 방식이다. 개발자는 이제 저수준의 스레드 제어 대신 알고리즘 자체에 집중하며 생산성을 획기적으로 높일 수 있다. 특히 이 모델은 AI 연산의 핵심인 텐서 코어(Tensor Cores)에 최적화되어 있어, 미래 GPU 아키텍처에서도 코드를 한 번만 작성하면 높은 성능을 유지하는 하위 호환성을 보장한다.\n또한 ▷하드웨어 지원 확대와 개발 환경의 '통합'으로 CUDA 13.0은 엔비디아의 최신 하드웨어에 대한 광범위한 지원을 제공한다.\n블랙웰 GPU 지원 강화로 CUDA 12.8에서 처음 지원을 시작한 B200, GB200에 더해 B300, GB300, RTX PRO, RTX 5000 시리즈 등 최신 블랙웰 기반 GPU를 모두 지원한다. ARM 플랫폼 개발 환경 통합으로 기존에는 서버용 ARM과 Jetson과 같은 임베디드 장치용 ARM 개발 환경이 분리되어 있었다. CUDA 13.0은 이 두 환경을 하나의 툴킷으로 통합해, 개발자가 DGX Spark와 같은 고성능 시스템에서 코드를 빌드하고 시뮬레이션한 뒤, Jetson Thor 같은 임베디드 장치에 코드를 수정하지 않고 그대로 배포할 수 있게 되었다. 이는 개발 과정을 간소화하고 생산성을 크게 높여준다.\n아울러, ▷개발자 편의성을 극대화하는 다양한 개선으로 CUDA 13.0은 개발자들이 더 빠르고 효율적으로 작업할 수 있도록 여러 측면에서 개선을 이뤘다.\n효율적인 압축 기술은 실행 파일의 코드 컨테이너인 '팻빈(fatbin)'의 기본 압축 방식을 지스탠다드(Zstandard)로 변경했다. 이를 통해 실행 파일 크기를 최대 17%까지 줄이면서도 실행 속도 저하는 거의 없다. CUDA Math API의 경우, 크기 중심의 압축 모드를 사용하면 최대 71%까지 용량을 줄일 수 있어 배포 효율성이 대폭 향상되었다.\n파이썬 통합 강화로 파이썬 개발자들이 GPU 가속의 이점을 쉽게 활용할 수 있도록 cuda.core의 초기 버전을 공개했다. 또한, 파이썬 패키지(wheel)의 파일 구조를 통일하고 cuda-toolkit이라는 메타 패키지를 도입해 필요한 구성 요소를 쉽게 설치할 수 있게 되었다.\n컴파일러 및 OS 지원으로 GCC 15, Clang 20 등 최신 호스트 컴파일러를 지원하고, Red Hat Enterprise Linux 10 등 최신 운영체제에 대한 지원도 추가되었다. 이번 CUDA 13.0은 단순히 성능을 향상시키는 것을 넘어, GPU 프로그래밍 방식을 근본적으로 바꾸고 개발 환경을 통합해 AI, 자율주행, 로봇공학 등 다양한 분야의 혁신을 가속화할 것으로 기대된다. 현재, 쿠다 툴킷 13.0(다운)을 비롯한 이전에 출시된 모든 CUDA 툴킷은 CUDA 다운로드 아카이브 페이지(다운)에서 다운로드할 수 있다 .\n한편, CUDA Toolkit 13.0은 단순한 기능 개선을 넘어, 타일 기반 프로그래밍이라는 차세대 패러다임과 플랫폼 통합 전략으로 GPU 컴퓨팅 개발 환경의 생산성과 범용성을 한 단계 끌어올렸다. 엔비디아는 이를 통해 AI, HPC, 로보틱스 등 GPU 활용 분야에서 개발자가 더 빠르고 효율적으로 혁신할 수 있는 기반을 마련했다고 강조했다.",
        "date": "2025-08-10",
        "source": "인공지능 신문",
        "category": "기술"
    },
    {
        "title": "약물 후보 '뚝딱'… KAIST 김우연 교수팀, 표적 단백질에 최적화된 신약 설계 AI 개발",
        "url": "https://www.aitimes.kr/news/articleView.html?idxno=35990",
        "content": "기존 약물 개발 방식은 질병을 일으키는 원인이 되는 표적 단백질(예: 암세포 수용체)을 정하고, 그 단백질에 잘 달라붙어 작용을 막을 분자(약물 후보)를 찾는 방식으로 수많은 후보 분자 대상으로 진행하다 보니 시간·비용이 많이 들고 성공 가능성도 낮았다.\n여기에, KAIST 연구진이 표적 단백질 정보만 있으면, 사전 정보(분자)가 없어도 딱 맞는 약물 후보를 설계해 주는 인공지능(AI) 모델을 개발하고 신약 개발의 새로운 가능성을 열었다.\nKAIST 화학과 김우연 교수 연구팀이 결합하는 약물 후보 분자의 사전 정보 없이 단백질의 구조만으로, 그에 꼭 맞는 약물 후보 분자와 그 결합 방식(비공유 결합성 상호작용)까지 함께 설계 및 최적화까지 할 수 있는 인공지능 모델 ‘BInD’를 개발했다.\n이 기술의 핵심은 ‘동시 설계’다. 기존 AI 모델들은 분자만 만들거나, 만들어진 분자와 단백질의 결합 여부만 따로 평가했다. 반면, 이번에 개발된 모델은 분자와 단백질 사이의 결합 방식까지 함께 고려해 한 번에 설계한다.\n실제로 단백질과 결합할 때 중요한 요소를 미리 반영하기 때문에, 효과적이고 안정적인 분자를 만들 확률이 훨씬 높다. 이러한 생성 과정은 단백질의 표적 부위에 맞춰 원자들의 종류와 위치, 공유결합과 상호작용을 하나의 생성 과정에서 동시에 만들어내는 과정을 시각적으로 보여준다.\n또한, 이 인공지능 모델은 신약 설계 시 반드시 고려해야 할 여러 요소(예를 들어 분자의 안정성, 물성, 구조의 자연스러움 등)을 동시에 만족시키도록 설계됐다. 기존에는 한두 가지 목표에 집중해 다른 조건을 희생하는 경우가 많았지만, 이번 모델은 다양한 조건을 균형 있게 반영해 실용성을 크게 높였다.\n연구팀은 이 AI가 무작위 상태에서 점점 더 정교한 구조를 그려나가는 방식인 ‘확산 모델’을 기반으로 작동한다고 설명했다. 확산 모델은 2024 노벨 화학상을 받은‘알파폴드3’의 단백질-약물 구조 생성에서 활용돼 높은 효율성이 입증된 바 있다.\n이번 연구에서는 원자가 공간상 어디에 있어야 하는지 좌표를 찍어주는 알파폴드3와 달리 ‘결합 길이’나 ‘단백질-분자 간 거리’처럼 실제 화학 법칙에 맞는 기준들을 알려주는 지식 기반 가이드를 넣어, 생성된 구조가 더 현실적인 결과를 내도록 도왔다.\n뿐만 아니라, 연구팀은 한 번 만든 결과 중에서 뛰어난 결합 패턴을 찾아 다시 활용하는 최적화 전략도 적용했다. 이를 통해 추가 학습 없이도 더 뛰어난 약물 후보를 만들어낼 수 있었으며, 특히 암 관련 표적 단백질(EGFR)의 돌연변이에 선택적으로 작용하는 분자도 생성하는 데 성공했다.\n또한, 이번 연구는 본 연구팀이 앞서 발표한 단백질에 어떤 분자가 어떻게 결합하는지에 대한 조건을 입력해야만 했던 기존 AI를 한 단계 더 발전시켰다는 점에서도 의미가 깊다.\nKAIST 화학과 김우연 교수는“이번에 개발한 AI는 표적 단백질에 잘 결합하는 핵심 요소를 스스로 학습하고 이해해, 사전 정보 없이도 상호작용 하는 최적의 약물 후보인 분자를 설계할 수 있다는 점에서 신약 개발의 패러다임을 크게 바꿀 수 있을 것이다”라고 말했다.\n이어 “이번 기술은 화학적 상호작용 원리에 기반해 더 현실적이고 신뢰할 수 있는 분자 구조를 생성할 수 있어, 더 빠르고 정밀한 신약 개발을 가능하게 할 것으로 기대한다”라고 강조했다.\nKAIST 화학과 이중원, 정원호 박사과정 학생이 공동 제1 저자로 참여한 이번 연구 결과는 국제학술지 ‘어드밴스드 사이언스(Advanced Science)’(IF=14.1)에 'BInD: 다목적 구조 기반 신약 설계를 위한 결합 및 상호작용 생성 확산 모델(BInD: Bond and Interaction-Generating Diffusion Model for Multi-Objective Structure-Based Drug Design-다운)'란 제목으로 지난달 11일 게재됐다.\n",
        "date": "2025-08-10",
        "source": "인공지능 신문",
        "category": "기술"
    }
]
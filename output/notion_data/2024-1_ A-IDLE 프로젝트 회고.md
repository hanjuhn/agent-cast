# [2024-1] A-IDLE 프로젝트 회고

**페이지 ID:** 255d3416-0518-80d0-97d1-c0db2fe7734c
**생성일:** 2025-08-20T07:54:00.000Z
**마지막 수정:** 2025-08-20T07:57:00.000Z
**URL:** https://www.notion.so/2024-1-A-IDLE-255d3416051880d097d1c0db2fe7734c

---

아무것도 남기지 않는다면, 아무것도 남지 않을 것입니다.

저는 2024-1학기 (2024.03.04~2024.06.20)에 4학년 캡스톤디자인 프로젝트를 팀과 함께 진행했습니다.

이번 회고록에서는 단순히 프로젝트의 전체 내용을 다루기보다는, 제가 직접 기여한 부분에 초점을 맞추어 작성하고자 합니다.

### 📢 프로젝트 소개

- 프로젝트 인원 : 4명 (데이터사이언스 전공)
- 프로젝트 : 생성형 AI를 활용한 블로그 콘텐츠 자동화 솔루션
- 깃허브 링크 : A-IDLE 깃허브
- 협업 : Github, Notion, Discord, Slack
- 기술스택
### 👩🏻‍💻 나의 역할

- 베이스라인 코드 구축 (3주)
- Knowledge generation (데이터 수집 & 전처리) (2주)
- Knowledge selection (데이터 추출) (2주)
- 프롬프트 엔지니어링 페르소나 작성 (1주)
### 2. 🚩 주요 내용

'오.지.통' 블로그 글감을 위한 뉴스 기사를 찾기 위해 크롤링을 통해 적절한 뉴스를 추출하고, 이를 프롬프트에 전달하는 파이프라인 구축

### 3.☝🏻 요구 사항

- 최신순으로 당일 뉴스를 추출하여 비용/시간 최적화된 크롤링
- 크롤링되지 않는 뉴스 기사 및 발행 일자 데이터 전처리
- 기사의 핵심 주제가 지하철 관련 기사인지 데이터 추출
- 중복 기사 분류 및 필요한 정보 포함 여부을 고려한 데이터 추출
- 전체적인 프로젝트 가이드라인 및 베이스라인 구축
- 실 '오.지.통'에 적용 가능한 정확한 데이터 요구
- 브랜딩 블로그 컨셉에 맞는 '지통이' 페르소나 구축
### 4.🙆🏻‍♂️ 공헌한 점

'오지통'의 서비스에 사용할 베이스라인 구축, 데이터 수집, 전처리, 프롬프트 엔지니어닝 페르소나 구축 담당

- 블로그 글 생성이라는 목적에 맞게 베이스라인 구축
- 자동화을 위한 비용/시간문제를 줄이기 위한 여러 가지 실험 진행
- 데이터 추출의 정확성을 높이기 위해 직접 레이블을 진행하여 실제 유용한 뉴스 기사인지 판별
- 실제 기업이 사용하는 페르소나를 레퍼런스로 '지통이' 캐릭터 페르소나 구축
- 여러 방법을 시도하면서 실 서비스에서 사용하기 위한 실험 진행
### 5. 📍사용한 스킬 또는 지식

- 베이스라인 구축
- knowledge generation 실험
- knowledge selection 실험
- 페르소나 부여
### 6. 💡결과/성과

### 1) '오.지.통' 베이스라인 구축

지하철 이용자들에게 정확하고 실용적인 정보를 제공하기 위해 '오.지.통' 시스템의 베이스라인을 구축.

- 데이터 수집:
- 데이터 전처리:
- 데이터 추출 및 선택:
- 데이터 주입
- 프롬프트 주입
- 페르소나 주입
성과

이와 같은 흐름을 통해 '오.지.통' 시스템의 베이스라인을 구축하여, 지하철 이용자들에게 정확하고 실용적인 정보를 제공

### 2) knowledge Generation - 크롤링 방식 비교 실험

다양한 뉴스 기사 추출 크롤링 방식에 대한 실험 결과 정리표

- 실험 결과 요약
- 실험 절차
1. newspaper3k로 일차 크롤링:
1. Selenium으로 보조 크롤링:
성과

- newspaper3k: 뉴스 기사 추출에 특화된 기능으로 가장 빠르고 효율적인 방식.
- Selenium: HTML 구조가 복잡한 경우 사용, 동적 페이지 처리에 강점 있으나 속도 느림.
성과

newspaper3k로 전체 기사 중 85%를 신속하고 효율적으로 추출했으며, Selenium으로 나머지 15%의 기사를 성공적으로 크롤링했습니다. 이러한 접근 방식은 시간(평균 추출 시간: 2초/기사 vs. 10초/기사)과 노력을 절약하면서도 높은 품질의 데이터를 확보할 수 있었습니다.

### 3) 관련 주제 필터링

1. 의미 분석을 위한 모델 준비
1. 종속성과 엔터티 분석
1. BERT 임베딩 생성
1. 주제 필터링 조건 정의
실험 과정

- 100개의 뉴스 기사 레이블 작업:
관련 주제 필터링 결과

100개의 레이블 작업된 기사를 사용하여 관련 주제를 필터링한 결과:

### 성능 지표 계산

- Recall: 0.871 (87.1%)
- Precision: 0.805 (80.5%)
- F1-score: 0.837 (83.7%)
### 4) 페르소나 부여 실험 결과

'오.지.통'의 페르소나 설정

- 실험 절차
- 성과
페르소나를 부여하여 GPT의 블로그 글 생성 정확성을 높이고, 허위 정보 작성 빈도를 효과적으로 줄임.

### 7.🏷️ 그 외

- 프로젝트 전반 내용 잡기 위해 Rag 논문 리뷰 진행
- 중간 발표 (7주차), 최종 발표 (15주차)
- 총 14회의 주간 보고 발표에서 팀의 진행 상황과 본인의 프로젝트 진행 상황 공유
이하 내용은 느낀점을 기술하므로 조금 편안한 말투로 작성하겠습니다.

### 8. 힘들었던 점/ 신경 쓴 구현

<실제 데이터, null 값은 생각보다 많다.>

뉴스 기사를 처리하면서 HTML의 구조가 달라서 크롤링이 제대로 되지 않거나, 모든 사이트가 통일되어 있지 않은 부분에서 수작업으로 html 구조를 뜯어서 넣거나, 예외 처리를 하는 부분의 시간을 많이 들였다. 예외 처리가 발생하지 않으면 너무 좋겠지만, 이렇게 만일에 상황에 대비하는 작업도 중요하다는 것을 알 수 있었다.

<데이터 라벨링, 맞는지 확인이 어렵다.>

관련 주제 필터링을 하면서 데이터를 일일이 라벨링 작업을 해야 하는 번거로움이 있었다. 관련된 뉴스 기사인지 판단하는 것이 지극히 내 개인적인 주관이 들어가는 것 같아 기준이 모호하다는 생각을 하긴 했다. 최대한 라벨링을 하면서 키워드가 들어가 있는지, 횟수나 기준을 세워가며 라벨링을 진행하면서 근거 있는 기준의 중요성을 알게 되었다.

### 9. 기술적인 부분 이외의 힘들었던 점

<기획 & 디자인>

기획과 디자인을 다른 프로젝트를 하면서 늘거나, 대학 시절 많이 만들었던 PPT 덕분에 잘하게 된 것은 사실이다. 하지만, 이번 프로젝트에서 데이터 분석가만 4명이 있는 터라, 기획과 디자인을 좀 많이 해야 한다는 다소 아쉬움이 남는다.

<일정 관리>

아무래도 팀장으로 역할하고 있으니, 내야 될 서류도 많았고 학교에서 제출해야 하는 부분, 지원금 관리부터 프로젝트 이외 것들을 감당해야 하는 것에 시간을 많이 빼앗긴다는 생각을 많이 하게 되었다. 팀원들이 오롯이 프로젝트에 집중하기 위해서, 그런 부수적인 것들을 처리하는 게 팀장의 역할이라 생각해서 진행하는 것이 약간 번거로웠지만, 그래서 빠르게 프로젝트가 진행될 수 있었던 것 같다.

### 10. 🎉 수상


# AI Agent 구현을 위한 MCP 활용 방안 (네이버클라우드 최장호 수석) (1)

**페이지 ID:** 253d3416-0518-8044-b73f-e80ef7f2b95f
**생성일:** 2025-08-18T05:16:00.000Z
**마지막 수정:** 2025-08-18T05:16:00.000Z
**URL:** https://www.notion.so/AI-Agent-MCP-1-253d341605188044b73fe80ef7f2b95f

---

앞선 발표에서 소개하였듯, AI 에이전트를 실제 서비스에 적용하기 위해선 LLM이 다양한 툴과 연동되어야 합니다. 하지만 이 연동 과정이 생각보다 만만치 않죠. 저는 이번 세션에서 MCP가 왜 필요한지, 어떻게 구현되고 적용되는지 사례를 중심으로 공유드리겠습니다.

## AI 에이전트는 어떻게 진화하고 있을까?

초기 LLM은 단순 질문에 답하거나 문장을 생성하는 수준이었습니다. 그러나 학습된 시점까지의 데이터로 답변을 해주기 때문에, 내부 데이터 혹은 최신 데이터를 실시간으로 반영할 수 있도록 RAG(Retrieval-Augmented Generation) 방식이 등장했고, 지금은 LLM이 외부 툴과 연동되는 에이전트 형태로 발전하고 있습니다.

에이전트는 사용자의 요청을 받고, 이를 처리하기 위해 어떤 툴을 써야 할지 판단하고, 툴을 호출하고 실행한 뒤, 결과를 바탕으로 답변을 구성하는 순서. 'Observe(관찰) → Plan(계획) → Act(실행)' 구조로 움직이게 되는데요. 이때 핵심은 어떤 툴을 얼마나 잘 연결할 수 있느냐, 그리고 툴 호출을 잘 수행할 수 있는 LLM을 쓰느냐에 달려 있어요. 그리고 MCP는 이 부분에서 도움을 줄 수 있는 것이죠.

에이전트의 작동 구조 (출처: https://www.bcg.com/capabilities/artificial-intelligence/ai-agents)

## MCP가 등장한 이유

문제는 툴을 연결하는 과정이 매우 번거롭다는 점입니다. 예를 들어 LLM 기반 애플리케이션(LangChain, ChatGPT, Claude 등)에 메일, Notion, GitHub, Slack 같은 도구를 연동하려면 각각의 SDK나 API에 맞춰 따로 개발해야 하죠.

MCP의 등장 배경: 여러 도구를 연결하는 과정의 번거로움

이런 문제를 해결하기 위해 등장한 것이 바로 MCP(Multi-Tool Connection Protocol)입니다. 엔트로픽(Anthropic)에서 제안한 방식인데, 요약하자면 "LLM이 외부 툴과 통신할 수 있도록 표준화된 프로토콜"이라고 할 수 있습니다.

LLM(예: HyperCLOVA X, Claude, GPT 등)은 MCP 클라이언트, 외부 툴(예: Notion, Gmail, GitHub 등)은 MCP 서버, 둘 사이를 표준화된 방식(JSON-RPC 기반)으로 통신하게 합니다. 이 프로토콜 덕분에 여러 툴을 붙일 때 매번 복잡한 로직을 새로 짤 필요 없이 간단히 표준만 맞춰주면 바로 쓸 수 있게 되는 거죠.

MCP: LLM이 외부 데이터 및 도구와 상호작용할 수 있도록 설계된 프로토콜 (이미지 출처)

## MCP, 이렇게 쓸 수 있어요.

저희도 MCP를 기반으로 다양한 프로젝트를 진행하고 있습니다. 제가 직접 해본 예로, 긴 유튜브 영상을 요약해 노션에 자동 정리하는 워크플로우를 MCP로 만들었습니다. 자막 추출, 댓글 요약, 캡처 생성, 노션 업로드까지 한 줄 지시로 Claude가 다 처리해 주니 정말 AI 에이전트 같더라고요.

코드 관리에도 MCP는 굉장히 유용하게 쓰입니다. GitHub 이슈를 자동으로 읽고, 관련 코드를 수정하고, 커밋까지 해주는 자동화도 가능합니다. 실제로 Cursor AI에서 이런 기능을 통해 이슈를 해결하는 시나리오를 구성해 봤고요.

## 반복 없이 챗봇 확장하기: MCP로 유연하게 구성하는 방법

고객사에서 자주 요청하는 기능 중 하나가 '챗봇에 실시간 웹 검색이나 내부 문서 검색 기능을 붙이는 것'입니다. 하지만 이를 구현하려면 매번 새로운 API를 붙이고 복잡한 로직을 짜야 해서 부담이 크죠. 이런 상황에서 MCP를 사용하면 도구 추가나 교체가 표준화된 방식으로 가능해 훨씬 유연하게 구성할 수 있습니다.

예를 들어 LangGraph로 에이전트의 흐름을 만들고, 내부에서 MCP Client가 동작해 외부 MCP Server(웹 검색, 문서 검색 등)와 통신하는 구조를 생각해 볼 수 있습니다.

MCP Client와 MCP Server간 통신 구조

이 구조는 네이버 클라우드 플랫폼 환경에서도 쉽게 구성할 수 있어요. 예를 들어, LLM은 네이버클라우드의 HyperCLOVA X를 사용하고, 벡터 DB는 NAVER Search DB 혹은 Pinecone 등을 활용합니다. 서버는 Docker(도커)로 로컬에 구성하면 보안상 더 안전하고요.

실제로 오래된 문서 정보를 최신 웹 데이터와 비교해 더 정확한 답을 자동으로 판단하는 AI 에이전트를 구현해 봤습니다. “예결위 위원이 몇 명이야?”라는 질문에 문서와 웹 정보를 비교해 최신 값을 반환하는 방식인데요. 이런 구조 덕분에 고객사는 복잡한 정보 판단까지 자동화할 수 있습니다.

네이버 클라우드 플랫폼을 활용한 MCP 구성

## MCP, 선택이 아닌 필수

결국 에이전트는 ‘연결’이 핵심입니다. MCP는 툴을 만드는 개발자와, 그것을 활용할 수 있는 LLM 사이의 연결 고리를 제공합니다. 앞으로 Agentic AI가 더 발전하려면, 다양한 툴과의 연동이 점점 더 중요해질 겁니다. MCP 같은 표준이 자리 잡을수록 개발자는 더 빠르게 툴을 만들고, LLM은 더 강력한 에이전트로 진화할 수 있겠죠.

여기 계신 여러분도 AI 프로젝트를 하시면서 반복적인 툴 연결 작업이 부담스럽다고 느끼셨다면, MCP 도입을 꼭 고려해 보시길 추천드립니다.


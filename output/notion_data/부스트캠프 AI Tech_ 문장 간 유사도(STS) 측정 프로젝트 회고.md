# [부스트캠프 AI Tech] 문장 간 유사도(STS) 측정 프로젝트 회고

**페이지 ID:** 255d3416-0518-8084-a58f-ca9775bcd821
**생성일:** 2025-08-20T07:55:00.000Z
**마지막 수정:** 2025-08-20T07:57:00.000Z
**URL:** https://www.notion.so/AI-Tech-STS-255d341605188084a58fca9775bcd821

---

### 너무나도 늦은 회고록이지만 뒤늦게라도 Boostcamp STS 프로젝트를 회고하려 합니다.

### 최종 성적

### Public 2위 : 0.9378

### Private 3위 : 0.9417

### 프로젝트 시작 전

인생에서의 첫 캐글형식의 순위형 프로젝트였다.리더보드형 프로젝트를 함에 앞서 의욕도 많이 앞섰고, 잘 하고 싶은 마음이 가득했었다.

높은 순위를 프로젝트하면서 한번은 가지고 싶었고 추후 팀을 자유롭게 꾸릴때 높은 성적은 도움이 될 것이라고 생각했다.

### 프로젝트 진행

3주간 진행된 프로젝트에서 추석이라는 기간이 포함되어있었고 실질적으로는 약 2주 정도의 기간동안 프로젝트를 집중할 수 있었다.

이 글을 찾아서 들어오시는 분들은 부스트캠프 사람들로 예상이 되기에 프로젝트의 소개는 넘어가도록 하겠습니다.

위 그림은 프로젝트의 타임라인이다.약 두달이 지나서야 쓰는 회고지만 지금 보면 다음과 같은 타임라인은 정말 잘못 되었다고 생각한다.

EDA와 앙상블을 동시에 진행하다니,,,

### 우리팀이 범했던 실수에 대해서 먼저 말하고자 한다.

### 1. EDA의 중요성 간과

Boostcamp에서 프로젝트를 마칠 때 마다 2팀 정도 발표를 자원하거나지원자가 없다면 Private 높은 순위의 팀이 발표를 맡아서 하게 된다.

이번 프로젝트에서는 Public에서 3등 팀이 Private에서 1위를 하게 된 것을 보고 저팀의 노하우가 궁금했다.

1위의 비결은 바로 EDA였다. 우리팀의 패착은 모델의 성능에만 집중을 했었다.

그 어떤 팀보다 모델 탐색과 실험은 잘했다라고 생각하고 그것이 높은 순위를 얻게된 비결이라고 생각했다.

그렇지만 1등팀은 데이터셋의 모든 문장들을 일일히 수동으로 Quality check를 했다고 발표에서 전달해줬다.

(여기서 우리팀이 졌다고 생각했다)

EDA라는 것을 처음해본 우리팀은 사실 라벨의 분포정도 확인을 해보았고, 분포를 맞춰주자.. 라는 결론을 내고

Undersampling, Oversampling, Swap등의 방식을 적용해보고 해당 증강데이터셋을 학습데이터셋으로 사용해본 결과모델별로 성능이 아주 소폭 상승하거나 대부분 하락했었다.그렇지만 데이터 셋 내에서 오라벨 등, 노이즈가 껴있을 것이라는 상상을 하진 않았다.

왜 성능이 오르지 않지라는 분석을 하지 않았다. 그렇기에 데이터 셋을 뜯어볼 생각조차 없었다.

그 이후에 어느정도 앙상블의 성능향상이 더뎌지자 KoEDA나 다른 방식의 증강을 뒤늦게 생각한 것이 정말 아쉽다.

STS와 같은 단순 태스크들에서는 EDA에 조금 더 시간을 투자할 수 있었을 텐데와 같은 생각을 지금에서야 한다.

### 2.  무모한 모델 탐색

아까 위에서도 말했듯, 거의 모델 탐색과 동시에 앙상블을 진행했다.

아무래도 첫 프로젝트고, 관련 지식이 없던 나는 어떤 것이 좋은 모델이지 라는 인사이트가 전혀없었다.

사실 그렇기에 모델을 무작위로 시간을 투자해서 많이 실험을 했고, 리더보드에 제출하는 형식으로 성능을 평가했었다.

모델에 대한 이해없이, 높은 순위만을 찾기 위해서 모델 선정의 기준도 없이 실험한 것은 반성해야 한다고 생각한다.

벤치마크라는 것을 뒤늦게 알았고 이 이후 앞으로의 순위형 프로젝트에서 벤치마크를 기준으로 높은 성능의 모델을 먼저 실험해봐야 하겠다는 간단한 생각을 갖게 되었다.

(지금 두세달 전의 나는 무모했다. 거의 30개가 넘는 모델들을 주구장창 돌려봤다)

무모한 도전 (Hoxy 이거 아시나요)

### 3. 무지성 앙상블

1등 방법론에 대해 들으면서 앙상블을 마지막날 하루 정도만 투자하였고,그외에는 계속 단일모델로 성능을 높이는 실험을 했다고 전달 받았다.

우리팀, 아니 거의 내가 모델실험을 주로했었는데 높은 성능의 모델들을 계속 무지성으로 앙상블을 진행했다. 앙상블에 사용된 모델의 개수가 16개인가 (다 많아서 읊지도 못한다)

LV 2에서 Data-Centric 프로젝트를 하는데 해당 프로젝트는 모델의 변경없이 데이터 셋만 변경시켜서 성능을 높이는 프로젝트다.

우리팀은 LV 1때 데이터셋을 하나도 건드리지 않고 모델링 + 앙상블로만 성능을 높이는 프로젝트를 했던 것 같다.

EDA에 대한 고찰이 필요하다. 정말 우리팀에게 필요하다고 생각했다.

추가적으로 단순히 순위를 높이는 프로젝트를 하는 것 보다 어떤 논리적인 흐름으로 실험을 진행했는지,

그 실험에서 얻을 수 있는 것과 그 결과를 분석하고 정리하는 것이 앞으로의 프로젝트에서 도움이 되리라 생각했다.

앙상블로 좋은 결과를 냈지만, 다른 팀들이 프라이빗에서 대부분 Private 점수가 많이 오르는데 우리팀만 소폭 상승했고,그 원인을 중첩 앙상블의 과적합이 일어났다고 생각한다.

### 아쉬웠던 점도 말했으면 잘했던 점도 정리하고자 한다.

### 1. 허깅페이스 사용 익히기

컴공 전공이라고 말하기 아쉬울 정도로 사실 인공지능을 알지 못했고, 웹개발은 더군다나 더 모른다.

생각보다 컴공 출신의 사람들을 만나면 어느정도 인공지능에 대한 공부도 하고오고, Transformer가 뭔지 대략적으로 알고 오는 것 같다.

다만 나는 그런 것들을 전혀 몰랐고, LV 1에서의 강의들이 솔직히 지금도 어렵고, 이해가 다 되는 것은 아니다.

그런 점에서 Hugging Face에 대해 익히는 시간을 많이 가졌고,단순히 모델을 바꿔가며 실험을 했지만 Hugging Face에는 많이 익숙해졌다.추가적으로 다양한 기능들을 탐구하게 된 시간이라고 생각한다.

### 2. 베이스라인 이해하기

파이썬에 대해서는 잘 알았지만 개념이 부족해서인가 파이토치와 관련한 코드는 이해가 잘 되지 않았다.

이를 어떻게 극복했냐 하면은 그냥 뚫어지게 쳐다봤다.

사실 프로젝트에 쏟는 시간이 정말 많았다고 생각한다.코드를 단순히 돌리는 게 아니라 이코드가 왜 나왔지라는 주석을 달아보며 이해하려 했다.이런 시간들이 정말 추후 LV 2에서도 도움이 많이 됐다고 생각한다.

### 3. 깃 사용법 익히기, 협업 툴 적응하기

노션 사용도 익숙하지 않고, 깃 사용도 거의 처음이라 Git Flow에 대한 이해가 부족했는데 사용하면서 Git에 대한 기초를 다졌다.

추후 부스트캠프에서 개발자스럽게 GitHub 사용하기 강의가 있어서 그 때 많은 공부를 했었다.

깃허브와 랩업리포트를 확인 할수 있게 GitHub 링크를 남겨두겠습니다.

GitHub - boostcampaitech7/level1-semantictextsimilarity-nlp-15: level1-semantictextsimilarity-nlp-15 created by GitHub Classroom
level1-semantictextsimilarity-nlp-15 created by GitHub Classroom - boostcampaitech7/level1-semantictextsimilarity-nlp-15
github.com

7기 이후 다음 기수분들이 저의 글들을 본다면, 당장 순위에 연연해하지 않고 팀의 실험을 이어나간다면 좋을 것 같습니다~

+ 전 기수의 실험들을 너무 쫓지말기!

